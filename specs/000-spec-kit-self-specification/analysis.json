{
  "project_analysis": {
    "project_path": "/home/runner/work/spec-kit/spec-kit",
    "project_name": "spec-kit",
    "structure": {},
    "documentation_files": [
      "README.md",
      "SUPPORT.md",
      "spec-driven.md",
      "README.md.bak",
      "CONTRIBUTING.md",
      "ONBOARDING.md",
      "SECURITY.md",
      "CODE_OF_CONDUCT.md",
      "memory/constitution_update_checklist.md",
      "memory/constitution.md",
      "templates/tasks-template.md",
      "templates/agent-file-template.md",
      "templates/plan-template.md",
      "templates/spec-template.md",
      "templates/commands/plan.md",
      "templates/commands/tasks.md",
      "templates/commands/specify.md"
    ],
    "code_files": [
      "pyproject.toml",
      "scripts/py/check_task_prerequisites.py",
      "scripts/py/create_new_feature.py",
      "scripts/py/__init__.py",
      "scripts/py/get_feature_paths.py",
      "scripts/py/update_agent_context.py",
      "scripts/py/common.py",
      "scripts/py/setup_plan.py",
      "src/spec_kit_mcp/scripts.py",
      "src/spec_kit_mcp/__init__.py",
      "src/spec_kit_mcp/server.py",
      "src/spec_kit_mcp/onboarding.py",
      "src/spec_kit_mcp/cli.py"
    ],
    "config_files": [
      "mcp-config.json",
      ".github/workflows/manual-release.yml",
      ".github/workflows/release.yml"
    ],
    "languages_detected": [
      "Python"
    ],
    "frameworks_detected": [],
    "build_systems": [
      "Python (pyproject.toml)"
    ],
    "has_tests": true,
    "has_ci_cd": true,
    "estimated_size": "medium",
    "file_count": 72,
    "dir_count": 27
  },
  "documentation_analysis": {
    "project_path": "/home/runner/work/spec-kit/spec-kit",
    "files_parsed": [
      "README.md",
      "README.md.bak",
      "README.md",
      "SUPPORT.md",
      "spec-driven.md",
      "CONTRIBUTING.md",
      "ONBOARDING.md",
      "SECURITY.md",
      "CODE_OF_CONDUCT.md",
      "memory/constitution_update_checklist.md",
      "memory/constitution.md",
      "templates/tasks-template.md",
      "templates/agent-file-template.md",
      "templates/plan-template.md",
      "templates/spec-template.md",
      "templates/commands/plan.md",
      "templates/commands/tasks.md",
      "templates/commands/specify.md",
      "CONTRIBUTING.md"
    ],
    "content_sections": {
      "README.md": {
        "content": "<div align=\"center\">\n    <img src=\"./media/logo_small.webp\"/>\n    <h1>\ud83c\udf31 Spec Kit</h1>\n    <h3><em>Build high-quality software faster.</em></h3>\n</div>\n\n<p align=\"center\">\n    <strong>An effort to allow organizations to focus on product scenarios rather than writing undifferentiated code with the help of Spec-Driven Development.</strong>\n</p>\n\n[![Release](https://github.com/github/spec-kit/actions/workflows/release.yml/badge.svg)](https://github.com/github/spec-kit/actions/workflows/release.yml)\n\n---\n\n## Table of Contents\n\n- [\ud83e\udd14 What is Spec-Driven Development?](#-what-is-spec-driven-development)\n- [\u26a1 Get started](#-get-started)\n- [\ud83d\udcda Core philosophy](#-core-philosophy)\n- [\ud83c\udf1f Development phases](#-development-phases)\n- [\ud83c\udfaf Experimental goals](#-experimental-goals)\n- [\ud83d\udd27 Prerequisites](#-prerequisites)\n- [\ud83d\udcd6 Learn more](#-learn-more)\n- [Detailed process](#detailed-process)\n- [Troubleshooting](#troubleshooting)\n\n## \ud83e\udd14 What is Spec-Driven Development?\n\nSpec-Driven Development **flips the script** on traditional software development. For decades, code has been king \u2014 specifications were just scaffolding we built and discarded once the \"real work\" of coding began. Spec-Driven Development changes this: **specifications become executable**, directly generating working implementations rather than just guiding them.\n\n## \u26a1 Get started\n\n### 1. Install Spec-Kit MCP Server\n\nThe Spec-Kit is now available as a Model Context Protocol (MCP) server that provides AI agents with powerful spec-driven development tools:\n\n```bash\n# Install the MCP server\npip install git+https://github.com/ASISaga/spec-kit.git\n\n# Run the MCP server\nspec-kit-mcp\n```\n\n### 2. Configure your AI agent\n\nAdd the Spec-Kit MCP server to your AI agent's configuration. The server provides these tools:\n\n**For New Projects:**\n- **init_project**: Initialize new Spec-Kit projects with templates\n- **create_new_feature**: Create feature branches with specifications  \n- **setup_plan**: Set up implementation plans\n- **check_task_prerequisites**: Validate task requirements\n- **update_agent_context**: Update agent context files\n- **get_feature_paths**: Get feature file paths\n- **run_script**: Execute cross-platform scripts\n- **check_requirements**: Check system requirements\n- **list_scripts**: Show available scripts and compatibility\n\n**For Existing Projects:**\n- **analyze_existing_project**: Analyze existing project structure and codebase\n- **parse_existing_documentation**: Extract requirements from existing documentation\n- **extract_requirements_from_code**: Extract specifications from code comments and docstrings\n- **generate_standardized_spec**: Generate Spec-Kit compatible specifications from analysis\n- **create_migration_plan**: Create detailed migration plans for adopting spec-driven development\n- **onboard_existing_project**: Complete end-to-end onboarding analysis\n\n**For Progressive Onboarding (NEW):**\n- **analyze_feature_component**: Analyze specific features/components within a project\n- **extract_feature_boundaries**: Identify logical feature boundaries for progressive onboarding\n- **onboard_project_feature**: Onboard individual features to spec-driven development\n- **merge_feature_specifications**: Combine multiple feature specifications into master specification\n- **detect_specification_conflicts**: Identify conflicts between feature specifications\n- **resolve_feature_dependencies**: Analyze and document dependencies between features\n- **create_progressive_migration_plan**: Create phased migration plans for incremental adoption\n- **track_onboarding_progress**: Track progress across multiple features/teams\n- **validate_specification_consistency**: Ensure consistency across progressive specifications\n\n### 3. Use with your AI agent\n\nOnce configured, your AI agent can use spec-driven development tools directly:\n\n**For New Projects:**\n- Create specifications that define the **what** and **why**, not the tech stack\n- Generate technical implementation plans with your chosen tech stack  \n- Break down features into actionable tasks\n- Manage the complete spec-driven development lifecycle\n\n**For Existing Projects:**\n- Analyze existing project structure and extract requirements\n- Parse documentation and code to understand current specifications\n- Generate standardized Spec-Kit compatible specifications\n- Create migration plans for adopting spec-driven development workflow\n- Onboard legacy projects to modern spec-driven approaches\n\n**For Progressive Onboarding (NEW):**\n- Analyze and onboard individual features or components incrementally\n- Support multiple teams working on different parts independently\n- Merge and coordinate specifications across features\n- Detect and resolve conflicts between feature specifications\n- Track progress and manage dependencies during progressive migration\n- Enable gradual adoption of spec-driven development across organizations\n\nFor detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).\nFor existing project onboarding, see our [onboarding guide](./ONBOARDING.md).\n\n## \ud83d\udcda Core philosophy\n\nSpec-Driven Development is a structured process that emphasizes:\n\n- **Intent-driven development** where specifications define the \"_what_\" before the \"_how_\"\n- **Rich specification creation** using guardrails and organizational principles\n- **Multi-step refinement** rather than one-shot code generation from prompts\n- **Heavy reliance** on advanced AI model capabilities for specification interpretation\n\n## \ud83c\udf1f Development phases\n\n| Phase | Focus | Key Activities |\n|-------|-------|----------------|\n| **0-to-1 Development** (\"Greenfield\") | Generate from scratch | <ul><li>Start with high-level requirements</li><li>Generate specifications</li><li>Plan implementation steps</li><li>Build production-ready applications</li></ul> |\n| **Creative Exploration** | Parallel implementations | <ul><li>Explore diverse solutions</li><li>Support multiple technology stacks & architectures</li><li>Experiment with UX patterns</li></ul> |\n| **Iterative Enhancement** (\"Brownfield\") | Brownfield modernization | <ul><li>Add features iteratively</li><li>Modernize legacy systems</li><li>Adapt processes</li></ul> |\n| **Existing Project Onboarding** (**ENHANCED**) | Legacy project migration | <ul><li>Analyze existing codebases and documentation</li><li>Extract and standardize requirements</li><li>Create migration plans</li><li>Adopt spec-driven workflows gradually</li></ul> |\n| **Progressive Onboarding** (**NEW**) | Incremental feature-level adoption | <ul><li>Onboard individual features and components</li><li>Support multi-team development workflows</li><li>Coordinate specifications across features</li><li>Enable gradual organizational adoption</li></ul> |\n\n## \ud83c\udfaf Experimental goals\n\nOur research and experimentation focus on:\n\n### Technology independence\n\n- Create applications using diverse technology stacks\n- Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks\n\n### Enterprise constraints\n\n- Demonstrate mission-critical application development\n- Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)\n- Support enterprise design systems and compliance requirements\n\n### User-centric development\n\n- Build applications for different user cohorts and preferences\n- Support various development approaches (from vibe-coding to AI-native development)\n\n### Creative & iterative processes\n\n- Validate the concept of parallel implementation exploration\n- Provide robust iterative feature development workflows\n- Extend processes to handle upgrades and modernization tasks  \n\n## \ud83d\udd27 Prerequisites\n\n- **Cross-platform**: Windows, Linux, macOS\n- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n- [uv](https://docs.astral.sh/uv/) for package management\n- [Python 3.11+](https://www.python.org/downloads/)\n- [Git](https://git-scm.com/downloads)\n\n## \ud83d\udcd6 Learn more\n\n- **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process\n- **[Detailed Walkthrough](#detailed-process)** - Step-by-step implementation guide\n\n---\n\n## Detailed process\n\n<details>\n<summary>Click to expand the detailed step-by-step walkthrough</summary>\n\nYou can use the Specify CLI to bootstrap your project, which will bring in the required artifacts in your environment. Run:\n\n```bash\nspecify init <project_name>\n```\n\nOr initialize in the current directory:\n\n```bash\nspecify init --here\n```\n\n![Specify CLI bootstrapping a new project in the terminal](./media/specify_cli.gif)\n\nYou will be prompted to select the AI agent you are using. You can also proactively specify it directly in the terminal:\n\n```bash\nspecify init <project_name> --ai claude\nspecify init <project_name> --ai gemini\nspecify init <project_name> --ai copilot\n# Or in current directory:\nspecify init --here --ai claude\n```\n\nThe CLI will check if you have Claude Code or Gemini CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:\n\n```bash\nspecify init <project_name> --ai claude --ignore-agent-tools\n```\n\n### **STEP 1:** Bootstrap the project\n\nGo to the project folder and run your AI agent. In our example, we're using `claude`.\n\n![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)\n\nYou will know that things are configured correctly if you see the `/specify`, `/plan`, and `/tasks` commands available.\n\nThe first step should be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.\n\n>[!IMPORTANT]\n>Be as explicit as possible about _what_ you are trying to build and _why_. **Do not focus on the tech stack at this point**.\n\nAn example prompt:\n\n```text\nDevelop Taskify, a team productivity platform. It should allow users to create projects, add team members,\nassign tasks, comment and move tasks between boards in Kanban style. In this initial phase for this feature,\nlet's call it \"Create Taskify,\" let's have multiple users but the users will be declared ahead of time, predefined.\nI want five users in two different categories, one product manager and four engineers. Let's create three\ndifferent sample projects. Let's have the standard Kanban columns for the status of each task, such as \"To Do,\"\n\"In Progress,\" \"In Review,\" and \"Done.\" There will be no login for this application as this is just the very\nfirst testing thing to ensure that our basic features are set up. For each task in the UI for a task card,\nyou should be able to change the current status of the task between the different columns in the Kanban work board.\nYou should be able to leave an unlimited number of comments for a particular card. You should be able to, from that task\ncard, assign one of the valid users. When you first launch Taskify, it's going to give you a list of the five users to pick\nfrom. There will be no password required. When you click on a user, you go into the main view, which displays the list of\nprojects. When you click on a project, you open the Kanban board for that project. You're going to see the columns.\nYou'll be able to drag and drop cards back and forth between different columns. You will see any cards that are\nassigned to you, the currently logged in user, in a different color from all the other ones, so you can quickly\nsee yours. You can edit any comments that you make, but you can't edit comments that other people made. You can\ndelete any comments that you made, but you can't delete comments anybody else made.\n```\n\nAfter this prompt is entered, you should see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.\n\nOnce this step is completed, you should have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text\nI want you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task so that the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.\n",
        "headings": [
          "## Table of Contents",
          "## \ud83e\udd14 What is Spec-Driven Development?",
          "## \u26a1 Get started",
          "### 1. Install Spec-Kit MCP Server",
          "# Install the MCP server",
          "# Run the MCP server",
          "### 2. Configure your AI agent",
          "### 3. Use with your AI agent",
          "## \ud83d\udcda Core philosophy",
          "## \ud83c\udf1f Development phases",
          "## \ud83c\udfaf Experimental goals",
          "### Technology independence",
          "### Enterprise constraints",
          "### User-centric development",
          "### Creative & iterative processes",
          "## \ud83d\udd27 Prerequisites",
          "## \ud83d\udcd6 Learn more",
          "## Detailed process",
          "# Or in current directory:",
          "### **STEP 1:** Bootstrap the project",
          "### **STEP 2:** Functional specification clarification",
          "### **STEP 3:** Generate a plan",
          "### **STEP 4:** Have Claude Code validate the plan",
          "### STEP 5: Implementation",
          "## Troubleshooting",
          "### Windows Support",
          "#### Windows-Specific Helpers",
          "# Navigate to your spec-kit project directory",
          "#### Windows Troubleshooting",
          "### Git Credential Manager on Linux",
          "#!/usr/bin/env bash",
          "## Maintainers",
          "## Support",
          "## Acknowledgements",
          "## License"
        ],
        "word_count": 2994
      },
      "README.md.bak": {
        "content": "<div align=\"center\">\n    <img src=\"./media/logo_small.webp\"/>\n    <h1>\ud83c\udf31 Spec Kit</h1>\n    <h3><em>Build high-quality software faster.</em></h3>\n</div>\n\n<p align=\"center\">\n    <strong>An effort to allow organizations to focus on product scenarios rather than writing undifferentiated code with the help of Spec-Driven Development.</strong>\n</p>\n\n[![Release](https://github.com/github/spec-kit/actions/workflows/release.yml/badge.svg)](https://github.com/github/spec-kit/actions/workflows/release.yml)\n\n---\n\n## Table of Contents\n\n- [\ud83e\udd14 What is Spec-Driven Development?](#-what-is-spec-driven-development)\n- [\u26a1 Get started](#-get-started)\n- [\ud83d\udcda Core philosophy](#-core-philosophy)\n- [\ud83c\udf1f Development phases](#-development-phases)\n- [\ud83c\udfaf Experimental goals](#-experimental-goals)\n- [\ud83d\udd27 Prerequisites](#-prerequisites)\n- [\ud83d\udcd6 Learn more](#-learn-more)\n- [Detailed process](#detailed-process)\n- [Troubleshooting](#troubleshooting)\n\n## \ud83e\udd14 What is Spec-Driven Development?\n\nSpec-Driven Development **flips the script** on traditional software development. For decades, code has been king \u2014 specifications were just scaffolding we built and discarded once the \"real work\" of coding began. Spec-Driven Development changes this: **specifications become executable**, directly generating working implementations rather than just guiding them.\n\n## \u26a1 Get started\n\n### 1. Install Specify\n\nInitialize your project depending on the coding agent you're using:\n\n```bash\nuvx --from git+https://github.com/github/spec-kit.git specify init <PROJECT_NAME>\n```\n\n### 2. Create the spec\n\nUse the `/specify` command to describe what you want to build. Focus on the **what** and **why**, not the tech stack.\n\n```bash\n/specify Build an application that can help me organize my photos in separate photo albums. Albums are grouped by date and can be re-organized by dragging and dropping on the main page. Albums never other nested albums. Within each album, photos are previewed in a tile-like interface.\n```\n\n### 3. Create a technical implementation plan\n\nUse the `/plan` command to provide your tech stack and architecture choices.\n\n```bash\n/plan The application uses Vite with minimal number of libraries. Use vanilla HTML, CSS, and JavaScript as much as possible. Images are not uploaded anywhere and metadata is stored in a local SQLite database.\n```\n\n### 4. Break down and implement\n\nUse `/tasks` to create an actionable task list, then ask your agent to implement the feature.\n\nFor detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).\n\n## \ud83d\udcda Core philosophy\n\nSpec-Driven Development is a structured process that emphasizes:\n\n- **Intent-driven development** where specifications define the \"_what_\" before the \"_how_\"\n- **Rich specification creation** using guardrails and organizational principles\n- **Multi-step refinement** rather than one-shot code generation from prompts\n- **Heavy reliance** on advanced AI model capabilities for specification interpretation\n\n## \ud83c\udf1f Development phases\n\n| Phase | Focus | Key Activities |\n|-------|-------|----------------|\n| **0-to-1 Development** (\"Greenfield\") | Generate from scratch | <ul><li>Start with high-level requirements</li><li>Generate specifications</li><li>Plan implementation steps</li><li>Build production-ready applications</li></ul> |\n| **Creative Exploration** | Parallel implementations | <ul><li>Explore diverse solutions</li><li>Support multiple technology stacks & architectures</li><li>Experiment with UX patterns</li></ul> |\n| **Iterative Enhancement** (\"Brownfield\") | Brownfield modernization | <ul><li>Add features iteratively</li><li>Modernize legacy systems</li><li>Adapt processes</li></ul> |\n\n## \ud83c\udfaf Experimental goals\n\nOur research and experimentation focus on:\n\n### Technology independence\n\n- Create applications using diverse technology stacks\n- Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks\n\n### Enterprise constraints\n\n- Demonstrate mission-critical application development\n- Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)\n- Support enterprise design systems and compliance requirements\n\n### User-centric development\n\n- Build applications for different user cohorts and preferences\n- Support various development approaches (from vibe-coding to AI-native development)\n\n### Creative & iterative processes\n\n- Validate the concept of parallel implementation exploration\n- Provide robust iterative feature development workflows\n- Extend processes to handle upgrades and modernization tasks  \n\n## \ud83d\udd27 Prerequisites\n\n- **Cross-platform**: Windows, Linux, macOS\n- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n- [uv](https://docs.astral.sh/uv/) for package management\n- [Python 3.11+](https://www.python.org/downloads/)\n- [Git](https://git-scm.com/downloads)\n\n## \ud83d\udcd6 Learn more\n\n- **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process\n- **[Detailed Walkthrough](#detailed-process)** - Step-by-step implementation guide\n\n---\n\n## Detailed process\n\n<details>\n<summary>Click to expand the detailed step-by-step walkthrough</summary>\n\nYou can use the Specify CLI to bootstrap your project, which will bring in the required artifacts in your environment. Run:\n\n```bash\nspecify init <project_name>\n```\n\nOr initialize in the current directory:\n\n```bash\nspecify init --here\n```\n\n![Specify CLI bootstrapping a new project in the terminal](./media/specify_cli.gif)\n\nYou will be prompted to select the AI agent you are using. You can also proactively specify it directly in the terminal:\n\n```bash\nspecify init <project_name> --ai claude\nspecify init <project_name> --ai gemini\nspecify init <project_name> --ai copilot\n# Or in current directory:\nspecify init --here --ai claude\n```\n\nThe CLI will check if you have Claude Code or Gemini CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:\n\n```bash\nspecify init <project_name> --ai claude --ignore-agent-tools\n```\n\n### **STEP 1:** Bootstrap the project\n\nGo to the project folder and run your AI agent. In our example, we're using `claude`.\n\n![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)\n\nYou will know that things are configured correctly if you see the `/specify`, `/plan`, and `/tasks` commands available.\n\nThe first step should be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.\n\n>[!IMPORTANT]\n>Be as explicit as possible about _what_ you are trying to build and _why_. **Do not focus on the tech stack at this point**.\n\nAn example prompt:\n\n```text\nDevelop Taskify, a team productivity platform. It should allow users to create projects, add team members,\nassign tasks, comment and move tasks between boards in Kanban style. In this initial phase for this feature,\nlet's call it \"Create Taskify,\" let's have multiple users but the users will be declared ahead of time, predefined.\nI want five users in two different categories, one product manager and four engineers. Let's create three\ndifferent sample projects. Let's have the standard Kanban columns for the status of each task, such as \"To Do,\"\n\"In Progress,\" \"In Review,\" and \"Done.\" There will be no login for this application as this is just the very\nfirst testing thing to ensure that our basic features are set up. For each task in the UI for a task card,\nyou should be able to change the current status of the task between the different columns in the Kanban work board.\nYou should be able to leave an unlimited number of comments for a particular card. You should be able to, from that task\ncard, assign one of the valid users. When you first launch Taskify, it's going to give you a list of the five users to pick\nfrom. There will be no password required. When you click on a user, you go into the main view, which displays the list of\nprojects. When you click on a project, you open the Kanban board for that project. You're going to see the columns.\nYou'll be able to drag and drop cards back and forth between different columns. You will see any cards that are\nassigned to you, the currently logged in user, in a different color from all the other ones, so you can quickly\nsee yours. You can edit any comments that you make, but you can't edit comments that other people made. You can\ndelete any comments that you made, but you can't delete comments anybody else made.\n```\n\nAfter this prompt is entered, you should see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.\n\nOnce this step is completed, you should have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text\nI want you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task so that the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.\n",
        "headings": [
          "## Table of Contents",
          "## \ud83e\udd14 What is Spec-Driven Development?",
          "## \u26a1 Get started",
          "### 1. Install Specify",
          "### 2. Create the spec",
          "### 3. Create a technical implementation plan",
          "### 4. Break down and implement",
          "## \ud83d\udcda Core philosophy",
          "## \ud83c\udf1f Development phases",
          "## \ud83c\udfaf Experimental goals",
          "### Technology independence",
          "### Enterprise constraints",
          "### User-centric development",
          "### Creative & iterative processes",
          "## \ud83d\udd27 Prerequisites",
          "## \ud83d\udcd6 Learn more",
          "## Detailed process",
          "# Or in current directory:",
          "### **STEP 1:** Bootstrap the project",
          "### **STEP 2:** Functional specification clarification",
          "### **STEP 3:** Generate a plan",
          "### **STEP 4:** Have Claude Code validate the plan",
          "### STEP 5: Implementation",
          "## Troubleshooting",
          "### Windows Support",
          "#### Windows-Specific Helpers",
          "# Navigate to your spec-kit project directory",
          "#### Windows Troubleshooting",
          "### Git Credential Manager on Linux",
          "#!/usr/bin/env bash",
          "## Maintainers",
          "## Support",
          "## Acknowledgements",
          "## License"
        ],
        "word_count": 2707
      },
      "SUPPORT.md": {
        "content": "# Support \n\n## How to file issues and get help\n\nThis project uses GitHub issues to track bugs and feature requests. Please search the existing issues before filing new issues to avoid duplicates. For new issues, file your bug or feature request as a new issue.\n\nFor help or questions about using this project, please:\n\n- Open a [GitHub issue](https://github.com/github/spec-kit/issues/new) for bug reports, feature requests, or questions about the Spec-Driven Development methodology\n- Check the [comprehensive guide](./spec-driven.md) for detailed documentation on the Spec-Driven Development process\n- Review the [README](./README.md) for getting started instructions and troubleshooting tips\n\n## Project Status\n\n**Spec Kit** is under active development and maintained by GitHub staff **AND THE COMMUNITY**. We will do our best to respond to support, feature requests, and community questions in a timely manner.\n\n## GitHub Support Policy\n\nSupport for this project is limited to the resources listed above.\n",
        "headings": [
          "# Support",
          "## How to file issues and get help",
          "## Project Status",
          "## GitHub Support Policy"
        ],
        "word_count": 146
      },
      "spec-driven.md": {
        "content": "# Specification-Driven Development (SDD)\n\n## The Power Inversion\n\nFor decades, code has been king. Specifications served code\u2014they were the scaffolding we built and then discarded once the \"real work\" of coding began. We wrote PRDs to guide development, created design docs to inform implementation, drew diagrams to visualize architecture. But these were always subordinate to the code itself. Code was truth. Everything else was, at best, good intentions. Code was the source of truth, as it moved forward, and spec's rarely kept pace. As the asset (code) and the implementation are one, it's not easy to have a parallel implementation without trying to build from the code.\n\nSpec-Driven Development (SDD) inverts this power structure. Specifications don't serve code\u2014code serves specifications. The (Product Requirements Document-Specification) PRD isn't a guide for implementation; it's the source that generates implementation. Technical plans aren't documents that inform coding; they're precise definitions that produce code. This isn't an incremental improvement to how we build software. It's a fundamental rethinking of what drives development.\n\nThe gap between specification and implementation has plagued software development since its inception. We've tried to bridge it with better documentation, more detailed requirements, stricter processes. These approaches fail because they accept the gap as inevitable. They try to narrow it but never eliminate it. SDD eliminates the gap by making specifications or and their concrete implementation plans born from the specification executable. When specifications to implementation plans generate code, there is no gap\u2014only transformation.\n\nThis transformation is now possible because AI can understand and implement complex specifications, and create detailed implementation plans. But raw AI generation without structure produces chaos. SDD provides that structure through specifications and subsequent implementation plans that are precise, complete, and unambiguous enough to generate working systems. The specification becomes the primary artifact. Code becomes its expression (as an implementation from the implementation plan) in a particular language and framework.\n\nIn this new world, maintaining software means evolving specifications. The intent of the development team is expressed in natural language (\"**intent-driven development**\"), design assets, core principles and other guidelines . The **lingua franca** of development moves to a higher-level, and code is the last-mile approach.\n\nDebugging means fixing specifications and their implementation plans that generate incorrect code. Refactoring means restructuring for clarity. The entire development workflow reorganizes around specifications as the central source of truth, with implementation plans and code as the continuously regenerated output. Updating apps with new features or creating a new parallel implementation because we are creative beings, means revisiting the specification and creating new implementation plans. This process is therefore a 0 -> 1, (1', ..), 2, 3, N.\n\nThe development team focuses in on their creativity, experimentation, their critical thinking.\n\n## The SDD Workflow in Practice\n\nThe workflow begins with an idea\u2014often vague and incomplete. Through iterative dialogue with AI, this idea becomes a comprehensive PRD. The AI asks clarifying questions, identifies edge cases, and helps define precise acceptance criteria. What might take days of meetings and documentation in traditional development happens in hours of focused specification work. This transforms the traditional SDLC\u2014requirements and design become continuous activities rather than discrete phases. This is supportive of a **team process**, that's team reviewed-specifications are expressed and versioned, created in branches, and merged.\n\nWhen a product manager updates acceptance criteria, implementation plans automatically flag affected technical decisions. When an architect discovers a better pattern, the PRD updates to reflect new possibilities.\n\nThroughout this specification process, research agents gather critical context. They investigate library compatibility, performance benchmarks, and security implications. Organizational constraints are discovered and applied automatically\u2014your company's database standards, authentication requirements, and deployment policies seamlessly integrate into every specification.\n\nFrom the PRD, AI generates implementation plans that map requirements to technical decisions. Every technology choice has documented rationale. Every architectural decision traces back to specific requirements. Throughout this process, consistency validation continuously improves quality. AI analyzes specifications for ambiguity, contradictions, and gaps\u2014not as a one-time gate, but as an ongoing refinement.\n\nCode generation begins as soon as specifications and their implementation plans are stable enough, but they do not have to be \"complete.\" Early generations might be exploratory\u2014testing whether the specification makes sense in practice. Domain concepts become data models. User stories become API endpoints. Acceptance scenarios become tests. This merges development and testing through specification\u2014test scenarios aren't written after code, they're part of the specification that generates both implementation and tests.\n\nThe feedback loop extends beyond initial development. Production metrics and incidents don't just trigger hotfixes\u2014they update specifications for the next regeneration. Performance bottlenecks become new non-functional requirements. Security vulnerabilities become constraints that affect all future generations. This iterative dance between specification, implementation, and operational reality is where true understanding emerges and where the traditional SDLC transforms into a continuous evolution.\n\n## Why SDD Matters Now\n\nThree trends make SDD not just possible but necessary:\n\nFirst, AI capabilities have reached a threshold where natural language specifications can reliably generate working code. This isn't about replacing developers\u2014it's about amplifying their effectiveness by automating the mechanical translation from specification to implementation. It can amplify exploration and creativity, it can support \"start-over\" easily, it supports addition subtraction and critical thinking.\n\nSecond, software complexity continues to grow exponentially. Modern systems integrate dozens of services, frameworks, and dependencies. Keeping all these pieces aligned with original intent through manual processes becomes increasingly difficult. SDD provides systematic alignment through specification-driven generation. Frameworks may evolve to provide AI-first support, not human-first support, or architect around reusable components.\n\nThird, the pace of change accelerates. Requirements change far more rapidly today than ever before. Pivoting is no longer exceptional\u2014it's expected. Modern product development demands rapid iteration based on user feedback, market conditions, and competitive pressures. Traditional development treats these changes as disruptions. Each pivot requires manually propagating changes through documentation, design, and code. The result is either slow, careful updates that limit velocity, or fast, reckless changes that accumulate technical debt.\n\nSDD can support what-if/simulation experiments, \"If we need to re-implement or change the application to promote a business need to sell more T-shirts, how would we implement and experiment for that?\".\n\nSDD transforms requirement changes from obstacles into normal workflow. When specifications drive implementation, pivots become systematic regenerations rather than manual rewrites. Change a core requirement in the PRD, and affected implementation plans update automatically. Modify a user story, and corresponding API endpoints regenerate. This isn't just about initial development\u2014it's about maintaining engineering velocity through inevitable changes.\n\n## Core Principles\n\n**Specifications as the Lingua Franca**: The specification becomes the primary artifact. Code becomes its expression in a particular language and framework. Maintaining software means evolving specifications.\n\n**Executable Specifications**: Specifications must be precise, complete, and unambiguous enough to generate working systems. This eliminates the gap between intent and implementation.\n\n**Continuous Refinement**: Consistency validation happens continuously, not as a one-time gate. AI analyzes specifications for ambiguity, contradictions, and gaps as an ongoing process.\n\n**Research-Driven Context**: Research agents gather critical context throughout the specification process, investigating technical options, performance implications, and organizational constraints.\n\n**Bidirectional Feedback**: Production reality informs specification evolution. Metrics, incidents, and operational learnings become inputs for specification refinement.\n\n**Branching for Exploration**: Generate multiple implementation approaches from the same specification to explore different optimization targets\u2014performance, maintainability, user experience, cost.\n\n## Implementation Approaches\n\nToday, practicing SDD requires assembling existing tools and maintaining discipline throughout the process. The methodology can be practiced with:\n\n- AI assistants for iterative specification development\n- Research agents for gathering technical context\n- Code generation tools for translating specifications to implementation\n- Version control systems adapted for specification-first workflows\n- Consistency checking through AI analysis of specification documents\n\nThe key is treating specifications as the source of truth, with code as the generated output that serves the specification rather than the other way around.\n\n## Streamlining SDD with Claude Commands\n\nThe SDD methodology is significantly enhanced through two powerful Claude commands that automate the specification and planning workflow:\n\n### The `new_feature` Command\n\nThis command transforms a simple feature description (the user-prompt) into a complete, structured specification with automatic repository management:\n\n1. **Automatic Feature Numbering**: Scans existing specs to determine the next feature number (e.g., 001, 002, 003)\n2. **Branch Creation**: Generates a semantic branch name from your description and creates it automatically\n3. **Template-Based Generation**: Copies and customizes the feature specification template with your requirements\n4. **Directory Structure**: Creates the proper `specs/[branch-name]/` structure for all related documents\n\n### The `generate_plan` Command\n\nOnce a feature specification exists, this command creates a comprehensive implementation plan:\n\n1. **Specification Analysis**: Reads and understands the feature requirements, user stories, and acceptance criteria\n2. **Constitutional Compliance**: Ensures alignment with project constitution and architectural principles\n3. **Technical Translation**: Converts business requirements into technical architecture and implementation details\n4. **Detailed Documentation**: Generates supporting documents for data models, API contracts, and test scenarios\n5. **Manual Testing Plans**: Creates step-by-step validation procedures for each user story\n\n### Example: Building a Chat Feature\n\nHere's how these commands transform the traditional development workflow:\n\n**Traditional Approach:**\n```\n1. Write a PRD in a document (2-3 hours)\n2. Create design documents (2-3 hours)\n3. Set up project structure manually (30 minutes)\n4. Write technical specifications (3-4 hours)\n5. Create test plans (2 hours)\nTotal: ~12 hours of documentation work\n```\n\n**SDD with Commands Approach:**\n```bash\n# Step 1: Create the feature specification (5 minutes)\n/new_feature Real-time chat system with message history and user presence\n\n# This automatically:\n# - Creates branch \"003-chat-system\"\n# - Generates specs/003-chat-system/feature-spec.md\n# - Populates it with structured requirements\n\n# Step 2: Generate implementation plan (10 minutes)\n/generate_plan WebSocket for real-time messaging, PostgreSQL for history, Redis for presence\n\n# This automatically creates:\n# - specs/003-chat-system/implementation-plan.md\n# - specs/003-chat-system/implementation-details/\n#   - 00-research.md (WebSocket library comparisons)\n#   - 02-data-model.md (Message and User schemas)\n#   - 03-api-contracts.md (WebSocket events, REST endpoints)\n#   - 06-contract-tests.md (Message flow scenarios)\n#   - 08-inter-library-tests.md (Database-WebSocket integration)\n# - specs/003-chat-system/manual-testing.md\n```\n\nIn 15 minutes, you have:\n- A complete feature specification with user stories and acceptance criteria\n- A detailed implementation plan with technology choices and rationale\n- API contracts and data models ready for code generation\n- Comprehensive test scenarios for both automated and manual testing\n- All documents properly versioned in a feature branch\n\n### The Power of Structured Automation\n\nThese commands don't just save time\u2014they enforce consistency and completeness:\n\n1. **No Forgotten Details**: Templates ensure every aspect is considered, from non-functional requirements to error handling\n2. **Traceable Decisions**: Every technical choice links back to specific requirements\n3. **Living Documentation**: Specifications stay in sync with code because they generate it\n4. **Rapid Iteration**: Change requirements and regenerate plans in minutes, not days\n\nThe commands embody SDD principles by treating specifications as executable artifacts rather than static documents. They transform the specification process from a necessary evil into the driving force of development.\n\n### Template-Driven Quality: How Structure Constrains LLMs for Better Outcomes\n\nThe true power of these commands lies not just in automation, but in how the templates guide LLM behavior toward higher-quality specifications. The templates act as sophisticated prompts that constrain the LLM's output in productive ways:\n\n#### 1. **Preventing Premature Implementation Details**\n\nThe feature specification template explicitly instructs:\n```\n- \u2705 Focus on WHAT users need and WHY\n- \u274c Avoid HOW to implement (no tech stack, APIs, code structure)\n```\n\nThis constraint forces the LLM to maintain proper abstraction levels. When an LLM might naturally jump to \"implement using React with Redux,\" the template keeps it focused on \"users need real-time updates of their data.\" This separation ensures specifications remain stable even as implementation technologies change.\n\n#### 2. **Forcing Explicit Uncertainty Markers**\n\nBoth templates mandate the use of `[NEEDS CLARIFICATION]` markers:\n```\nWhen creating this spec from a user prompt:\n1. **Mark all ambiguities**: Use [NEEDS CLARIFICATION: specific question] \n2. **Don't guess**: If the prompt doesn't specify something, mark it\n```\n\nThis prevents the common LLM behavior of making plausible but potentially incorrect assumptions. Instead of guessing that a \"login system\" uses email/password authentication, the LLM must mark it as `[NEEDS CLARIFICATION: auth method not specified - email/password, SSO, OAuth?]`.\n\n#### 3. **Structured Thinking Through Checklists**\n\nThe templates include comprehensive checklists that act as \"unit tests\" for the specification:\n```\n### Requirement Completeness\n- [ ] No [NEEDS CLARIFICATION] markers remain\n- [ ] Requirements are testable and unambiguous  \n- [ ] Success criteria are measurable\n```\n\nThese checklists force the LLM to self-review its output systematically, catching gaps that might otherwise slip through. It's like giving the LLM a quality assurance framework.\n\n#### 4. **Constitutional Compliance Through Gates**\n\nThe implementation plan template enforces architectural principles through phase gates:\n```\n### Phase -1: Pre-Implementation Gates\n#### Simplicity Gate (Article VII)\n- [ ] Using \u22643 projects?\n- [ ] No future-proofing?\n#### Anti-Abstraction Gate (Article VIII)\n- [ ] Using framework directly?\n- [ ] Single model representation?\n```\n\nThese gates prevent over-engineering by making the LLM explicitly justify any complexity. If a gate fails, the LLM must document why in the \"Complexity Tracking\" section, creating accountability for architectural decisions.\n\n#### 5. **Hierarchical Detail Management**\n\nThe templates enforce proper information architecture:\n```\n**IMPORTANT**: This implementation plan should remain high-level and readable. \nAny code samples, detailed algorithms, or extensive technical specifications \nmust be placed in the appropriate `implementation-details/` file\n```\n\nThis prevents the common problem of specifications becoming unreadable code dumps. The LLM learns to maintain appropriate detail levels, extracting complexity to separate files while keeping the main document navigable.\n\n#### 6. **Test-First Thinking**\n\nThe implementation template enforces test-first development:\n```\n### File Creation Order\n1. Create `contracts/` with API specifications\n2. Create test files in order: contract \u2192 integration \u2192 e2e \u2192 unit\n3. Create source files to make tests pass\n```\n\nThis ordering constraint ensures the LLM thinks about testability and contracts before implementation, leading to more robust and verifiable specifications.\n\n#### 7. **Preventing Speculative Features**\n\nTemplates explicitly discourage speculation:\n```\n- [ ] No speculative or \"might need\" features\n- [ ] All phases have clear prerequisites and deliverables\n```\n\nThis stops the LLM from adding \"nice to have\" features that complicate implementation. Every feature must trace back to a concrete user story with clear acceptance criteria.\n\n### The Compound Effect\n\nThese constraints work together to produce specifications that are:\n- **Complete**: Checklists ensure nothing is forgotten\n- **Unambiguous**: Forced clarification markers highlight uncertainties\n- **Testable**: Test-first thinking baked into the process\n- **Maintainable**: Proper abstraction levels and information hierarchy\n- **Implementable**: Clear phases with concrete deliverables\n\nThe templates transform the LLM from a creative writer into a disciplined specification engineer, channeling its capabilities toward producing consistently high-quality, executable specifications that truly drive development.\n\n## The Constitutional Foundation: Enforcing Architectural Discipline\n\nAt the heart of SDD lies a constitution\u2014a set of immutable principles that govern how specifications become code. The constitution (`base/memory/constitution.md`) acts as the architectural DNA of the system, ensuring that every generated implementation maintains consistency, simplicity, and quality.\n\n### The Nine Articles of Development\n\nThe constitution defines nine articles that shape every aspect of the development process:\n\n#### Article I: Library-First Principle\nEvery feature must begin as a standalone library\u2014no exceptions. This forces modular design from the start:\n```\nEvery feature in Specify MUST begin its existence as a standalone library. \nNo feature shall be implemented directly within application code without \nfirst being abstracted into a reusable library component.\n```\n\nThis principle ensures that specifications generate modular, reusable code rather than monolithic applications. When the LLM generates an implementation plan, it must structure features as libraries with clear boundaries and minimal dependencies.\n\n#### Article II: CLI Interface Mandate\nEvery library must expose its functionality through a command-line interface:\n```\nAll CLI interfaces MUST:\n- Accept text as input (via stdin, arguments, or files)\n- Produce text as output (via stdout)\n- Support JSON format for structured data exchange\n```\n\nThis enforces observability and testability. The LLM cannot hide functionality inside opaque classes\u2014everything must be accessible and verifiable through text-based interfaces.\n\n#### Article III: Test-First Imperative\nThe most transformative article\u2014no code before tests:\n```\nThis is NON-NEGOTIABLE: All implementation MUST follow strict Test-Driven Development.\nNo implementation code shall be written before:\n1. Unit tests are written\n2. Tests are validated and approved by the user\n3. Tests are confirmed to FAIL (Red phase)\n```\n\nThis completely inverts traditional AI code generation. Instead of generating code and hoping it works, the LLM must first generate comprehensive tests that define behavior, get them approved, and only then generate implementation.\n\n#### Articles VII & VIII: Simplicity and Anti-Abstraction\nThese paired articles combat over-engineering:\n```\nSection 7.3: Minimal Project Structure\n- Maximum 3 projects for initial implementation\n- Additional projects require documented justification\n\nSection 8.1: Framework Trust\n- Use framework features directly rather than wrapping them\n```\n\nWhen an LLM might naturally create elaborate abstractions, these articles force it to justify every layer of complexity. The implementation plan template's \"Phase -1 Gates\" directly enforce these principles.\n\n#### Article IX: Integration-First Testing\nPrioritizes real-world testing over isolated unit tests:\n```\nTests MUST use realistic environments:\n- Prefer real databases over mocks\n- Use actual service instances over stubs\n- Contract tests mandatory before implementation\n```\n\nThis ensures generated code works in practice, not just in theory.\n\n### Constitutional Enforcement Through Templates\n\nThe implementation plan template operationalizes these articles through concrete checkpoints:\n\n```markdown\n### Phase -1: Pre-Implementation Gates\n#### Simplicity Gate (Article VII)\n- [ ] Using \u22643 projects?\n- [ ] No future-proofing?\n\n#### Anti-Abstraction Gate (Article VIII)\n- [ ] Using framework directly?\n- [ ] Single model representation?\n\n#### Integration-First Gate (Article IX)\n- [ ] Contracts defined?\n- [ ] Contract tests written?\n```\n\nThese gates act as compile-time checks for architectural principles. The LLM cannot proceed without either passing the gates or documenting justified exceptions in the \"Complexity Tracking\" section.\n\n### The Power of Immutable Principles\n\nThe constitution's power lies in its immutability. While implementation details can evolve, the core principles remain constant. This provides:\n\n1. **Consistency Across Time**: Code generated today follows the same principles as code generated next year\n2. **Consistency Across LLMs**: Different AI models produce architecturally compatible code\n3. **Architectural Integrity**: Every feature reinforces rather than undermines the system design\n4. **Quality Guarantees**: Test-first, library-first, and simplicity principles ensure maintainable code\n\n### Constitutional Evolution\n\nWhile principles are immutable, their application can evolve:\n```\nSection 4.2: Amendment Process\nModifications to this constitution require:\n- Explicit documentation of the rationale for change\n- Review and approval by project maintainers\n- Backwards compatibility assessment\n```\n\nThis allows the methodology to learn and improve while maintaining stability. The constitution shows its own evolution with dated amendments, demonstrating how principles can be refined based on real-world experience.\n\n### Beyond Rules: A Development Philosophy\n\nThe constitution isn't just a rulebook\u2014it's a philosophy that shapes how LLMs think about code generation:\n\n- **Observability Over Opacity**: Everything must be inspectable through CLI interfaces\n- **Simplicity Over Cleverness**: Start simple, add complexity only when proven necessary\n- **Integration Over Isolation**: Test in real environments, not artificial ones\n- **Modularity Over Monoliths**: Every feature is a library with clear boundaries\n\nBy embedding these principles into the specification and planning process, SDD ensures that generated code isn't just functional\u2014it's maintainable, testable, and architecturally sound. The constitution transforms AI from a code generator into an architectural partner that respects and reinforces system design principles.\n\n## The Transformation\n\nThis isn't about replacing developers or automating creativity. It's about amplifying human capability by automating mechanical translation. It's about creating a tight feedback loop where specifications, research, and code evolve together, each iteration bringing deeper understanding and better alignment between intent and implementation.\n\nSoftware development needs better tools for maintaining alignment between intent and implementation. SDD provides the methodology for achieving this alignment through executable specifications that generate code rather than merely guiding it.",
        "headings": [
          "# Specification-Driven Development (SDD)",
          "## The Power Inversion",
          "## The SDD Workflow in Practice",
          "## Why SDD Matters Now",
          "## Core Principles",
          "## Implementation Approaches",
          "## Streamlining SDD with Claude Commands",
          "### The `new_feature` Command",
          "### The `generate_plan` Command",
          "### Example: Building a Chat Feature",
          "# Step 1: Create the feature specification (5 minutes)",
          "# This automatically:",
          "# - Creates branch \"003-chat-system\"",
          "# - Generates specs/003-chat-system/feature-spec.md",
          "# - Populates it with structured requirements",
          "# Step 2: Generate implementation plan (10 minutes)",
          "# This automatically creates:",
          "# - specs/003-chat-system/implementation-plan.md",
          "# - specs/003-chat-system/implementation-details/",
          "#   - 00-research.md (WebSocket library comparisons)",
          "#   - 02-data-model.md (Message and User schemas)",
          "#   - 03-api-contracts.md (WebSocket events, REST endpoints)",
          "#   - 06-contract-tests.md (Message flow scenarios)",
          "#   - 08-inter-library-tests.md (Database-WebSocket integration)",
          "# - specs/003-chat-system/manual-testing.md",
          "### The Power of Structured Automation",
          "### Template-Driven Quality: How Structure Constrains LLMs for Better Outcomes",
          "#### 1. **Preventing Premature Implementation Details**",
          "#### 2. **Forcing Explicit Uncertainty Markers**",
          "#### 3. **Structured Thinking Through Checklists**",
          "### Requirement Completeness",
          "#### 4. **Constitutional Compliance Through Gates**",
          "### Phase -1: Pre-Implementation Gates",
          "#### Simplicity Gate (Article VII)",
          "#### Anti-Abstraction Gate (Article VIII)",
          "#### 5. **Hierarchical Detail Management**",
          "#### 6. **Test-First Thinking**",
          "### File Creation Order",
          "#### 7. **Preventing Speculative Features**",
          "### The Compound Effect",
          "## The Constitutional Foundation: Enforcing Architectural Discipline",
          "### The Nine Articles of Development",
          "#### Article I: Library-First Principle",
          "#### Article II: CLI Interface Mandate",
          "#### Article III: Test-First Imperative",
          "#### Articles VII & VIII: Simplicity and Anti-Abstraction",
          "#### Article IX: Integration-First Testing",
          "### Constitutional Enforcement Through Templates",
          "### Phase -1: Pre-Implementation Gates",
          "#### Simplicity Gate (Article VII)",
          "#### Anti-Abstraction Gate (Article VIII)",
          "#### Integration-First Gate (Article IX)",
          "### The Power of Immutable Principles",
          "### Constitutional Evolution",
          "### Beyond Rules: A Development Philosophy",
          "## The Transformation"
        ],
        "word_count": 3280
      },
      "CONTRIBUTING.md": {
        "content": "## Contributing to Spec Kit\n\nHi there! We're thrilled that you'd like to contribute to Spec Kit. Contributions to this project are [released](https://help.github.com/articles/github-terms-of-service/#6-contributions-under-repository-license) to the public under the [project's open source license](LICENSE).\n\nPlease note that this project is released with a [Contributor Code of Conduct](CODE_OF_CONDUCT.md). By participating in this project you agree to abide by its terms.\n\n## Prerequisites for running and testing code\n\nThese are one time installations required to be able to test your changes locally as part of the pull request (PR) submission process.\n\n1. Install [Python 3.11+](https://www.python.org/downloads/)\n1. Install [uv](https://docs.astral.sh/uv/) for package management\n1. Install [Git](https://git-scm.com/downloads)\n1. Have an AI coding agent available: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n\n## Submitting a pull request\n\n1. Fork and clone the repository\n1. Configure and install the dependencies: `uv sync`\n1. Make sure the CLI works on your machine: `uv run specify --help`\n1. Create a new branch: `git checkout -b my-branch-name`\n1. Make your change, add tests, and make sure everything still works\n1. Test the CLI functionality with a sample project if relevant\n1. Push to your fork and submit a pull request\n1. Wait for your pull request to be reviewed and merged.\n\nHere are a few things you can do that will increase the likelihood of your pull request being accepted:\n\n- Follow the project's coding conventions.\n- Write tests for new functionality.\n- Update documentation (`README.md,` `spec-driven.md`) if your changes affect user-facing features.\n- Keep your change as focused as possible. If there are multiple changes you would like to make that are not dependent upon each other, consider submitting them as separate pull requests.\n- Write a [good commit message](http://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html).\n- Test your changes with the Spec-Driven Development workflow to ensure compatibility.\n\n## Development workflow\n\nWhen working on spec-kit:\n\n1. Test changes with the `specify` CLI commands (`/specify`, `/plan`, `/tasks`) in your coding agent of choice\n2. Verify templates are working correctly in `templates/` directory\n3. Test script functionality in the `scripts/` directory\n4. Ensure memory files (`memory/constitution.md`) are updated if major process changes are made\n\n## Resources\n\n- [Spec-Driven Development Methodology](./spec-driven.md)\n- [How to Contribute to Open Source](https://opensource.guide/how-to-contribute/)\n- [Using Pull Requests](https://help.github.com/articles/about-pull-requests/)\n- [GitHub Help](https://help.github.com)\n",
        "headings": [
          "## Contributing to Spec Kit",
          "## Prerequisites for running and testing code",
          "## Submitting a pull request",
          "## Development workflow",
          "## Resources"
        ],
        "word_count": 365
      },
      "ONBOARDING.md": {
        "content": "# Onboarding Existing Projects to Spec-Driven Development\n\nThe Spec-Kit MCP server provides powerful tools to onboard existing projects to a spec-driven development workflow. This includes both complete project onboarding and progressive onboarding for incremental adoption across teams and features.\n\n## Overview\n\nThe Spec-Kit MCP server supports two onboarding approaches:\n\n### Complete Project Onboarding\nFor migrating entire projects at once. This approach:\n- Analyzes complete project structures and codebases\n- Extracts requirements and specifications from documentation and code\n- Generates standardized specifications following Spec-Kit format\n- Creates detailed migration plans for adopting spec-driven development\n- Performs complete end-to-end onboarding analysis\n\n### Progressive Onboarding (NEW)\nFor incremental adoption by different teams, features, or sub-projects. This approach:\n- Enables feature-level and component-level onboarding\n- Supports multiple teams working on different parts independently\n- Provides specification assembly and coordination tools\n- Manages dependencies between features during progressive migration\n- Tracks progress across multiple onboarding efforts\n\n## MCP Tools Overview\n\n### Complete Project Onboarding Tools\n\n#### 1. `analyze_existing_project`\nAnalyzes the structure of an existing project to understand its organization.\n\n**Parameters:**\n- `project_path` (required): Path to the existing project directory\n- `max_depth` (optional): Maximum directory depth to scan (default: 3)\n\n#### 2. `parse_existing_documentation`\nParses existing documentation files to extract requirements and specifications.\n\n**Parameters:**\n- `project_path` (required): Path to the project directory\n- `file_patterns` (optional): List of file patterns to search for\n\n#### 3. `extract_requirements_from_code`\nExtracts requirements from code comments, docstrings, and TODO/FIXME items.\n\n**Parameters:**\n- `project_path` (required): Path to the project directory\n- `file_patterns` (optional): List of file patterns to search for\n\n#### 4. `generate_standardized_spec`\nGenerates a standardized specification from existing project analysis.\n\n**Parameters:**\n- `project_analysis` (required): Result from `analyze_existing_project`\n- `documentation_analysis` (required): Result from `parse_existing_documentation`\n- `code_analysis` (required): Result from `extract_requirements_from_code`\n\n#### 5. `create_migration_plan`\nCreates a detailed migration plan for adopting spec-driven development.\n\n**Parameters:**\n- `project_analysis` (required): Result from `analyze_existing_project`\n- `standardized_spec` (required): Result from `generate_standardized_spec`\n\n#### 6. `onboard_existing_project`\nComplete end-to-end onboarding (combines all analysis steps).\n\n**Parameters:**\n- `project_path` (required): Path to the existing project directory\n- `max_depth` (optional): Maximum directory depth to scan (default: 3)\n- `include_migration_plan` (optional): Whether to include migration plan (default: true)\n\n### Progressive Onboarding Tools (NEW)\n\n#### 7. `analyze_feature_component`\nAnalyzes a specific feature or component within a project for progressive onboarding.\n\n**Parameters:**\n- `project_path` (required): Path to the main project directory\n- `feature_path` (required): Relative path to the feature/component within the project\n- `max_depth` (optional): Maximum directory depth to scan within the feature (default: 2)\n\n**Returns:** Feature-specific analysis including:\n- File counts and complexity estimation\n- Languages and frameworks detected\n- Dependencies and external references\n- Test coverage and documentation status\n- Integration points and potential boundaries\n\n#### 8. `extract_feature_boundaries`\nIdentifies logical feature boundaries within a project to support progressive onboarding.\n\n**Parameters:**\n- `project_path` (required): Path to the project directory\n- `analysis_depth` (optional): Depth to analyze for feature boundaries (default: 2)\n\n**Returns:** Feature boundary analysis including:\n- Suggested feature candidates\n- Confidence scores and reasoning\n- Boundary criteria used\n- Sub-feature identification\n\n#### 9. `onboard_project_feature`\nOnboards a specific feature to spec-driven development with dependency analysis.\n\n**Parameters:**\n- `project_path` (required): Path to the main project directory\n- `feature_path` (required): Relative path to the feature within the project\n- `include_dependencies` (optional): Whether to analyze feature dependencies (default: true)\n\n**Returns:** Complete feature onboarding including:\n- Feature-specific specification\n- Dependency analysis and integration points\n- Implementation recommendations\n- Readiness assessment\n\n#### 10. `merge_feature_specifications`\nMerges multiple feature specifications into a master specification.\n\n**Parameters:**\n- `feature_specifications` (required): List of feature specification dictionaries to merge\n- `master_project_info` (optional): Master project information for context\n\n**Returns:** Merged specification including:\n- Consolidated requirements and user stories\n- Integrated technical stack\n- Cross-feature coordination notes\n- Assembly metadata and conflict information\n\n#### 11. `detect_specification_conflicts`\nDetects conflicts between multiple feature specifications.\n\n**Parameters:**\n- `feature_specifications` (required): List of feature specification dictionaries to analyze\n\n**Returns:** Conflict analysis including:\n- API endpoint conflicts\n- Requirement conflicts\n- Technology stack conflicts\n- Resolution suggestions\n\n#### 12. `resolve_feature_dependencies`\nAnalyzes and documents dependencies between features.\n\n**Parameters:**\n- `feature_specifications` (required): List of feature specification dictionaries to analyze\n\n**Returns:** Dependency analysis including:\n- Dependency graph and relationships\n- Circular dependency detection\n- Critical dependency identification\n- Implementation order suggestions\n- Resolution plan\n\n#### 13. `create_progressive_migration_plan`\nCreates a progressive migration plan for incremental adoption of spec-driven development.\n\n**Parameters:**\n- `project_path` (required): Path to the project directory\n- `feature_boundaries` (required): Result from `extract_feature_boundaries`\n- `priority_features` (optional): List of features to prioritize\n\n**Returns:** Progressive migration plan including:\n- Phased migration approach\n- Resource allocation and timeline estimates\n- Success metrics and risk mitigation\n- Coordination plan for multiple teams\n\n#### 14. `track_onboarding_progress`\nTracks progress of progressive onboarding migration.\n\n**Parameters:**\n- `project_path` (required): Path to the project directory\n- `migration_plan` (required): Result from `create_progressive_migration_plan`\n- `completed_features` (optional): List of features that have been completed\n\n**Returns:** Progress tracking including:\n- Overall and phase-wise progress\n- Feature status tracking\n- Next actions and recommendations\n- Blocker identification\n\n#### 15. `validate_specification_consistency`\nValidates consistency across multiple feature specifications.\n\n**Parameters:**\n- `feature_specifications` (required): List of feature specification dictionaries to validate\n\n**Returns:** Consistency validation including:\n- Format and naming consistency checks\n- Requirement and technical consistency\n- Inconsistency identification\n- Improvement recommendations\n\n## Usage Examples\n\n### Complete Project Onboarding\n\n#### Basic Project Analysis\n```javascript\n// Analyze an existing project structure\nconst analysis = await mcpClient.callTool(\"analyze_existing_project\", {\n  project_path: \"/path/to/your/project\",\n  max_depth: 3\n});\n```\n\n#### Parse Documentation\n```javascript\n// Extract requirements from documentation\nconst docs = await mcpClient.callTool(\"parse_existing_documentation\", {\n  project_path: \"/path/to/your/project\",\n  file_patterns: [\"*.md\", \"README*\", \"docs/**/*\"]\n});\n```\n\n#### Complete Onboarding\n```javascript\n// Perform complete end-to-end onboarding\nconst onboarding = await mcpClient.callTool(\"onboard_existing_project\", {\n  project_path: \"/path/to/your/project\",\n  max_depth: 2,\n  include_migration_plan: true\n});\n\nconsole.log(\"Project:\", onboarding.summary.project_name);\nconsole.log(\"Size:\", onboarding.summary.estimated_size);\nconsole.log(\"Languages:\", onboarding.summary.languages);\nconsole.log(\"Next steps:\", onboarding.summary.next_steps);\n```\n\n### Progressive Onboarding Workflow (NEW)\n\n#### Step 1: Identify Feature Boundaries\n```javascript\n// Discover logical feature boundaries in your project\nconst boundaries = await mcpClient.callTool(\"extract_feature_boundaries\", {\n  project_path: \"/path/to/your/project\",\n  analysis_depth: 2\n});\n\n// Review suggested features\nboundaries.suggested_features.forEach(feature => {\n  console.log(`Feature: ${feature.feature_name}`);\n  console.log(`Confidence: ${feature.confidence_score}`);\n  console.log(`Reasons: ${feature.reasons.join(', ')}`);\n});\n```\n\n#### Step 2: Analyze Individual Features\n```javascript\n// Analyze a specific feature component\nconst featureAnalysis = await mcpClient.callTool(\"analyze_feature_component\", {\n  project_path: \"/path/to/your/project\",\n  feature_path: \"src/user-management\",\n  max_depth: 2\n});\n\nconsole.log(`Feature complexity: ${featureAnalysis.estimated_complexity}`);\nconsole.log(`External dependencies: ${featureAnalysis.external_references.length}`);\n```\n\n#### Step 3: Onboard Features Progressively\n```javascript\n// Onboard individual features\nconst featureOnboarding = await mcpClient.callTool(\"onboard_project_feature\", {\n  project_path: \"/path/to/your/project\",\n  feature_path: \"src/user-management\",\n  include_dependencies: true\n});\n\nconsole.log(`Feature readiness: ${featureOnboarding.summary.ready_for_spec_driven}`);\n```\n\n#### Step 4: Create Progressive Migration Plan\n```javascript\n// Create a phased migration plan\nconst migrationPlan = await mcpClient.callTool(\"create_progressive_migration_plan\", {\n  project_path: \"/path/to/your/project\",\n  feature_boundaries: boundaries,\n  priority_features: [\"user-management\", \"core-api\"]\n});\n\n// Review migration phases\nmigrationPlan.migration_phases.forEach(phase => {\n  console.log(`Phase ${phase.phase}: ${phase.name}`);\n  console.log(`Duration: ${phase.duration}`);\n  console.log(`Features: ${phase.features.join(', ')}`);\n});\n```\n\n#### Step 5: Track Progress\n```javascript\n// Track onboarding progress\nconst progress = await mcpClient.callTool(\"track_onboarding_progress\", {\n  project_path: \"/path/to/your/project\",\n  migration_plan: migrationPlan,\n  completed_features: [\"user-management\"]\n});\n\nconsole.log(`Overall progress: ${progress.overall_progress.completion_percentage}%`);\nconsole.log(`Next actions:`, progress.next_actions);\n```\n\n#### Step 6: Merge Feature Specifications\n```javascript\n// Once multiple features are onboarded, merge their specifications\nconst mergedSpec = await mcpClient.callTool(\"merge_feature_specifications\", {\n  feature_specifications: [\n    featureOnboarding1.feature_specification,\n    featureOnboarding2.feature_specification,\n    featureOnboarding3.feature_specification\n  ],\n  master_project_info: {\n    project_name: \"MyApplication\",\n    description: \"Multi-feature application\"\n  }\n});\n```\n\n#### Step 7: Validate Consistency\n```javascript\n// Validate consistency across feature specifications\nconst validation = await mcpClient.callTool(\"validate_specification_consistency\", {\n  feature_specifications: [\n    featureSpec1,\n    featureSpec2,\n    featureSpec3\n  ]\n});\n\nconsole.log(`Consistency score: ${validation.consistency_score}`);\nconsole.log(`Status: ${validation.overall_status}`);\nconsole.log(`Recommendations:`, validation.recommendations);\n```\n\n#### Step 8: Detect and Resolve Conflicts\n```javascript\n// Detect conflicts between feature specifications\nconst conflicts = await mcpClient.callTool(\"detect_specification_conflicts\", {\n  feature_specifications: [featureSpec1, featureSpec2, featureSpec3]\n});\n\nif (conflicts.conflicts.length > 0) {\n  console.log(\"Conflicts detected:\");\n  conflicts.conflicts.forEach(conflict => {\n    console.log(`- ${conflict.type}: ${conflict.description}`);\n  });\n}\n\n// Analyze feature dependencies\nconst dependencies = await mcpClient.callTool(\"resolve_feature_dependencies\", {\n  feature_specifications: [featureSpec1, featureSpec2, featureSpec3]\n});\n\nconsole.log(\"Suggested implementation order:\", dependencies.implementation_order);\n```\n\n## Migration Workflows\n\n### Complete Project Migration Workflow\n\nThe typical workflow for onboarding an entire existing project is:\n\n1. **Initial Analysis**: Use `analyze_existing_project` to understand the project structure\n2. **Documentation Review**: Use `parse_existing_documentation` to extract existing requirements\n3. **Code Analysis**: Use `extract_requirements_from_code` to find additional requirements\n4. **Specification Generation**: Use `generate_standardized_spec` to create a Spec-Kit compatible specification\n5. **Migration Planning**: Use `create_migration_plan` to create a detailed migration roadmap\n\nOr simply use `onboard_existing_project` for a complete end-to-end analysis.\n\n### Progressive Onboarding Workflow (NEW)\n\nThe progressive onboarding workflow supports incremental adoption across teams and features:\n\n#### Phase 1: Discovery and Planning\n1. **Feature Identification**: Use `extract_feature_boundaries` to identify logical features\n2. **Feature Prioritization**: Select which features to onboard first based on:\n   - Team readiness and availability\n   - Feature complexity and dependencies\n   - Business priority and impact\n3. **Progressive Planning**: Use `create_progressive_migration_plan` to create a phased approach\n\n#### Phase 2: Feature-Level Onboarding\n1. **Feature Analysis**: Use `analyze_feature_component` for each selected feature\n2. **Feature Onboarding**: Use `onboard_project_feature` to create feature specifications\n3. **Dependency Analysis**: Use `resolve_feature_dependencies` to understand inter-feature relationships\n4. **Conflict Detection**: Use `detect_specification_conflicts` to identify potential issues early\n\n#### Phase 3: Integration and Coordination\n1. **Specification Merging**: Use `merge_feature_specifications` to create master specifications\n2. **Consistency Validation**: Use `validate_specification_consistency` to ensure coherence\n3. **Progress Tracking**: Use `track_onboarding_progress` to monitor overall advancement\n4. **Continuous Refinement**: Iterate based on feedback and lessons learned\n\n#### Phase 4: Scaling and Optimization\n1. **Team Coordination**: Establish cross-team processes for specification management\n2. **Workflow Integration**: Integrate spec-driven development into regular team workflows\n3. **Continuous Improvement**: Regular reviews and optimization of the progressive process\n4. **Knowledge Sharing**: Document and share best practices across teams\n\n## Migration Approaches Comparison\n\n| Aspect | Complete Migration | Progressive Migration |\n|--------|-------------------|----------------------|\n| **Timeline** | 2-4 months | 3-8 months |\n| **Risk** | Higher (all-or-nothing) | Lower (incremental) |\n| **Resource Requirements** | High initial commitment | Distributed over time |\n| **Team Impact** | Significant disruption | Minimal disruption |\n| **Flexibility** | Limited once started | High adaptability |\n| **Coordination Complexity** | Medium | Higher |\n| **Early Value** | Delayed | Immediate for early features |\n| **Best For** | Small teams, simple projects | Large teams, complex projects |\n\n## Migration Phases\n\n### Complete Project Migration Phases\n\nThe migration plan includes these standard phases:\n\n1. **Assessment and Planning** (1-2 weeks): Complete analysis and roadmap creation\n2. **Specification Creation** (2-4 weeks): Comprehensive project specification development\n3. **Process Integration** (2-3 weeks): Integrate spec-driven processes into workflow\n4. **Pilot Implementation** (3-4 weeks): Pilot new approach with selected features\n5. **Full Adoption** (Ongoing): Complete transition to spec-driven development\n\n### Progressive Migration Phases\n\nProgressive migration typically follows these phases:\n\n1. **Pilot Migration** (2-3 weeks): Start with 1-2 simple features\n   - Establish spec-driven workflow\n   - Train team on new process\n   - Validate tooling and templates\n   - Gather initial feedback\n\n2. **Progressive Expansion** (3-4 weeks per batch): Add more features gradually\n   - Apply spec-driven process to additional features\n   - Refine and optimize workflow\n   - Address integration challenges\n   - Build team expertise\n\n3. **Integration and Optimization** (2-3 weeks): Integrate all features\n   - Create master specification\n   - Resolve cross-feature dependencies\n   - Optimize development workflow\n   - Establish maintenance procedures\n\n## Best Practices\n\n### Complete Project Onboarding\n- **Start with Analysis**: Always begin with a thorough project analysis\n- **Review Results**: Manually review and validate extracted requirements\n- **Fill Gaps**: Address any gaps identified in the analysis\n- **Stakeholder Validation**: Validate specifications with project stakeholders\n- **Full Migration**: Follow the phased approach for complete transition\n- **Team Training**: Ensure team is trained on spec-driven development methodology\n\n### Progressive Onboarding (NEW)\n- **Start Small**: Begin with 1-2 simple, well-defined features to build confidence\n- **Choose Pilot Features Wisely**: Select features that are:\n  - Relatively independent\n  - Well-understood by the team\n  - Have clear boundaries\n  - Lower complexity and risk\n- **Establish Team Champions**: Identify team members who can drive adoption in each feature area\n- **Regular Coordination**: Set up regular sync meetings between feature teams\n- **Document Lessons Learned**: Capture insights and improvements for subsequent features\n- **Iterative Improvement**: Continuously refine the process based on feedback\n- **Dependency Management**: Analyze and plan for inter-feature dependencies early\n- **Conflict Resolution**: Address specification conflicts promptly\n- **Progress Visibility**: Maintain clear visibility into overall migration progress\n\n### Team Coordination for Progressive Onboarding\n- **Clear Ownership**: Establish clear ownership for each feature specification\n- **Interface Contracts**: Define clear interfaces between features early\n- **Regular Reviews**: Implement regular cross-feature specification reviews\n- **Shared Standards**: Establish and maintain shared specification standards\n- **Communication Channels**: Set up dedicated channels for coordination\n- **Decision Making**: Define clear decision-making processes for cross-feature issues\n\n### Feature Selection Strategies\n- **Complexity-First**: Start with simpler features to build momentum\n- **Value-First**: Prioritize features that deliver business value quickly\n- **Dependency-First**: Start with features that others depend on\n- **Team-First**: Begin with teams most ready and motivated for change\n- **Risk-First**: Address highest-risk features early when resources are fresh\n\n### Common Pitfalls to Avoid\n- **Over-Ambitious Scope**: Don't try to onboard too many features simultaneously\n- **Insufficient Coordination**: Neglecting cross-feature coordination leads to conflicts\n- **Specification Drift**: Allowing quality and consistency to degrade over time\n- **Resource Competition**: Teams competing for limited migration resources\n- **Communication Gaps**: Poor communication between feature teams and stakeholders\n- **Process Rigidity**: Being too rigid about process when flexibility is needed\n\n## Supported File Types\n\nThe onboarding tools support analysis of:\n\n**Documentation:**\n- Markdown files (*.md)\n- README files\n- Text files (*.txt, *.rst)\n- Documentation directories\n\n**Code:**\n- Python (*.py)\n- JavaScript/TypeScript (*.js, *.ts)\n- Java (*.java)\n- C# (*.cs)\n- C/C++ (*.c, *.cpp, *.h, *.hpp)\n- Configuration files (package.json, pyproject.toml, etc.)\n\n**Configuration:**\n- YAML/JSON files\n- Docker files\n- CI/CD configurations (.github, .gitlab)\n- Build configurations (Makefile, etc.)\n\n## Troubleshooting\n\n**Large Projects**: For very large projects, consider:\n- Reducing `max_depth` parameter\n- Using specific `file_patterns` to focus analysis\n- Running analysis on project subsections\n\n**Analysis Timeouts**: If analysis takes too long:\n- Exclude large directories (node_modules, .git, etc.)\n- Use more specific file patterns\n- Analyze project sections separately\n\n**Missing Requirements**: If few requirements are found:\n- Check documentation file patterns\n- Review file naming conventions\n- Manually supplement with stakeholder interviews\n\n## Integration with Existing Workflow\n\nBoth complete and progressive onboarding tools integrate seamlessly with existing Spec-Kit workflows:\n\n### Standard Integration\n- Generated specifications use standard Spec-Kit templates\n- Migration plans align with Spec-Kit methodology\n- Output formats are compatible with existing tools\n- Can be used alongside `init_project` for hybrid approaches\n\n### Progressive Integration (NEW)\n- **Feature-Level Branching**: Each feature can have its own specification branch\n- **Incremental Documentation**: Build documentation incrementally as features are onboarded\n- **Gradual Process Adoption**: Teams can adopt spec-driven practices at their own pace\n- **Cross-Feature Coordination**: Tools support coordination between independently onboarded features\n- **Specification Assembly**: Multiple feature specifications can be merged into master specifications\n- **Continuous Integration**: Progress tracking integrates with existing project management tools\n\n### Enterprise Integration\n- **Multi-Team Support**: Tools designed for organizations with multiple development teams\n- **Governance Integration**: Supports integration with existing architecture and governance processes\n- **Compliance**: Progressive approach helps maintain compliance during transition\n- **Risk Management**: Incremental approach reduces risk compared to big-bang migrations\n- **Resource Planning**: Better resource allocation across teams and time periods\n\nThis enables organizations to adopt spec-driven development for both new and existing projects using a consistent approach and toolset, while accommodating different team needs and organizational constraints.",
        "headings": [
          "# Onboarding Existing Projects to Spec-Driven Development",
          "## Overview",
          "### Complete Project Onboarding",
          "### Progressive Onboarding (NEW)",
          "## MCP Tools Overview",
          "### Complete Project Onboarding Tools",
          "#### 1. `analyze_existing_project`",
          "#### 2. `parse_existing_documentation`",
          "#### 3. `extract_requirements_from_code`",
          "#### 4. `generate_standardized_spec`",
          "#### 5. `create_migration_plan`",
          "#### 6. `onboard_existing_project`",
          "### Progressive Onboarding Tools (NEW)",
          "#### 7. `analyze_feature_component`",
          "#### 8. `extract_feature_boundaries`",
          "#### 9. `onboard_project_feature`",
          "#### 10. `merge_feature_specifications`",
          "#### 11. `detect_specification_conflicts`",
          "#### 12. `resolve_feature_dependencies`",
          "#### 13. `create_progressive_migration_plan`",
          "#### 14. `track_onboarding_progress`",
          "#### 15. `validate_specification_consistency`",
          "## Usage Examples",
          "### Complete Project Onboarding",
          "#### Basic Project Analysis",
          "#### Parse Documentation",
          "#### Complete Onboarding",
          "### Progressive Onboarding Workflow (NEW)",
          "#### Step 1: Identify Feature Boundaries",
          "#### Step 2: Analyze Individual Features",
          "#### Step 3: Onboard Features Progressively",
          "#### Step 4: Create Progressive Migration Plan",
          "#### Step 5: Track Progress",
          "#### Step 6: Merge Feature Specifications",
          "#### Step 7: Validate Consistency",
          "#### Step 8: Detect and Resolve Conflicts",
          "## Migration Workflows",
          "### Complete Project Migration Workflow",
          "### Progressive Onboarding Workflow (NEW)",
          "#### Phase 1: Discovery and Planning",
          "#### Phase 2: Feature-Level Onboarding",
          "#### Phase 3: Integration and Coordination",
          "#### Phase 4: Scaling and Optimization",
          "## Migration Approaches Comparison",
          "## Migration Phases",
          "### Complete Project Migration Phases",
          "### Progressive Migration Phases",
          "## Best Practices",
          "### Complete Project Onboarding",
          "### Progressive Onboarding (NEW)",
          "### Team Coordination for Progressive Onboarding",
          "### Feature Selection Strategies",
          "### Common Pitfalls to Avoid",
          "## Supported File Types",
          "## Troubleshooting",
          "## Integration with Existing Workflow",
          "### Standard Integration",
          "### Progressive Integration (NEW)",
          "### Enterprise Integration"
        ],
        "word_count": 2492
      },
      "SECURITY.md": {
        "content": "Thanks for helping make GitHub safe for everyone.\n\n# Security\n\nGitHub takes the security of our software products and services seriously, including all of the open source code repositories managed through our GitHub organizations, such as [GitHub](https://github.com/GitHub).\n\nEven though [open source repositories are outside of the scope of our bug bounty program](https://bounty.github.com/index.html#scope) and therefore not eligible for bounty rewards, we will ensure that your finding gets passed along to the appropriate maintainers for remediation. \n\n## Reporting Security Issues\n\nIf you believe you have found a security vulnerability in any GitHub-owned repository, please report it to us through coordinated disclosure.\n\n**Please do not report security vulnerabilities through public GitHub issues, discussions, or pull requests.**\n\nInstead, please send an email to opensource-security[@]github.com.\n\nPlease include as much of the information listed below as you can to help us better understand and resolve the issue:\n\n  * The type of issue (e.g., buffer overflow, SQL injection, or cross-site scripting)\n  * Full paths of source file(s) related to the manifestation of the issue\n  * The location of the affected source code (tag/branch/commit or direct URL)\n  * Any special configuration required to reproduce the issue\n  * Step-by-step instructions to reproduce the issue\n  * Proof-of-concept or exploit code (if possible)\n  * Impact of the issue, including how an attacker might exploit the issue\n\nThis information will help us triage your report more quickly.\n\n## Policy\n\nSee [GitHub's Safe Harbor Policy](https://docs.github.com/en/site-policy/security-policies/github-bug-bounty-program-legal-safe-harbor#1-safe-harbor-terms)",
        "headings": [
          "# Security",
          "## Reporting Security Issues",
          "## Policy"
        ],
        "word_count": 232
      },
      "CODE_OF_CONDUCT.md": {
        "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, gender identity and expression, level of experience,\nnationality, personal appearance, race, religion, or sexual identity and\norientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\nadvances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at <opensource@github.com>. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at [http://contributor-covenant.org/version/1/4][version]\n\n[homepage]: http://contributor-covenant.org\n[version]: http://contributor-covenant.org/version/1/4/",
        "headings": [
          "# Contributor Covenant Code of Conduct",
          "## Our Pledge",
          "## Our Standards",
          "## Our Responsibilities",
          "## Scope",
          "## Enforcement",
          "## Attribution"
        ],
        "word_count": 446
      },
      "memory/constitution_update_checklist.md": {
        "content": "# Constitution Update Checklist\n\nWhen amending the constitution (`/memory/constitution.md`), ensure all dependent documents are updated to maintain consistency.\n\n## Templates to Update\n\n### When adding/modifying ANY article:\n- [ ] `/templates/plan-template.md` - Update Constitution Check section\n- [ ] `/templates/spec-template.md` - Update if requirements/scope affected\n- [ ] `/templates/tasks-template.md` - Update if new task types needed\n- [ ] `/.claude/commands/plan.md` - Update if planning process changes\n- [ ] `/.claude/commands/tasks.md` - Update if task generation affected\n- [ ] `/CLAUDE.md` - Update runtime development guidelines\n\n### Article-specific updates:\n\n#### Article I (Library-First):\n- [ ] Ensure templates emphasize library creation\n- [ ] Update CLI command examples\n- [ ] Add llms.txt documentation requirements\n\n#### Article II (CLI Interface):\n- [ ] Update CLI flag requirements in templates\n- [ ] Add text I/O protocol reminders\n\n#### Article III (Test-First):\n- [ ] Update test order in all templates\n- [ ] Emphasize TDD requirements\n- [ ] Add test approval gates\n\n#### Article IV (Integration Testing):\n- [ ] List integration test triggers\n- [ ] Update test type priorities\n- [ ] Add real dependency requirements\n\n#### Article V (Observability):\n- [ ] Add logging requirements to templates\n- [ ] Include multi-tier log streaming\n- [ ] Update performance monitoring sections\n\n#### Article VI (Versioning):\n- [ ] Add version increment reminders\n- [ ] Include breaking change procedures\n- [ ] Update migration requirements\n\n#### Article VII (Simplicity):\n- [ ] Update project count limits\n- [ ] Add pattern prohibition examples\n- [ ] Include YAGNI reminders\n\n## Validation Steps\n\n1. **Before committing constitution changes:**\n   - [ ] All templates reference new requirements\n   - [ ] Examples updated to match new rules\n   - [ ] No contradictions between documents\n\n2. **After updating templates:**\n   - [ ] Run through a sample implementation plan\n   - [ ] Verify all constitution requirements addressed\n   - [ ] Check that templates are self-contained (readable without constitution)\n\n3. **Version tracking:**\n   - [ ] Update constitution version number\n   - [ ] Note version in template footers\n   - [ ] Add amendment to constitution history\n\n## Common Misses\n\nWatch for these often-forgotten updates:\n- Command documentation (`/commands/*.md`)\n- Checklist items in templates\n- Example code/commands\n- Domain-specific variations (web vs mobile vs CLI)\n- Cross-references between documents\n\n## Template Sync Status\n\nLast sync check: 2025-07-16\n- Constitution version: 2.1.1\n- Templates aligned: \u274c (missing versioning, observability details)\n\n---\n\n*This checklist ensures the constitution's principles are consistently applied across all project documentation.*",
        "headings": [
          "# Constitution Update Checklist",
          "## Templates to Update",
          "### When adding/modifying ANY article:",
          "### Article-specific updates:",
          "#### Article I (Library-First):",
          "#### Article II (CLI Interface):",
          "#### Article III (Test-First):",
          "#### Article IV (Integration Testing):",
          "#### Article V (Observability):",
          "#### Article VI (Versioning):",
          "#### Article VII (Simplicity):",
          "## Validation Steps",
          "## Common Misses",
          "## Template Sync Status"
        ],
        "word_count": 418
      },
      "memory/constitution.md": {
        "content": "# [PROJECT_NAME] Constitution\n<!-- Example: Spec Constitution, TaskFlow Constitution, etc. -->\n\n## Core Principles\n\n### [PRINCIPLE_1_NAME]\n<!-- Example: I. Library-First -->\n[PRINCIPLE_1_DESCRIPTION]\n<!-- Example: Every feature starts as a standalone library; Libraries must be self-contained, independently testable, documented; Clear purpose required - no organizational-only libraries -->\n\n### [PRINCIPLE_2_NAME]\n<!-- Example: II. CLI Interface -->\n[PRINCIPLE_2_DESCRIPTION]\n<!-- Example: Every library exposes functionality via CLI; Text in/out protocol: stdin/args \u2192 stdout, errors \u2192 stderr; Support JSON + human-readable formats -->\n\n### [PRINCIPLE_3_NAME]\n<!-- Example: III. Test-First (NON-NEGOTIABLE) -->\n[PRINCIPLE_3_DESCRIPTION]\n<!-- Example: TDD mandatory: Tests written \u2192 User approved \u2192 Tests fail \u2192 Then implement; Red-Green-Refactor cycle strictly enforced -->\n\n### [PRINCIPLE_4_NAME]\n<!-- Example: IV. Integration Testing -->\n[PRINCIPLE_4_DESCRIPTION]\n<!-- Example: Focus areas requiring integration tests: New library contract tests, Contract changes, Inter-service communication, Shared schemas -->\n\n### [PRINCIPLE_5_NAME]\n<!-- Example: V. Observability, VI. Versioning & Breaking Changes, VII. Simplicity -->\n[PRINCIPLE_5_DESCRIPTION]\n<!-- Example: Text I/O ensures debuggability; Structured logging required; Or: MAJOR.MINOR.BUILD format; Or: Start simple, YAGNI principles -->\n\n## [SECTION_2_NAME]\n<!-- Example: Additional Constraints, Security Requirements, Performance Standards, etc. -->\n\n[SECTION_2_CONTENT]\n<!-- Example: Technology stack requirements, compliance standards, deployment policies, etc. -->\n\n## [SECTION_3_NAME]\n<!-- Example: Development Workflow, Review Process, Quality Gates, etc. -->\n\n[SECTION_3_CONTENT]\n<!-- Example: Code review requirements, testing gates, deployment approval process, etc. -->\n\n## Governance\n<!-- Example: Constitution supersedes all other practices; Amendments require documentation, approval, migration plan -->\n\n[GOVERNANCE_RULES]\n<!-- Example: All PRs/reviews must verify compliance; Complexity must be justified; Use [GUIDANCE_FILE] for runtime development guidance -->\n\n**Version**: [CONSTITUTION_VERSION] | **Ratified**: [RATIFICATION_DATE] | **Last Amended**: [LAST_AMENDED_DATE]\n<!-- Example: Version: 2.1.1 | Ratified: 2025-06-13 | Last Amended: 2025-07-16 -->",
        "headings": [
          "# [PROJECT_NAME] Constitution",
          "## Core Principles",
          "### [PRINCIPLE_1_NAME]",
          "### [PRINCIPLE_2_NAME]",
          "### [PRINCIPLE_3_NAME]",
          "### [PRINCIPLE_4_NAME]",
          "### [PRINCIPLE_5_NAME]",
          "## [SECTION_2_NAME]",
          "## [SECTION_3_NAME]",
          "## Governance"
        ],
        "word_count": 272
      },
      "templates/tasks-template.md": {
        "content": "# Tasks: [FEATURE NAME]\n\n**Input**: Design documents from `/specs/[###-feature-name]/`\n**Prerequisites**: plan.md (required), research.md, data-model.md, contracts/\n\n## Execution Flow (main)\n```\n1. Load plan.md from feature directory\n   \u2192 If not found: ERROR \"No implementation plan found\"\n   \u2192 Extract: tech stack, libraries, structure\n2. Load optional design documents:\n   \u2192 data-model.md: Extract entities \u2192 model tasks\n   \u2192 contracts/: Each file \u2192 contract test task\n   \u2192 research.md: Extract decisions \u2192 setup tasks\n3. Generate tasks by category:\n   \u2192 Setup: project init, dependencies, linting\n   \u2192 Tests: contract tests, integration tests\n   \u2192 Core: models, services, CLI commands\n   \u2192 Integration: DB, middleware, logging\n   \u2192 Polish: unit tests, performance, docs\n4. Apply task rules:\n   \u2192 Different files = mark [P] for parallel\n   \u2192 Same file = sequential (no [P])\n   \u2192 Tests before implementation (TDD)\n5. Number tasks sequentially (T001, T002...)\n6. Generate dependency graph\n7. Create parallel execution examples\n8. Validate task completeness:\n   \u2192 All contracts have tests?\n   \u2192 All entities have models?\n   \u2192 All endpoints implemented?\n9. Return: SUCCESS (tasks ready for execution)\n```\n\n## Format: `[ID] [P?] Description`\n- **[P]**: Can run in parallel (different files, no dependencies)\n- Include exact file paths in descriptions\n\n## Path Conventions\n- **Single project**: `src/`, `tests/` at repository root\n- **Web app**: `backend/src/`, `frontend/src/`\n- **Mobile**: `api/src/`, `ios/src/` or `android/src/`\n- Paths shown below assume single project - adjust based on plan.md structure\n\n## Phase 3.1: Setup\n- [ ] T001 Create project structure per implementation plan\n- [ ] T002 Initialize [language] project with [framework] dependencies\n- [ ] T003 [P] Configure linting and formatting tools\n\n## Phase 3.2: Tests First (TDD) \u26a0\ufe0f MUST COMPLETE BEFORE 3.3\n**CRITICAL: These tests MUST be written and MUST FAIL before ANY implementation**\n- [ ] T004 [P] Contract test POST /api/users in tests/contract/test_users_post.py\n- [ ] T005 [P] Contract test GET /api/users/{id} in tests/contract/test_users_get.py\n- [ ] T006 [P] Integration test user registration in tests/integration/test_registration.py\n- [ ] T007 [P] Integration test auth flow in tests/integration/test_auth.py\n\n## Phase 3.3: Core Implementation (ONLY after tests are failing)\n- [ ] T008 [P] User model in src/models/user.py\n- [ ] T009 [P] UserService CRUD in src/services/user_service.py\n- [ ] T010 [P] CLI --create-user in src/cli/user_commands.py\n- [ ] T011 POST /api/users endpoint\n- [ ] T012 GET /api/users/{id} endpoint\n- [ ] T013 Input validation\n- [ ] T014 Error handling and logging\n\n## Phase 3.4: Integration\n- [ ] T015 Connect UserService to DB\n- [ ] T016 Auth middleware\n- [ ] T017 Request/response logging\n- [ ] T018 CORS and security headers\n\n## Phase 3.5: Polish\n- [ ] T019 [P] Unit tests for validation in tests/unit/test_validation.py\n- [ ] T020 Performance tests (<200ms)\n- [ ] T021 [P] Update docs/api.md\n- [ ] T022 Remove duplication\n- [ ] T023 Run manual-testing.md\n\n## Dependencies\n- Tests (T004-T007) before implementation (T008-T014)\n- T008 blocks T009, T015\n- T016 blocks T018\n- Implementation before polish (T019-T023)\n\n## Parallel Example\n```\n# Launch T004-T007 together:\nTask: \"Contract test POST /api/users in tests/contract/test_users_post.py\"\nTask: \"Contract test GET /api/users/{id} in tests/contract/test_users_get.py\"\nTask: \"Integration test registration in tests/integration/test_registration.py\"\nTask: \"Integration test auth in tests/integration/test_auth.py\"\n```\n\n## Notes\n- [P] tasks = different files, no dependencies\n- Verify tests fail before implementing\n- Commit after each task\n- Avoid: vague tasks, same file conflicts\n\n## Task Generation Rules\n*Applied during main() execution*\n\n1. **From Contracts**:\n   - Each contract file \u2192 contract test task [P]\n   - Each endpoint \u2192 implementation task\n   \n2. **From Data Model**:\n   - Each entity \u2192 model creation task [P]\n   - Relationships \u2192 service layer tasks\n   \n3. **From User Stories**:\n   - Each story \u2192 integration test [P]\n   - Quickstart scenarios \u2192 validation tasks\n\n4. **Ordering**:\n   - Setup \u2192 Tests \u2192 Models \u2192 Services \u2192 Endpoints \u2192 Polish\n   - Dependencies block parallel execution\n\n## Validation Checklist\n*GATE: Checked by main() before returning*\n\n- [ ] All contracts have corresponding tests\n- [ ] All entities have model tasks\n- [ ] All tests come before implementation\n- [ ] Parallel tasks truly independent\n- [ ] Each task specifies exact file path\n- [ ] No task modifies same file as another [P] task",
        "headings": [
          "# Tasks: [FEATURE NAME]",
          "## Execution Flow (main)",
          "## Format: `[ID] [P?] Description`",
          "## Path Conventions",
          "## Phase 3.1: Setup",
          "## Phase 3.2: Tests First (TDD) \u26a0\ufe0f MUST COMPLETE BEFORE 3.3",
          "## Phase 3.3: Core Implementation (ONLY after tests are failing)",
          "## Phase 3.4: Integration",
          "## Phase 3.5: Polish",
          "## Dependencies",
          "## Parallel Example",
          "# Launch T004-T007 together:",
          "## Notes",
          "## Task Generation Rules",
          "## Validation Checklist"
        ],
        "word_count": 689
      },
      "templates/agent-file-template.md": {
        "content": "# [PROJECT NAME] Development Guidelines\n\nAuto-generated from all feature plans. Last updated: [DATE]\n\n## Active Technologies\n[EXTRACTED FROM ALL PLAN.MD FILES]\n\n## Project Structure\n```\n[ACTUAL STRUCTURE FROM PLANS]\n```\n\n## Commands\n[ONLY COMMANDS FOR ACTIVE TECHNOLOGIES]\n\n## Code Style\n[LANGUAGE-SPECIFIC, ONLY FOR LANGUAGES IN USE]\n\n## Recent Changes\n[LAST 3 FEATURES AND WHAT THEY ADDED]\n\n<!-- MANUAL ADDITIONS START -->\n<!-- MANUAL ADDITIONS END -->",
        "headings": [
          "# [PROJECT NAME] Development Guidelines",
          "## Active Technologies",
          "## Project Structure",
          "## Commands",
          "## Code Style",
          "## Recent Changes"
        ],
        "word_count": 66
      },
      "templates/plan-template.md": {
        "content": "# Implementation Plan: [FEATURE]\n\n**Branch**: `[###-feature-name]` | **Date**: [DATE] | **Spec**: [link]\n**Input**: Feature specification from `/specs/[###-feature-name]/spec.md`\n\n## Execution Flow (/plan command scope)\n```\n1. Load feature spec from Input path\n   \u2192 If not found: ERROR \"No feature spec at {path}\"\n2. Fill Technical Context (scan for NEEDS CLARIFICATION)\n   \u2192 Detect Project Type from context (web=frontend+backend, mobile=app+api)\n   \u2192 Set Structure Decision based on project type\n3. Evaluate Constitution Check section below\n   \u2192 If violations exist: Document in Complexity Tracking\n   \u2192 If no justification possible: ERROR \"Simplify approach first\"\n   \u2192 Update Progress Tracking: Initial Constitution Check\n4. Execute Phase 0 \u2192 research.md\n   \u2192 If NEEDS CLARIFICATION remain: ERROR \"Resolve unknowns\"\n5. Execute Phase 1 \u2192 contracts, data-model.md, quickstart.md, agent-specific template file (e.g., `CLAUDE.md` for Claude Code, `.github/copilot-instructions.md` for GitHub Copilot, or `GEMINI.md` for Gemini CLI).\n6. Re-evaluate Constitution Check section\n   \u2192 If new violations: Refactor design, return to Phase 1\n   \u2192 Update Progress Tracking: Post-Design Constitution Check\n7. Plan Phase 2 \u2192 Describe task generation approach (DO NOT create tasks.md)\n8. STOP - Ready for /tasks command\n```\n\n**IMPORTANT**: The /plan command STOPS at step 7. Phases 2-4 are executed by other commands:\n- Phase 2: /tasks command creates tasks.md\n- Phase 3-4: Implementation execution (manual or via tools)\n\n## Summary\n[Extract from feature spec: primary requirement + technical approach from research]\n\n## Technical Context\n**Language/Version**: [e.g., Python 3.11, Swift 5.9, Rust 1.75 or NEEDS CLARIFICATION]  \n**Primary Dependencies**: [e.g., FastAPI, UIKit, LLVM or NEEDS CLARIFICATION]  \n**Storage**: [if applicable, e.g., PostgreSQL, CoreData, files or N/A]  \n**Testing**: [e.g., pytest, XCTest, cargo test or NEEDS CLARIFICATION]  \n**Target Platform**: [e.g., Linux server, iOS 15+, WASM or NEEDS CLARIFICATION]\n**Project Type**: [single/web/mobile - determines source structure]  \n**Performance Goals**: [domain-specific, e.g., 1000 req/s, 10k lines/sec, 60 fps or NEEDS CLARIFICATION]  \n**Constraints**: [domain-specific, e.g., <200ms p95, <100MB memory, offline-capable or NEEDS CLARIFICATION]  \n**Scale/Scope**: [domain-specific, e.g., 10k users, 1M LOC, 50 screens or NEEDS CLARIFICATION]\n\n## Constitution Check\n*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*\n\n**Simplicity**:\n- Projects: [#] (max 3 - e.g., api, cli, tests)\n- Using framework directly? (no wrapper classes)\n- Single data model? (no DTOs unless serialization differs)\n- Avoiding patterns? (no Repository/UoW without proven need)\n\n**Architecture**:\n- EVERY feature as library? (no direct app code)\n- Libraries listed: [name + purpose for each]\n- CLI per library: [commands with --help/--version/--format]\n- Library docs: llms.txt format planned?\n\n**Testing (NON-NEGOTIABLE)**:\n- RED-GREEN-Refactor cycle enforced? (test MUST fail first)\n- Git commits show tests before implementation?\n- Order: Contract\u2192Integration\u2192E2E\u2192Unit strictly followed?\n- Real dependencies used? (actual DBs, not mocks)\n- Integration tests for: new libraries, contract changes, shared schemas?\n- FORBIDDEN: Implementation before test, skipping RED phase\n\n**Observability**:\n- Structured logging included?\n- Frontend logs \u2192 backend? (unified stream)\n- Error context sufficient?\n\n**Versioning**:\n- Version number assigned? (MAJOR.MINOR.BUILD)\n- BUILD increments on every change?\n- Breaking changes handled? (parallel tests, migration plan)\n\n## Project Structure\n\n### Documentation (this feature)\n```\nspecs/[###-feature]/\n\u251c\u2500\u2500 plan.md              # This file (/plan command output)\n\u251c\u2500\u2500 research.md          # Phase 0 output (/plan command)\n\u251c\u2500\u2500 data-model.md        # Phase 1 output (/plan command)\n\u251c\u2500\u2500 quickstart.md        # Phase 1 output (/plan command)\n\u251c\u2500\u2500 contracts/           # Phase 1 output (/plan command)\n\u2514\u2500\u2500 tasks.md             # Phase 2 output (/tasks command - NOT created by /plan)\n```\n\n### Source Code (repository root)\n```\n# Option 1: Single project (DEFAULT)\nsrc/\n\u251c\u2500\u2500 models/\n\u251c\u2500\u2500 services/\n\u251c\u2500\u2500 cli/\n\u2514\u2500\u2500 lib/\n\ntests/\n\u251c\u2500\u2500 contract/\n\u251c\u2500\u2500 integration/\n\u2514\u2500\u2500 unit/\n\n# Option 2: Web application (when \"frontend\" + \"backend\" detected)\nbackend/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 services/\n\u2502   \u2514\u2500\u2500 api/\n\u2514\u2500\u2500 tests/\n\nfrontend/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 components/\n\u2502   \u251c\u2500\u2500 pages/\n\u2502   \u2514\u2500\u2500 services/\n\u2514\u2500\u2500 tests/\n\n# Option 3: Mobile + API (when \"iOS/Android\" detected)\napi/\n\u2514\u2500\u2500 [same as backend above]\n\nios/ or android/\n\u2514\u2500\u2500 [platform-specific structure]\n```\n\n**Structure Decision**: [DEFAULT to Option 1 unless Technical Context indicates web/mobile app]\n\n## Phase 0: Outline & Research\n1. **Extract unknowns from Technical Context** above:\n   - For each NEEDS CLARIFICATION \u2192 research task\n   - For each dependency \u2192 best practices task\n   - For each integration \u2192 patterns task\n\n2. **Generate and dispatch research agents**:\n   ```\n   For each unknown in Technical Context:\n     Task: \"Research {unknown} for {feature context}\"\n   For each technology choice:\n     Task: \"Find best practices for {tech} in {domain}\"\n   ```\n\n3. **Consolidate findings** in `research.md` using format:\n   - Decision: [what was chosen]\n   - Rationale: [why chosen]\n   - Alternatives considered: [what else evaluated]\n\n**Output**: research.md with all NEEDS CLARIFICATION resolved\n\n## Phase 1: Design & Contracts\n*Prerequisites: research.md complete*\n\n1. **Extract entities from feature spec** \u2192 `data-model.md`:\n   - Entity name, fields, relationships\n   - Validation rules from requirements\n   - State transitions if applicable\n\n2. **Generate API contracts** from functional requirements:\n   - For each user action \u2192 endpoint\n   - Use standard REST/GraphQL patterns\n   - Output OpenAPI/GraphQL schema to `/contracts/`\n\n3. **Generate contract tests** from contracts:\n   - One test file per endpoint\n   - Assert request/response schemas\n   - Tests must fail (no implementation yet)\n\n4. **Extract test scenarios** from user stories:\n   - Each story \u2192 integration test scenario\n   - Quickstart test = story validation steps\n\n5. **Update agent file incrementally** (O(1) operation):\n   - Run `/scripts/update-agent-context.sh [claude|gemini|copilot]` for your AI assistant\n   - If exists: Add only NEW tech from current plan\n   - Preserve manual additions between markers\n   - Update recent changes (keep last 3)\n   - Keep under 150 lines for token efficiency\n   - Output to repository root\n\n**Output**: data-model.md, /contracts/*, failing tests, quickstart.md, agent-specific file\n\n## Phase 2: Task Planning Approach\n*This section describes what the /tasks command will do - DO NOT execute during /plan*\n\n**Task Generation Strategy**:\n- Load `/templates/tasks-template.md` as base\n- Generate tasks from Phase 1 design docs (contracts, data model, quickstart)\n- Each contract \u2192 contract test task [P]\n- Each entity \u2192 model creation task [P] \n- Each user story \u2192 integration test task\n- Implementation tasks to make tests pass\n\n**Ordering Strategy**:\n- TDD order: Tests before implementation \n- Dependency order: Models before services before UI\n- Mark [P] for parallel execution (independent files)\n\n**Estimated Output**: 25-30 numbered, ordered tasks in tasks.md\n\n**IMPORTANT**: This phase is executed by the /tasks command, NOT by /plan\n\n## Phase 3+: Future Implementation\n*These phases are beyond the scope of the /plan command*\n\n**Phase 3**: Task execution (/tasks command creates tasks.md)  \n**Phase 4**: Implementation (execute tasks.md following constitutional principles)  \n**Phase 5**: Validation (run tests, execute quickstart.md, performance validation)\n\n## Complexity Tracking\n*Fill ONLY if Constitution Check has violations that must be justified*\n\n| Violation | Why Needed | Simpler Alternative Rejected Because |\n|-----------|------------|-------------------------------------|\n| [e.g., 4th project] | [current need] | [why 3 projects insufficient] |\n| [e.g., Repository pattern] | [specific problem] | [why direct DB access insufficient] |\n\n\n## Progress Tracking\n*This checklist is updated during execution flow*\n\n**Phase Status**:\n- [ ] Phase 0: Research complete (/plan command)\n- [ ] Phase 1: Design complete (/plan command)\n- [ ] Phase 2: Task planning complete (/plan command - describe approach only)\n- [ ] Phase 3: Tasks generated (/tasks command)\n- [ ] Phase 4: Implementation complete\n- [ ] Phase 5: Validation passed\n\n**Gate Status**:\n- [ ] Initial Constitution Check: PASS\n- [ ] Post-Design Constitution Check: PASS\n- [ ] All NEEDS CLARIFICATION resolved\n- [ ] Complexity deviations documented\n\n---\n*Based on Constitution v2.1.1 - See `/memory/constitution.md`*",
        "headings": [
          "# Implementation Plan: [FEATURE]",
          "## Execution Flow (/plan command scope)",
          "## Summary",
          "## Technical Context",
          "## Constitution Check",
          "## Project Structure",
          "### Documentation (this feature)",
          "### Source Code (repository root)",
          "# Option 1: Single project (DEFAULT)",
          "# Option 2: Web application (when \"frontend\" + \"backend\" detected)",
          "# Option 3: Mobile + API (when \"iOS/Android\" detected)",
          "## Phase 0: Outline & Research",
          "## Phase 1: Design & Contracts",
          "## Phase 2: Task Planning Approach",
          "## Phase 3+: Future Implementation",
          "## Complexity Tracking",
          "## Progress Tracking"
        ],
        "word_count": 1214
      },
      "templates/spec-template.md": {
        "content": "# Feature Specification: [FEATURE NAME]\n\n**Feature Branch**: `[###-feature-name]`  \n**Created**: [DATE]  \n**Status**: Draft  \n**Input**: User description: \"$ARGUMENTS\"\n\n## Execution Flow (main)\n```\n1. Parse user description from Input\n   \u2192 If empty: ERROR \"No feature description provided\"\n2. Extract key concepts from description\n   \u2192 Identify: actors, actions, data, constraints\n3. For each unclear aspect:\n   \u2192 Mark with [NEEDS CLARIFICATION: specific question]\n4. Fill User Scenarios & Testing section\n   \u2192 If no clear user flow: ERROR \"Cannot determine user scenarios\"\n5. Generate Functional Requirements\n   \u2192 Each requirement must be testable\n   \u2192 Mark ambiguous requirements\n6. Identify Key Entities (if data involved)\n7. Run Review Checklist\n   \u2192 If any [NEEDS CLARIFICATION]: WARN \"Spec has uncertainties\"\n   \u2192 If implementation details found: ERROR \"Remove tech details\"\n8. Return: SUCCESS (spec ready for planning)\n```\n\n---\n\n## \u26a1 Quick Guidelines\n- \u2705 Focus on WHAT users need and WHY\n- \u274c Avoid HOW to implement (no tech stack, APIs, code structure)\n- \ud83d\udc65 Written for business stakeholders, not developers\n\n### Section Requirements\n- **Mandatory sections**: Must be completed for every feature\n- **Optional sections**: Include only when relevant to the feature\n- When a section doesn't apply, remove it entirely (don't leave as \"N/A\")\n\n### For AI Generation\nWhen creating this spec from a user prompt:\n1. **Mark all ambiguities**: Use [NEEDS CLARIFICATION: specific question] for any assumption you'd need to make\n2. **Don't guess**: If the prompt doesn't specify something (e.g., \"login system\" without auth method), mark it\n3. **Think like a tester**: Every vague requirement should fail the \"testable and unambiguous\" checklist item\n4. **Common underspecified areas**:\n   - User types and permissions\n   - Data retention/deletion policies  \n   - Performance targets and scale\n   - Error handling behaviors\n   - Integration requirements\n   - Security/compliance needs\n\n---\n\n## User Scenarios & Testing *(mandatory)*\n\n### Primary User Story\n[Describe the main user journey in plain language]\n\n### Acceptance Scenarios\n1. **Given** [initial state], **When** [action], **Then** [expected outcome]\n2. **Given** [initial state], **When** [action], **Then** [expected outcome]\n\n### Edge Cases\n- What happens when [boundary condition]?\n- How does system handle [error scenario]?\n\n## Requirements *(mandatory)*\n\n### Functional Requirements\n- **FR-001**: System MUST [specific capability, e.g., \"allow users to create accounts\"]\n- **FR-002**: System MUST [specific capability, e.g., \"validate email addresses\"]  \n- **FR-003**: Users MUST be able to [key interaction, e.g., \"reset their password\"]\n- **FR-004**: System MUST [data requirement, e.g., \"persist user preferences\"]\n- **FR-005**: System MUST [behavior, e.g., \"log all security events\"]\n\n*Example of marking unclear requirements:*\n- **FR-006**: System MUST authenticate users via [NEEDS CLARIFICATION: auth method not specified - email/password, SSO, OAuth?]\n- **FR-007**: System MUST retain user data for [NEEDS CLARIFICATION: retention period not specified]\n\n### Key Entities *(include if feature involves data)*\n- **[Entity 1]**: [What it represents, key attributes without implementation]\n- **[Entity 2]**: [What it represents, relationships to other entities]\n\n---\n\n## Review & Acceptance Checklist\n*GATE: Automated checks run during main() execution*\n\n### Content Quality\n- [ ] No implementation details (languages, frameworks, APIs)\n- [ ] Focused on user value and business needs\n- [ ] Written for non-technical stakeholders\n- [ ] All mandatory sections completed\n\n### Requirement Completeness\n- [ ] No [NEEDS CLARIFICATION] markers remain\n- [ ] Requirements are testable and unambiguous  \n- [ ] Success criteria are measurable\n- [ ] Scope is clearly bounded\n- [ ] Dependencies and assumptions identified\n\n---\n\n## Execution Status\n*Updated by main() during processing*\n\n- [ ] User description parsed\n- [ ] Key concepts extracted\n- [ ] Ambiguities marked\n- [ ] User scenarios defined\n- [ ] Requirements generated\n- [ ] Entities identified\n- [ ] Review checklist passed\n\n---\n",
        "headings": [
          "# Feature Specification: [FEATURE NAME]",
          "## Execution Flow (main)",
          "## \u26a1 Quick Guidelines",
          "### Section Requirements",
          "### For AI Generation",
          "## User Scenarios & Testing *(mandatory)*",
          "### Primary User Story",
          "### Acceptance Scenarios",
          "### Edge Cases",
          "## Requirements *(mandatory)*",
          "### Functional Requirements",
          "### Key Entities *(include if feature involves data)*",
          "## Review & Acceptance Checklist",
          "### Content Quality",
          "### Requirement Completeness",
          "## Execution Status"
        ],
        "word_count": 605
      },
      "templates/commands/plan.md": {
        "content": "---\nname: plan\ndescription: \"Plan how to implement the specified feature. This is the second step in the Spec-Driven Development lifecycle.\"\n---\n\nPlan how to implement the specified feature.\n\nThis is the second step in the Spec-Driven Development lifecycle.\n\nGiven the implementation details provided as an argument, do this:\n\n1. Run `scripts/setup-plan.sh --json` from the repo root and parse JSON for FEATURE_SPEC, IMPL_PLAN, SPECS_DIR, BRANCH. All future file paths must be absolute.\n2. Read and analyze the feature specification to understand:\n   - The feature requirements and user stories\n   - Functional and non-functional requirements\n   - Success criteria and acceptance criteria\n   - Any technical constraints or dependencies mentioned\n\n3. Read the constitution at `/memory/constitution.md` to understand constitutional requirements.\n\n4. Execute the implementation plan template:\n   - Load `/templates/plan-template.md` (already copied to IMPL_PLAN path)\n   - Set Input path to FEATURE_SPEC\n   - Run the Execution Flow (main) function steps 1-10\n   - The template is self-contained and executable\n   - Follow error handling and gate checks as specified\n   - Let the template guide artifact generation in $SPECS_DIR:\n     * Phase 0 generates research.md\n     * Phase 1 generates data-model.md, contracts/, quickstart.md\n     * Phase 2 generates tasks.md\n   - Incorporate user-provided details from arguments into Technical Context: {ARGS}\n   - Update Progress Tracking as you complete each phase\n\n5. Verify execution completed:\n   - Check Progress Tracking shows all phases complete\n   - Ensure all required artifacts were generated\n   - Confirm no ERROR states in execution\n\n6. Report results with branch name, file paths, and generated artifacts.\n\nUse absolute paths with the repository root for all file operations to avoid path issues.\n",
        "headings": [],
        "word_count": 258
      },
      "templates/commands/tasks.md": {
        "content": "---\nname: tasks\ndescription: \"Break down the plan into executable tasks. This is the third step in the Spec-Driven Development lifecycle.\"\n---\n\nBreak down the plan into executable tasks.\n\nThis is the third step in the Spec-Driven Development lifecycle.\n\nGiven the context provided as an argument, do this:\n\n1. Run `scripts/check-task-prerequisites.sh --json` from repo root and parse FEATURE_DIR and AVAILABLE_DOCS list. All paths must be absolute.\n2. Load and analyze available design documents:\n   - Always read plan.md for tech stack and libraries\n   - IF EXISTS: Read data-model.md for entities\n   - IF EXISTS: Read contracts/ for API endpoints  \n   - IF EXISTS: Read research.md for technical decisions\n   - IF EXISTS: Read quickstart.md for test scenarios\n   \n   Note: Not all projects have all documents. For example:\n   - CLI tools might not have contracts/\n   - Simple libraries might not need data-model.md\n   - Generate tasks based on what's available\n\n3. Generate tasks following the template:\n   - Use `/templates/tasks-template.md` as the base\n   - Replace example tasks with actual tasks based on:\n     * **Setup tasks**: Project init, dependencies, linting\n     * **Test tasks [P]**: One per contract, one per integration scenario\n     * **Core tasks**: One per entity, service, CLI command, endpoint\n     * **Integration tasks**: DB connections, middleware, logging\n     * **Polish tasks [P]**: Unit tests, performance, docs\n\n4. Task generation rules:\n   - Each contract file \u2192 contract test task marked [P]\n   - Each entity in data-model \u2192 model creation task marked [P]\n   - Each endpoint \u2192 implementation task (not parallel if shared files)\n   - Each user story \u2192 integration test marked [P]\n   - Different files = can be parallel [P]\n   - Same file = sequential (no [P])\n\n5. Order tasks by dependencies:\n   - Setup before everything\n   - Tests before implementation (TDD)\n   - Models before services\n   - Services before endpoints\n   - Core before integration\n   - Everything before polish\n\n6. Include parallel execution examples:\n   - Group [P] tasks that can run together\n   - Show actual Task agent commands\n\n7. Create FEATURE_DIR/tasks.md with:\n   - Correct feature name from implementation plan\n   - Numbered tasks (T001, T002, etc.)\n   - Clear file paths for each task\n   - Dependency notes\n   - Parallel execution guidance\n\nContext for task generation: {ARGS}\n\nThe tasks.md should be immediately executable - each task must be specific enough that an LLM can complete it without additional context.\n",
        "headings": [],
        "word_count": 374
      },
      "templates/commands/specify.md": {
        "content": "---\nname: specify\ndescription: \"Start a new feature by creating a specification and feature branch. This is the first step in the Spec-Driven Development lifecycle.\"\n---\n\nStart a new feature by creating a specification and feature branch.\n\nThis is the first step in the Spec-Driven Development lifecycle.\n\nGiven the feature description provided as an argument, do this:\n\n1. Run the script `scripts/create-new-feature.sh --json \"{ARGS}\"` from repo root and parse its JSON output for BRANCH_NAME and SPEC_FILE. All file paths must be absolute.\n2. Load `templates/spec-template.md` to understand required sections.\n3. Write the specification to SPEC_FILE using the template structure, replacing placeholders with concrete details derived from the feature description (arguments) while preserving section order and headings.\n4. Report completion with branch name, spec file path, and readiness for the next phase.\n\nNote: The script creates and checks out the new branch and initializes the spec file before writing.\n",
        "headings": [],
        "word_count": 148
      }
    },
    "requirements_found": [
      "adhere to when establishing the plan.",
      "be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.",
      "allow users to create projects, add team members,",
      "be able to change the current status of the task between the different columns in the Kanban work board.",
      "be able to leave an unlimited number of comments for a particular card. You should be able to, from that task",
      "see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.",
      "have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.",
      "contain a set of user stories and functional requirements, as defined in the template.",
      "resemble the following:",
      "be a variable number of tasks between 5 and 15",
      "also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:",
      "be a REST API created with a projects API,",
      "have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:",
      "break this down into a series of steps. First, identify a list of tasks",
      "do during implementation that you're not sure of or would benefit",
      "help you solve a specific targeted question.",
      "be doing that are obvious from reading this. Because I don't know if there's enough here. For example,",
      "adhere to when establishing the plan.",
      "be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.",
      "allow users to create projects, add team members,",
      "be able to change the current status of the task between the different columns in the Kanban work board.",
      "be able to leave an unlimited number of comments for a particular card. You should be able to, from that task",
      "see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.",
      "have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.",
      "contain a set of user stories and functional requirements, as defined in the template.",
      "resemble the following:",
      "be a variable number of tasks between 5 and 15",
      "also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:",
      "be a REST API created with a projects API,",
      "have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:",
      "break this down into a series of steps. First, identify a list of tasks",
      "do during implementation that you're not sure of or would benefit",
      "help you solve a specific targeted question.",
      "be doing that are obvious from reading this. Because I don't know if there's enough here. For example,",
      "adhere to when establishing the plan.",
      "be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.",
      "allow users to create projects, add team members,",
      "be able to change the current status of the task between the different columns in the Kanban work board.",
      "be able to leave an unlimited number of comments for a particular card. You should be able to, from that task",
      "see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.",
      "have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.",
      "contain a set of user stories and functional requirements, as defined in the template.",
      "resemble the following:",
      "be a variable number of tasks between 5 and 15",
      "also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:",
      "be a REST API created with a projects API,",
      "have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:",
      "break this down into a series of steps. First, identify a list of tasks",
      "do during implementation that you're not sure of or would benefit",
      "help you solve a specific targeted question.",
      "be doing that are obvious from reading this. Because I don't know if there's enough here. For example,",
      "changes from obstacles into normal workflow. When specifications drive implementation, pivots become systematic regenerations rather than manual rewrites. Change a core requirement in the PRD, and affected implementation plans update automatically. Modify a user story, and corresponding API endpoints regenerate. This isn't just about initial development\u2014it's about maintaining engineering velocity through inevitable changes.",
      "Completeness",
      "be precise, complete, and unambiguous enough to generate working systems. This eliminates the gap between intent and implementation.",
      "mark it as `[NEEDS CLARIFICATION: auth method not specified - email/password, SSO, OAuth?]`.",
      "document why in the \"Complexity Tracking\" section, creating accountability for architectural decisions.",
      "be placed in the appropriate `implementation-details/` file",
      "trace back to a concrete user story with clear acceptance criteria.",
      "begin as a standalone library\u2014no exceptions. This forces modular design from the start:",
      "begin its existence as a standalone library.",
      "structure features as libraries with clear boundaries and minimal dependencies.",
      "expose its functionality through a command-line interface:",
      "be accessible and verifiable through text-based interfaces.",
      "follow strict Test-Driven Development.",
      "first generate comprehensive tests that define behavior, get them approved, and only then generate implementation.",
      "use realistic environments:",
      "be inspectable through CLI interfaces",
      "remain high-level and readable.",
      "be implemented directly within application code without",
      "be written before:",
      "re-implement or change the application to promote a business need to sell more T-shirts, how would we implement and experiment for that?\".",
      "and technical consistency",
      "be self-contained, independently testable, documented; Clear purpose required - no organizational-only libraries -->",
      "verify compliance; Complexity must be justified; Use [GUIDANCE_FILE] for runtime development guidance -->",
      "COMPLETE BEFORE 3.3",
      "be written and MUST FAIL before ANY implementation**",
      "+ technical approach from research]",
      "pass before Phase 0 research. Re-check after Phase 1 design.*",
      "fail first)",
      "fail (no implementation yet)",
      "be justified*",
      "must be testable",
      "should fail the \"testable and unambiguous\" checklist item",
      "Completeness",
      "be testable",
      "be completed for every feature",
      "[specific capability, e.g., \"allow users to create accounts\"]",
      "[specific capability, e.g., \"validate email addresses\"]",
      "be able to [key interaction, e.g., \"reset their password\"]",
      "[data requirement, e.g., \"persist user preferences\"]",
      "[behavior, e.g., \"log all security events\"]",
      "authenticate users via [NEEDS CLARIFICATION: auth method not specified - email/password, SSO, OAuth?]",
      "retain user data for [NEEDS CLARIFICATION: retention period not specified]",
      "fail the \"testable and unambiguous\" checklist item",
      "be absolute.",
      "be absolute.",
      "be specific enough that an LLM can complete it without additional context.",
      "be immediately executable - each task must be specific enough that an LLM can complete it without additional context.",
      "be absolute."
    ],
    "features_found": [
      "branches with specifications",
      "boundaries for progressive onboarding",
      "specifications into master specification",
      "specifications",
      "specifications",
      "level adoption | <ul><li>Onboard individual features and components</li><li>Support multi-team development workflows</li><li>Coordinate specifications across features</li><li>Enable gradual organizational adoption</li></ul> |",
      "development workflows",
      "spec meets the criteria. Leave it empty if it does not.",
      "\"Add user authentication\"",
      "\"Add user authentication\"",
      "requests, and questions about using Spec-Driven Development.",
      "organizations to focus on product scenarios rather than writing undifferentiated code with the help of Spec-Driven Development.</strong>",
      "users to create projects, add team members,",
      "gradual adoption of spec-driven development across organizations",
      "gradual organizational adoption</li></ul> |",
      "development workflows",
      "spec meets the criteria. Leave it empty if it does not.",
      "\"Add user authentication\"",
      "\"Add user authentication\"",
      "requests, and questions about using Spec-Driven Development.",
      "organizations to focus on product scenarios rather than writing undifferentiated code with the help of Spec-Driven Development.</strong>",
      "users to create projects, add team members,",
      "branches with specifications",
      "boundaries for progressive onboarding",
      "specifications into master specification",
      "specifications",
      "specifications",
      "level adoption | <ul><li>Onboard individual features and components</li><li>Support multi-team development workflows</li><li>Coordinate specifications across features</li><li>Enable gradual organizational adoption</li></ul> |",
      "development workflows",
      "spec meets the criteria. Leave it empty if it does not.",
      "\"Add user authentication\"",
      "\"Add user authentication\"",
      "requests, and questions about using Spec-Driven Development.",
      "organizations to focus on product scenarios rather than writing undifferentiated code with the help of Spec-Driven Development.</strong>",
      "users to create projects, add team members,",
      "gradual adoption of spec-driven development across organizations",
      "gradual organizational adoption</li></ul> |",
      "requests. Please search the existing issues before filing new issues to avoid duplicates. For new issues, file your bug or feature request as a new issue.",
      "requests, or questions about the Spec-Driven Development methodology",
      "requests, and community questions in a timely manner.",
      "description (the user-prompt) into a complete, structured specification with automatic repository management:",
      "Numbering**: Scans existing specs to determine the next feature number (e.g., 001, 002, 003)",
      "specification template with your requirements",
      "specification exists, this command creates a comprehensive implementation plan:",
      "requirements, user stories, and acceptance criteria",
      "Here's how these commands transform the traditional development workflow:",
      "specification (5 minutes)",
      "Real-time chat system with message history and user presence",
      "specification with user stories and acceptance criteria",
      "specification template explicitly instructs:",
      "must trace back to a concrete user story with clear acceptance criteria.",
      "must begin as a standalone library\u2014no exceptions. This forces modular design from the start:",
      "in Specify MUST begin its existence as a standalone library.",
      "shall be implemented directly within application code without",
      "reinforces rather than undermines the system design",
      "is a library with clear boundaries",
      "through a command-line interface:",
      "inside opaque classes\u2014everything must be accessible and verifiable through text-based interfaces.",
      "by automating mechanical translation. It's about creating a tight feedback loop where specifications, research, and code evolve together, each iteration bringing deeper understanding and better alignment between intent and implementation.",
      "the methodology to learn and improve while maintaining stability. The constitution shows its own evolution with dated amendments, demonstrating how principles can be refined based on real-world experience.",
      "with a sample project if relevant",
      "in the `scripts/` directory",
      "level and component-level onboarding",
      "or component within a project for progressive onboarding.",
      "(default: 2)",
      "specific analysis including:",
      "boundaries within a project to support progressive onboarding.",
      "boundaries (default: 2)",
      "boundary analysis including:",
      "identification",
      "to spec-driven development with dependency analysis.",
      "within the project",
      "dependencies (default: true)",
      "onboarding including:",
      "specific specification",
      "specifications into a master specification.",
      "specification dictionaries to merge",
      "coordination notes",
      "specifications.",
      "specification dictionaries to analyze",
      "specification dictionaries to analyze",
      "status tracking",
      "specifications.",
      "specification dictionaries to validate",
      "boundaries in your project",
      "${feature.feature_name}`);",
      "complexity: ${featureAnalysis.estimated_complexity}`);",
      "readiness: ${featureOnboarding.summary.ready_for_spec_driven}`);",
      "Specifications",
      "application\"",
      "specifications",
      "specifications",
      "dependencies",
      "Identification**: Use `extract_feature_boundaries` to identify logical features",
      "Prioritization**: Select which features to onboard first based on:",
      "complexity and dependencies",
      "Level Onboarding",
      "Analysis**: Use `analyze_feature_component` for each selected feature",
      "Onboarding**: Use `onboard_project_feature` to create feature specifications",
      "relationships",
      "dependencies",
      "dependencies early",
      "specification",
      "specification reviews",
      "Selection Strategies",
      "coordination leads to conflicts",
      "teams and stakeholders",
      "Level Branching**: Each feature can have its own specification branch",
      "Coordination**: Tools support coordination between independently onboarded features",
      "specifications can be merged into master specifications",
      "feature-level and component-level onboarding",
      "organizations to adopt spec-driven development for both new and existing projects using a consistent approach and toolset, while accommodating different team needs and organizational constraints.",
      "starts as a standalone library; Libraries must be self-contained, independently testable, documented; Clear purpose required - no organizational-only libraries -->",
      "via CLI; Text in/out protocol: stdin/args \u2192 stdout, errors \u2192 stderr; Support JSON + human-readable formats -->",
      "plans. Last updated: [DATE]",
      "name]` | **Date**: [DATE] | **Spec**: [link]",
      "specification from `/specs/[###-feature-name]/spec.md`",
      "spec from Input path",
      "spec at {path}\"",
      "spec: primary requirement + technical approach from research]",
      "as library? (no direct app code)",
      "spec** \u2192 `data-model.md`:",
      "Specification: [FEATURE NAME]",
      "Branch**: `[###-feature-name]`",
      "description provided\"",
      "**Optional sections**: Include only when relevant to the feature",
      "involves data)*",
      "users to create accounts\"]",
      "specification to understand:",
      "requirements and user stories",
      "name from implementation plan",
      "by creating a specification and feature branch. This is the first step in the Spec-Driven Development lifecycle.\"",
      "by creating a specification and feature branch.",
      "description provided as an argument, do this:",
      "description (arguments) while preserving section order and headings.",
      "with a sample project if relevant",
      "in the `scripts/` directory"
    ],
    "user_stories_found": [
      "Model Context Protocol (MCP) server that provides AI agents with powerful spec-driven development tools:\n\n```bash\n# Install the MCP server\npip install git+https://github.com/ASISaga/spec-kit.git\n\n# Run the MCP server\nspec-kit-mcp\n```\n\n### 2. Configure your AI agent\n\nAdd the Spec-Kit MCP server to your AI agent's configuration. The server provides these tools:\n\n**For New Projects:**\n- **init_project**: Initialize new Spec-Kit projects with templates\n- **create_new_feature**: Create feature branches with specifications  \n- **setup_plan**: Set up implementation plans\n- **check_task_prerequisites**: Validate task requirements\n- **update_agent_context**: Update agent context files\n- **get_feature_paths**: Get feature file paths\n- **run_script**: Execute cross-platform scripts\n- **check_requirements**: Check system requirements\n- **list_scripts**: Show available scripts and compatibility\n\n**For Existing Projects:**\n- **analyze_existing_project**: Analyze existing project structure and codebase\n- **parse_existing_documentation**: Extract requirements from existing documentation\n- **extract_requirements_from_code**: Extract specifications from code comments and docstrings\n- **generate_standardized_spec**: Generate Spec-Kit compatible specifications from analysis\n- **create_migration_plan**: Create detailed migration plans for adopting spec-driven development\n- **onboard_existing_project**: Complete end-to-end onboarding analysis\n\n**For Progressive Onboarding (NEW):**\n- **analyze_feature_component**: Analyze specific features/components within a project\n- **extract_feature_boundaries**: Identify logical feature boundaries for progressive onboarding\n- **onboard_project_feature**: Onboard individual features to spec-driven development\n- **merge_feature_specifications**: Combine multiple feature specifications into master specification\n- **detect_specification_conflicts**: Identify conflicts between feature specifications\n- **resolve_feature_dependencies**: Analyze and document dependencies between features\n- **create_progressive_migration_plan**: Create phased migration plans for incremental adoption\n- **track_onboarding_progress**: Track progress across multiple features/teams\n- **validate_specification_consistency**: Ensure consistency across progressive specifications\n\n### 3. Use with your AI agent\n\nOnce configured, your AI agent can use spec-driven development tools directly:\n\n**For New Projects:**\n- Create specifications that define the **what** and **why**, not the tech stack\n- Generate technical implementation plans with your chosen tech stack  \n- Break down features into actionable tasks\n- Manage the complete spec-driven development lifecycle\n\n**For Existing Projects:**\n- Analyze existing project structure and extract requirements\n- Parse documentation and code to understand current specifications\n- Generate standardized Spec-Kit compatible specifications\n- Create migration plans for adopting spec-driven development workflow\n- Onboard legacy projects to modern spec-driven approaches\n\n**For Progressive Onboarding (NEW):**\n- Analyze and onboard individual features or components incrementally\n- Support multiple teams working on different parts independently\n- Merge and coordinate specifications across features\n- Detect and resolve conflicts between feature specifications\n- Track progress and manage dependencies during progressive migration\n- Enable gradual adoption of spec-driven development across organizations\n\nFor detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).\nFor existing project onboarding, see our [onboarding guide](./ONBOARDING.md).\n\n## \ud83d\udcda Core philosophy\n\nSpec-Driven Development is a structured process that emphasizes:\n\n- **Intent-driven development** where specifications define the \"_what_\" before the \"_how_\"\n- **Rich specification creation** using guardrails and organizational principles\n- **Multi-step refinement** rather than one-shot code generation from prompts\n- **Heavy reliance** on advanced AI model capabilities for specification interpretation\n\n## \ud83c\udf1f Development phases\n\n| Phase | Focus | Key Activities |\n|-------|-------|----------------|\n| **0-to-1 Development** (\"Greenfield\") | Generate from scratch | <ul><li>Start with high-level requirements</li><li>Generate specifications</li><li>Plan implementation steps</li><li>Build production-ready applications</li></ul> |\n| **Creative Exploration** | Parallel implementations | <ul><li>Explore diverse solutions</li><li>Support multiple technology stacks & architectures</li><li>Experiment with UX patterns</li></ul> |\n| **Iterative Enhancement** (\"Brownfield\") | Brownfield modernization | <ul><li>Add features iteratively</li><li>Modernize legacy systems</li><li>Adapt processes</li></ul> |\n| **Existing Project Onboarding** (**ENHANCED**) | Legacy project migration | <ul><li>Analyze existing codebases and documentation</li><li>Extract and standardize requirements</li><li>Create migration plans</li><li>Adopt spec-driven workflows gradually</li></ul> |\n| **Progressive Onboarding** (**NEW**) | Incremental feature-level adoption | <ul><li>Onboard individual features and components</li><li>Support multi-team development workflows</li><li>Coordinate specifications across features</li><li>Enable gradual organizational adoption</li></ul> |\n\n## \ud83c\udfaf Experimental goals\n\nOur research and experimentation focus on:\n\n### Technology independence\n\n- Create applications using diverse technology stacks\n- Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks\n\n### Enterprise constraints\n\n- Demonstrate mission-critical application development\n- Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)\n- Support enterprise design systems and compliance requirements\n\n### User-centric development\n\n- Build applications for different user cohorts and preferences\n- Support various development approaches (from vibe-coding to AI-native development)\n\n### Creative & iterative processes\n\n- Validate the concept of parallel implementation exploration\n- Provide robust iterative feature development workflows\n- Extend processes to handle upgrades and modernization tasks  \n\n## \ud83d\udd27 Prerequisites\n\n- **Cross-platform**: Windows, Linux, macOS\n- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n- [uv](https://docs.astral.sh/uv/) for package management\n- [Python 3.11+](https://www.python.org/downloads/)\n- [Git](https://git-scm.com/downloads)\n\n## \ud83d\udcd6 Learn more\n\n- **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process\n- **[Detailed Walkthrough](#detailed-process)** - Step-by-step implementation guide\n\n---\n\n## Detailed process\n\n<details>\n<summary>Click to expand the detailed step-by-step walkthrough</summary>\n\nYou can use the Specify CLI to bootstrap your project, which will bring in the required artifacts in your environment. Run:\n\n```bash\nspecify init <project_name>\n```\n\nOr initialize in the current directory:\n\n```bash\nspecify init --here\n```\n\n![Specify CLI bootstrapping a new project in the terminal](./media/specify_cli.gif)\n\nYou will be prompted to select the AI agent you are using. You can also proactively specify it directly in the terminal:\n\n```bash\nspecify init <project_name> --ai claude\nspecify init <project_name> --ai gemini\nspecify init <project_name> --ai copilot\n# Or in current directory:\nspecify init --here --ai claude\n```\n\nThe CLI will check if you have Claude Code or Gemini CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:\n\n```bash\nspecify init <project_name> --ai claude --ignore-agent-tools\n```\n\n### **STEP 1:** Bootstrap the project\n\nGo to the project folder and run your AI agent. In our example, we're using `claude`.\n\n![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)\n\nYou will know that things are configured correctly if you see the `/specify`, `/plan`, and `/tasks` commands available.\n\nThe first step should be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.\n\n>[!IMPORTANT]\n>Be as explicit as possible about _what_ you are trying to build and _why_. **Do not focus on the tech stack at this point**.\n\nAn example prompt:\n\n```text\nDevelop Taskify, a team productivity platform. It should allow users to create projects, add team members,\nassign tasks, comment and move tasks between boards in Kanban style. In this initial phase for this feature,\nlet's call it \"Create Taskify,\" let's have multiple users but the users will be declared ahead of time, predefined. five users in two different categories, one product manager and four engineers. Let's create three\ndifferent sample projects. Let's have the standard Kanban columns for the status of each task, such as \"To Do,\"\n\"In Progress,\" \"In Review,\" and \"Done.\" There will be no login for this application as this is just the very\nfirst testing thing to ensure that our basic features are set up. For each task in the UI for a task card,\nyou should be able to change the current status of the task between the different columns in the Kanban work board.\nYou should be able to leave an unlimited number of comments for a particular card. You should be able to, from that task\ncard, assign one of the valid users. When you first launch Taskify, it's going to give you a list of the five users to pick\nfrom. There will be no password required. When you click on a user, you go into the main view, which displays the list of\nprojects. When you click on a project, you open the Kanban board for that project. You're going to see the columns.\nYou'll be able to drag and drop cards back and forth between different columns. You will see any cards that are\nassigned to you, the currently logged in user, in a different color from all the other ones, so you can quickly\nsee yours. You can edit any comments that you make, but you can't edit comments that other people made. You can\ndelete any comments that you made, but you can't delete comments anybody else made.\n```\n\nAfter this prompt is entered, you should see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.\n\nOnce this step is completed, you should have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text\nI want you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.",
      "Model Context Protocol (MCP) server that provides AI agents with powerful spec-driven development tools:\n\n```bash\n# Install the MCP server\npip install git+https://github.com/ASISaga/spec-kit.git\n\n# Run the MCP server\nspec-kit-mcp\n```\n\n### 2. Configure your AI agent\n\nAdd the Spec-Kit MCP server to your AI agent's configuration. The server provides these tools:\n\n**For New Projects:**\n- **init_project**: Initialize new Spec-Kit projects with templates\n- **create_new_feature**: Create feature branches with specifications  \n- **setup_plan**: Set up implementation plans\n- **check_task_prerequisites**: Validate task requirements\n- **update_agent_context**: Update agent context files\n- **get_feature_paths**: Get feature file paths\n- **run_script**: Execute cross-platform scripts\n- **check_requirements**: Check system requirements\n- **list_scripts**: Show available scripts and compatibility\n\n**For Existing Projects:**\n- **analyze_existing_project**: Analyze existing project structure and codebase\n- **parse_existing_documentation**: Extract requirements from existing documentation\n- **extract_requirements_from_code**: Extract specifications from code comments and docstrings\n- **generate_standardized_spec**: Generate Spec-Kit compatible specifications from analysis\n- **create_migration_plan**: Create detailed migration plans for adopting spec-driven development\n- **onboard_existing_project**: Complete end-to-end onboarding analysis\n\n**For Progressive Onboarding (NEW):**\n- **analyze_feature_component**: Analyze specific features/components within a project\n- **extract_feature_boundaries**: Identify logical feature boundaries for progressive onboarding\n- **onboard_project_feature**: Onboard individual features to spec-driven development\n- **merge_feature_specifications**: Combine multiple feature specifications into master specification\n- **detect_specification_conflicts**: Identify conflicts between feature specifications\n- **resolve_feature_dependencies**: Analyze and document dependencies between features\n- **create_progressive_migration_plan**: Create phased migration plans for incremental adoption\n- **track_onboarding_progress**: Track progress across multiple features/teams\n- **validate_specification_consistency**: Ensure consistency across progressive specifications\n\n### 3. Use with your AI agent\n\nOnce configured, your AI agent can use spec-driven development tools directly:\n\n**For New Projects:**\n- Create specifications that define the **what** and **why**, not the tech stack\n- Generate technical implementation plans with your chosen tech stack  \n- Break down features into actionable tasks\n- Manage the complete spec-driven development lifecycle\n\n**For Existing Projects:**\n- Analyze existing project structure and extract requirements\n- Parse documentation and code to understand current specifications\n- Generate standardized Spec-Kit compatible specifications\n- Create migration plans for adopting spec-driven development workflow\n- Onboard legacy projects to modern spec-driven approaches\n\n**For Progressive Onboarding (NEW):**\n- Analyze and onboard individual features or components incrementally\n- Support multiple teams working on different parts independently\n- Merge and coordinate specifications across features\n- Detect and resolve conflicts between feature specifications\n- Track progress and manage dependencies during progressive migration\n- Enable gradual adoption of spec-driven development across organizations\n\nFor detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).\nFor existing project onboarding, see our [onboarding guide](./ONBOARDING.md).\n\n## \ud83d\udcda Core philosophy\n\nSpec-Driven Development is a structured process that emphasizes:\n\n- **Intent-driven development** where specifications define the \"_what_\" before the \"_how_\"\n- **Rich specification creation** using guardrails and organizational principles\n- **Multi-step refinement** rather than one-shot code generation from prompts\n- **Heavy reliance** on advanced AI model capabilities for specification interpretation\n\n## \ud83c\udf1f Development phases\n\n| Phase | Focus | Key Activities |\n|-------|-------|----------------|\n| **0-to-1 Development** (\"Greenfield\") | Generate from scratch | <ul><li>Start with high-level requirements</li><li>Generate specifications</li><li>Plan implementation steps</li><li>Build production-ready applications</li></ul> |\n| **Creative Exploration** | Parallel implementations | <ul><li>Explore diverse solutions</li><li>Support multiple technology stacks & architectures</li><li>Experiment with UX patterns</li></ul> |\n| **Iterative Enhancement** (\"Brownfield\") | Brownfield modernization | <ul><li>Add features iteratively</li><li>Modernize legacy systems</li><li>Adapt processes</li></ul> |\n| **Existing Project Onboarding** (**ENHANCED**) | Legacy project migration | <ul><li>Analyze existing codebases and documentation</li><li>Extract and standardize requirements</li><li>Create migration plans</li><li>Adopt spec-driven workflows gradually</li></ul> |\n| **Progressive Onboarding** (**NEW**) | Incremental feature-level adoption | <ul><li>Onboard individual features and components</li><li>Support multi-team development workflows</li><li>Coordinate specifications across features</li><li>Enable gradual organizational adoption</li></ul> |\n\n## \ud83c\udfaf Experimental goals\n\nOur research and experimentation focus on:\n\n### Technology independence\n\n- Create applications using diverse technology stacks\n- Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks\n\n### Enterprise constraints\n\n- Demonstrate mission-critical application development\n- Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)\n- Support enterprise design systems and compliance requirements\n\n### User-centric development\n\n- Build applications for different user cohorts and preferences\n- Support various development approaches (from vibe-coding to AI-native development)\n\n### Creative & iterative processes\n\n- Validate the concept of parallel implementation exploration\n- Provide robust iterative feature development workflows\n- Extend processes to handle upgrades and modernization tasks  \n\n## \ud83d\udd27 Prerequisites\n\n- **Cross-platform**: Windows, Linux, macOS\n- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n- [uv](https://docs.astral.sh/uv/) for package management\n- [Python 3.11+](https://www.python.org/downloads/)\n- [Git](https://git-scm.com/downloads)\n\n## \ud83d\udcd6 Learn more\n\n- **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process\n- **[Detailed Walkthrough](#detailed-process)** - Step-by-step implementation guide\n\n---\n\n## Detailed process\n\n<details>\n<summary>Click to expand the detailed step-by-step walkthrough</summary>\n\nYou can use the Specify CLI to bootstrap your project, which will bring in the required artifacts in your environment. Run:\n\n```bash\nspecify init <project_name>\n```\n\nOr initialize in the current directory:\n\n```bash\nspecify init --here\n```\n\n![Specify CLI bootstrapping a new project in the terminal](./media/specify_cli.gif)\n\nYou will be prompted to select the AI agent you are using. You can also proactively specify it directly in the terminal:\n\n```bash\nspecify init <project_name> --ai claude\nspecify init <project_name> --ai gemini\nspecify init <project_name> --ai copilot\n# Or in current directory:\nspecify init --here --ai claude\n```\n\nThe CLI will check if you have Claude Code or Gemini CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:\n\n```bash\nspecify init <project_name> --ai claude --ignore-agent-tools\n```\n\n### **STEP 1:** Bootstrap the project\n\nGo to the project folder and run your AI agent. In our example, we're using `claude`.\n\n![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)\n\nYou will know that things are configured correctly if you see the `/specify`, `/plan`, and `/tasks` commands available.\n\nThe first step should be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.\n\n>[!IMPORTANT]\n>Be as explicit as possible about _what_ you are trying to build and _why_. **Do not focus on the tech stack at this point**.\n\nAn example prompt:\n\n```text\nDevelop Taskify, a team productivity platform. It should allow users to create projects, add team members,\nassign tasks, comment and move tasks between boards in Kanban style. In this initial phase for this feature,\nlet's call it \"Create Taskify,\" let's have multiple users but the users will be declared ahead of time, predefined. five users in two different categories, one product manager and four engineers. Let's create three\ndifferent sample projects. Let's have the standard Kanban columns for the status of each task, such as \"To Do,\"\n\"In Progress,\" \"In Review,\" and \"Done.\" There will be no login for this application as this is just the very\nfirst testing thing to ensure that our basic features are set up. For each task in the UI for a task card,\nyou should be able to change the current status of the task between the different columns in the Kanban work board.\nYou should be able to leave an unlimited number of comments for a particular card. You should be able to, from that task\ncard, assign one of the valid users. When you first launch Taskify, it's going to give you a list of the five users to pick\nfrom. There will be no password required. When you click on a user, you go into the main view, which displays the list of\nprojects. When you click on a project, you open the Kanban board for that project. You're going to see the columns.\nYou'll be able to drag and drop cards back and forth between different columns. You will see any cards that are\nassigned to you, the currently logged in user, in a different color from all the other ones, so you can quickly\nsee yours. You can edit any comments that you make, but you can't edit comments that other people made. You can\ndelete any comments that you made, but you can't delete comments anybody else made.\n```\n\nAfter this prompt is entered, you should see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.\n\nOnce this step is completed, you should have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text\nI want you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.",
      "new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.",
      "new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.",
      "Model Context Protocol (MCP) server that provides AI agents with powerful spec-driven development tools:\n\n```bash\n# Install the MCP server\npip install git+https://github.com/ASISaga/spec-kit.git\n\n# Run the MCP server\nspec-kit-mcp\n```\n\n### 2. Configure your AI agent\n\nAdd the Spec-Kit MCP server to your AI agent's configuration. The server provides these tools:\n\n**For New Projects:**\n- **init_project**: Initialize new Spec-Kit projects with templates\n- **create_new_feature**: Create feature branches with specifications  \n- **setup_plan**: Set up implementation plans\n- **check_task_prerequisites**: Validate task requirements\n- **update_agent_context**: Update agent context files\n- **get_feature_paths**: Get feature file paths\n- **run_script**: Execute cross-platform scripts\n- **check_requirements**: Check system requirements\n- **list_scripts**: Show available scripts and compatibility\n\n**For Existing Projects:**\n- **analyze_existing_project**: Analyze existing project structure and codebase\n- **parse_existing_documentation**: Extract requirements from existing documentation\n- **extract_requirements_from_code**: Extract specifications from code comments and docstrings\n- **generate_standardized_spec**: Generate Spec-Kit compatible specifications from analysis\n- **create_migration_plan**: Create detailed migration plans for adopting spec-driven development\n- **onboard_existing_project**: Complete end-to-end onboarding analysis\n\n**For Progressive Onboarding (NEW):**\n- **analyze_feature_component**: Analyze specific features/components within a project\n- **extract_feature_boundaries**: Identify logical feature boundaries for progressive onboarding\n- **onboard_project_feature**: Onboard individual features to spec-driven development\n- **merge_feature_specifications**: Combine multiple feature specifications into master specification\n- **detect_specification_conflicts**: Identify conflicts between feature specifications\n- **resolve_feature_dependencies**: Analyze and document dependencies between features\n- **create_progressive_migration_plan**: Create phased migration plans for incremental adoption\n- **track_onboarding_progress**: Track progress across multiple features/teams\n- **validate_specification_consistency**: Ensure consistency across progressive specifications\n\n### 3. Use with your AI agent\n\nOnce configured, your AI agent can use spec-driven development tools directly:\n\n**For New Projects:**\n- Create specifications that define the **what** and **why**, not the tech stack\n- Generate technical implementation plans with your chosen tech stack  \n- Break down features into actionable tasks\n- Manage the complete spec-driven development lifecycle\n\n**For Existing Projects:**\n- Analyze existing project structure and extract requirements\n- Parse documentation and code to understand current specifications\n- Generate standardized Spec-Kit compatible specifications\n- Create migration plans for adopting spec-driven development workflow\n- Onboard legacy projects to modern spec-driven approaches\n\n**For Progressive Onboarding (NEW):**\n- Analyze and onboard individual features or components incrementally\n- Support multiple teams working on different parts independently\n- Merge and coordinate specifications across features\n- Detect and resolve conflicts between feature specifications\n- Track progress and manage dependencies during progressive migration\n- Enable gradual adoption of spec-driven development across organizations\n\nFor detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).\nFor existing project onboarding, see our [onboarding guide](./ONBOARDING.md).\n\n## \ud83d\udcda Core philosophy\n\nSpec-Driven Development is a structured process that emphasizes:\n\n- **Intent-driven development** where specifications define the \"_what_\" before the \"_how_\"\n- **Rich specification creation** using guardrails and organizational principles\n- **Multi-step refinement** rather than one-shot code generation from prompts\n- **Heavy reliance** on advanced AI model capabilities for specification interpretation\n\n## \ud83c\udf1f Development phases\n\n| Phase | Focus | Key Activities |\n|-------|-------|----------------|\n| **0-to-1 Development** (\"Greenfield\") | Generate from scratch | <ul><li>Start with high-level requirements</li><li>Generate specifications</li><li>Plan implementation steps</li><li>Build production-ready applications</li></ul> |\n| **Creative Exploration** | Parallel implementations | <ul><li>Explore diverse solutions</li><li>Support multiple technology stacks & architectures</li><li>Experiment with UX patterns</li></ul> |\n| **Iterative Enhancement** (\"Brownfield\") | Brownfield modernization | <ul><li>Add features iteratively</li><li>Modernize legacy systems</li><li>Adapt processes</li></ul> |\n| **Existing Project Onboarding** (**ENHANCED**) | Legacy project migration | <ul><li>Analyze existing codebases and documentation</li><li>Extract and standardize requirements</li><li>Create migration plans</li><li>Adopt spec-driven workflows gradually</li></ul> |\n| **Progressive Onboarding** (**NEW**) | Incremental feature-level adoption | <ul><li>Onboard individual features and components</li><li>Support multi-team development workflows</li><li>Coordinate specifications across features</li><li>Enable gradual organizational adoption</li></ul> |\n\n## \ud83c\udfaf Experimental goals\n\nOur research and experimentation focus on:\n\n### Technology independence\n\n- Create applications using diverse technology stacks\n- Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks\n\n### Enterprise constraints\n\n- Demonstrate mission-critical application development\n- Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)\n- Support enterprise design systems and compliance requirements\n\n### User-centric development\n\n- Build applications for different user cohorts and preferences\n- Support various development approaches (from vibe-coding to AI-native development)\n\n### Creative & iterative processes\n\n- Validate the concept of parallel implementation exploration\n- Provide robust iterative feature development workflows\n- Extend processes to handle upgrades and modernization tasks  \n\n## \ud83d\udd27 Prerequisites\n\n- **Cross-platform**: Windows, Linux, macOS\n- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n- [uv](https://docs.astral.sh/uv/) for package management\n- [Python 3.11+](https://www.python.org/downloads/)\n- [Git](https://git-scm.com/downloads)\n\n## \ud83d\udcd6 Learn more\n\n- **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process\n- **[Detailed Walkthrough](#detailed-process)** - Step-by-step implementation guide\n\n---\n\n## Detailed process\n\n<details>\n<summary>Click to expand the detailed step-by-step walkthrough</summary>\n\nYou can use the Specify CLI to bootstrap your project, which will bring in the required artifacts in your environment. Run:\n\n```bash\nspecify init <project_name>\n```\n\nOr initialize in the current directory:\n\n```bash\nspecify init --here\n```\n\n![Specify CLI bootstrapping a new project in the terminal](./media/specify_cli.gif)\n\nYou will be prompted to select the AI agent you are using. You can also proactively specify it directly in the terminal:\n\n```bash\nspecify init <project_name> --ai claude\nspecify init <project_name> --ai gemini\nspecify init <project_name> --ai copilot\n# Or in current directory:\nspecify init --here --ai claude\n```\n\nThe CLI will check if you have Claude Code or Gemini CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:\n\n```bash\nspecify init <project_name> --ai claude --ignore-agent-tools\n```\n\n### **STEP 1:** Bootstrap the project\n\nGo to the project folder and run your AI agent. In our example, we're using `claude`.\n\n![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)\n\nYou will know that things are configured correctly if you see the `/specify`, `/plan`, and `/tasks` commands available.\n\nThe first step should be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.\n\n>[!IMPORTANT]\n>Be as explicit as possible about _what_ you are trying to build and _why_. **Do not focus on the tech stack at this point**.\n\nAn example prompt:\n\n```text\nDevelop Taskify, a team productivity platform. It should allow users to create projects, add team members,\nassign tasks, comment and move tasks between boards in Kanban style. In this initial phase for this feature,\nlet's call it \"Create Taskify,\" let's have multiple users but the users will be declared ahead of time, predefined. five users in two different categories, one product manager and four engineers. Let's create three\ndifferent sample projects. Let's have the standard Kanban columns for the status of each task, such as \"To Do,\"\n\"In Progress,\" \"In Review,\" and \"Done.\" There will be no login for this application as this is just the very\nfirst testing thing to ensure that our basic features are set up. For each task in the UI for a task card,\nyou should be able to change the current status of the task between the different columns in the Kanban work board.\nYou should be able to leave an unlimited number of comments for a particular card. You should be able to, from that task\ncard, assign one of the valid users. When you first launch Taskify, it's going to give you a list of the five users to pick\nfrom. There will be no password required. When you click on a user, you go into the main view, which displays the list of\nprojects. When you click on a project, you open the Kanban board for that project. You're going to see the columns.\nYou'll be able to drag and drop cards back and forth between different columns. You will see any cards that are\nassigned to you, the currently logged in user, in a different color from all the other ones, so you can quickly\nsee yours. You can edit any comments that you make, but you can't edit comments that other people made. You can\ndelete any comments that you made, but you can't delete comments anybody else made.\n```\n\nAfter this prompt is entered, you should see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.\n\nOnce this step is completed, you should have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text\nI want you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.",
      "Model Context Protocol (MCP) server that provides AI agents with powerful spec-driven development tools:\n\n```bash\n# Install the MCP server\npip install git+https://github.com/ASISaga/spec-kit.git\n\n# Run the MCP server\nspec-kit-mcp\n```\n\n### 2. Configure your AI agent\n\nAdd the Spec-Kit MCP server to your AI agent's configuration. The server provides these tools:\n\n**For New Projects:**\n- **init_project**: Initialize new Spec-Kit projects with templates\n- **create_new_feature**: Create feature branches with specifications  \n- **setup_plan**: Set up implementation plans\n- **check_task_prerequisites**: Validate task requirements\n- **update_agent_context**: Update agent context files\n- **get_feature_paths**: Get feature file paths\n- **run_script**: Execute cross-platform scripts\n- **check_requirements**: Check system requirements\n- **list_scripts**: Show available scripts and compatibility\n\n**For Existing Projects:**\n- **analyze_existing_project**: Analyze existing project structure and codebase\n- **parse_existing_documentation**: Extract requirements from existing documentation\n- **extract_requirements_from_code**: Extract specifications from code comments and docstrings\n- **generate_standardized_spec**: Generate Spec-Kit compatible specifications from analysis\n- **create_migration_plan**: Create detailed migration plans for adopting spec-driven development\n- **onboard_existing_project**: Complete end-to-end onboarding analysis\n\n**For Progressive Onboarding (NEW):**\n- **analyze_feature_component**: Analyze specific features/components within a project\n- **extract_feature_boundaries**: Identify logical feature boundaries for progressive onboarding\n- **onboard_project_feature**: Onboard individual features to spec-driven development\n- **merge_feature_specifications**: Combine multiple feature specifications into master specification\n- **detect_specification_conflicts**: Identify conflicts between feature specifications\n- **resolve_feature_dependencies**: Analyze and document dependencies between features\n- **create_progressive_migration_plan**: Create phased migration plans for incremental adoption\n- **track_onboarding_progress**: Track progress across multiple features/teams\n- **validate_specification_consistency**: Ensure consistency across progressive specifications\n\n### 3. Use with your AI agent\n\nOnce configured, your AI agent can use spec-driven development tools directly:\n\n**For New Projects:**\n- Create specifications that define the **what** and **why**, not the tech stack\n- Generate technical implementation plans with your chosen tech stack  \n- Break down features into actionable tasks\n- Manage the complete spec-driven development lifecycle\n\n**For Existing Projects:**\n- Analyze existing project structure and extract requirements\n- Parse documentation and code to understand current specifications\n- Generate standardized Spec-Kit compatible specifications\n- Create migration plans for adopting spec-driven development workflow\n- Onboard legacy projects to modern spec-driven approaches\n\n**For Progressive Onboarding (NEW):**\n- Analyze and onboard individual features or components incrementally\n- Support multiple teams working on different parts independently\n- Merge and coordinate specifications across features\n- Detect and resolve conflicts between feature specifications\n- Track progress and manage dependencies during progressive migration\n- Enable gradual adoption of spec-driven development across organizations\n\nFor detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).\nFor existing project onboarding, see our [onboarding guide](./ONBOARDING.md).\n\n## \ud83d\udcda Core philosophy\n\nSpec-Driven Development is a structured process that emphasizes:\n\n- **Intent-driven development** where specifications define the \"_what_\" before the \"_how_\"\n- **Rich specification creation** using guardrails and organizational principles\n- **Multi-step refinement** rather than one-shot code generation from prompts\n- **Heavy reliance** on advanced AI model capabilities for specification interpretation\n\n## \ud83c\udf1f Development phases\n\n| Phase | Focus | Key Activities |\n|-------|-------|----------------|\n| **0-to-1 Development** (\"Greenfield\") | Generate from scratch | <ul><li>Start with high-level requirements</li><li>Generate specifications</li><li>Plan implementation steps</li><li>Build production-ready applications</li></ul> |\n| **Creative Exploration** | Parallel implementations | <ul><li>Explore diverse solutions</li><li>Support multiple technology stacks & architectures</li><li>Experiment with UX patterns</li></ul> |\n| **Iterative Enhancement** (\"Brownfield\") | Brownfield modernization | <ul><li>Add features iteratively</li><li>Modernize legacy systems</li><li>Adapt processes</li></ul> |\n| **Existing Project Onboarding** (**ENHANCED**) | Legacy project migration | <ul><li>Analyze existing codebases and documentation</li><li>Extract and standardize requirements</li><li>Create migration plans</li><li>Adopt spec-driven workflows gradually</li></ul> |\n| **Progressive Onboarding** (**NEW**) | Incremental feature-level adoption | <ul><li>Onboard individual features and components</li><li>Support multi-team development workflows</li><li>Coordinate specifications across features</li><li>Enable gradual organizational adoption</li></ul> |\n\n## \ud83c\udfaf Experimental goals\n\nOur research and experimentation focus on:\n\n### Technology independence\n\n- Create applications using diverse technology stacks\n- Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks\n\n### Enterprise constraints\n\n- Demonstrate mission-critical application development\n- Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)\n- Support enterprise design systems and compliance requirements\n\n### User-centric development\n\n- Build applications for different user cohorts and preferences\n- Support various development approaches (from vibe-coding to AI-native development)\n\n### Creative & iterative processes\n\n- Validate the concept of parallel implementation exploration\n- Provide robust iterative feature development workflows\n- Extend processes to handle upgrades and modernization tasks  \n\n## \ud83d\udd27 Prerequisites\n\n- **Cross-platform**: Windows, Linux, macOS\n- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n- [uv](https://docs.astral.sh/uv/) for package management\n- [Python 3.11+](https://www.python.org/downloads/)\n- [Git](https://git-scm.com/downloads)\n\n## \ud83d\udcd6 Learn more\n\n- **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process\n- **[Detailed Walkthrough](#detailed-process)** - Step-by-step implementation guide\n\n---\n\n## Detailed process\n\n<details>\n<summary>Click to expand the detailed step-by-step walkthrough</summary>\n\nYou can use the Specify CLI to bootstrap your project, which will bring in the required artifacts in your environment. Run:\n\n```bash\nspecify init <project_name>\n```\n\nOr initialize in the current directory:\n\n```bash\nspecify init --here\n```\n\n![Specify CLI bootstrapping a new project in the terminal](./media/specify_cli.gif)\n\nYou will be prompted to select the AI agent you are using. You can also proactively specify it directly in the terminal:\n\n```bash\nspecify init <project_name> --ai claude\nspecify init <project_name> --ai gemini\nspecify init <project_name> --ai copilot\n# Or in current directory:\nspecify init --here --ai claude\n```\n\nThe CLI will check if you have Claude Code or Gemini CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:\n\n```bash\nspecify init <project_name> --ai claude --ignore-agent-tools\n```\n\n### **STEP 1:** Bootstrap the project\n\nGo to the project folder and run your AI agent. In our example, we're using `claude`.\n\n![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)\n\nYou will know that things are configured correctly if you see the `/specify`, `/plan`, and `/tasks` commands available.\n\nThe first step should be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.\n\n>[!IMPORTANT]\n>Be as explicit as possible about _what_ you are trying to build and _why_. **Do not focus on the tech stack at this point**.\n\nAn example prompt:\n\n```text\nDevelop Taskify, a team productivity platform. It should allow users to create projects, add team members,\nassign tasks, comment and move tasks between boards in Kanban style. In this initial phase for this feature,\nlet's call it \"Create Taskify,\" let's have multiple users but the users will be declared ahead of time, predefined. five users in two different categories, one product manager and four engineers. Let's create three\ndifferent sample projects. Let's have the standard Kanban columns for the status of each task, such as \"To Do,\"\n\"In Progress,\" \"In Review,\" and \"Done.\" There will be no login for this application as this is just the very\nfirst testing thing to ensure that our basic features are set up. For each task in the UI for a task card,\nyou should be able to change the current status of the task between the different columns in the Kanban work board.\nYou should be able to leave an unlimited number of comments for a particular card. You should be able to, from that task\ncard, assign one of the valid users. When you first launch Taskify, it's going to give you a list of the five users to pick\nfrom. There will be no password required. When you click on a user, you go into the main view, which displays the list of\nprojects. When you click on a project, you open the Kanban board for that project. You're going to see the columns.\nYou'll be able to drag and drop cards back and forth between different columns. You will see any cards that are\nassigned to you, the currently logged in user, in a different color from all the other ones, so you can quickly\nsee yours. You can edit any comments that you make, but you can't edit comments that other people made. You can\ndelete any comments that you made, but you can't delete comments anybody else made.\n```\n\nAfter this prompt is entered, you should see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.\n\nOnce this step is completed, you should have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text\nI want you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.",
      "### Example: Building a Chat Feature\n\nHere's how these commands transform the traditional development workflow:\n\n**Traditional Approach:**\n```\n1. Write a PRD in a document (2-3 hours)\n2. Create design documents (2-3 hours)\n3. Set up project structure manually (30 minutes)\n4. Write technical specifications (3-4 hours)\n5. Create test plans (2 hours)\nTotal: ~12 hours of documentation work\n```\n\n**SDD with Commands Approach:**\n```bash\n# Step 1: Create the feature specification (5 minutes)\n/new_feature Real-time chat system with message history and user presence\n\n# This automatically:\n# - Creates branch \"003-chat-system\"\n# - Generates specs/003-chat-system/feature-spec.md\n# - Populates it with structured requirements\n\n# Step 2: Generate implementation plan (10 minutes)\n/generate_plan WebSocket for real-time messaging, PostgreSQL for history, Redis for presence\n\n# This automatically creates:\n# - specs/003-chat-system/implementation-plan.md\n# - specs/003-chat-system/implementation-details/\n#   - 00-research.md (WebSocket library comparisons)\n#   - 02-data-model.md (Message and User schemas)\n#   - 03-api-contracts.md (WebSocket events, REST endpoints)\n#   - 06-contract-tests.md (Message flow scenarios)\n#   - 08-inter-library-tests.md (Database-WebSocket integration)\n# - specs/003-chat-system/manual-testing.md\n```\n\nIn 15 minutes, you have:\n- A complete feature specification with user stories and acceptance criteria\n- A detailed implementation plan with technology choices and rationale\n- API contracts and data models ready for code generation\n- Comprehensive test scenarios for both automated and manual testing\n- All documents properly versioned in a feature branch\n\n### The Power of Structured Automation\n\nThese commands don't just save time\u2014they enforce consistency and completeness:\n\n1. **No Forgotten Details**: Templates ensure every aspect is considered, from non-functional requirements to error handling\n2. **Traceable Decisions**: Every technical choice links back to specific requirements\n3. **Living Documentation**: Specifications stay in sync with code because they generate it\n4. **Rapid Iteration**: Change requirements and regenerate plans in minutes, not days\n\nThe commands embody SDD principles by treating specifications as executable artifacts rather than static documents. They transform the specification process from a necessary evil into the driving force of development.\n\n### Template-Driven Quality: How Structure Constrains LLMs for Better Outcomes\n\nThe true power of these commands lies not just in automation, but in how the templates guide LLM behavior toward higher-quality specifications. The templates act as sophisticated prompts that constrain the LLM's output in productive ways:\n\n#### 1. **Preventing Premature Implementation Details**\n\nThe feature specification template explicitly instructs:\n```\n- \u2705 Focus on WHAT users need and WHY\n- \u274c Avoid HOW to implement (no tech stack, APIs, code structure)\n```\n\nThis constraint forces the LLM to maintain proper abstraction levels. When an LLM might naturally jump to \"implement using React with Redux,\" the template keeps it focused on \"users need real-time updates of their data.\" This separation ensures specifications remain stable even as implementation technologies change.\n\n#### 2. **Forcing Explicit Uncertainty Markers**\n\nBoth templates mandate the use of `[NEEDS CLARIFICATION]` markers:\n```\nWhen creating this spec from a user prompt:\n1. **Mark all ambiguities**: Use [NEEDS CLARIFICATION: specific question] \n2. **Don't guess**: If the prompt doesn't specify something, mark it\n```\n\nThis prevents the common LLM behavior of making plausible but potentially incorrect assumptions. Instead of guessing that a \"login system\" uses email/password authentication, the LLM must mark it as `[NEEDS CLARIFICATION: auth method not specified - email/password, SSO, OAuth?]`.\n\n#### 3. **Structured Thinking Through Checklists**\n\nThe templates include comprehensive checklists that act as \"unit tests\" for the specification:\n```\n### Requirement Completeness\n- [ ] No [NEEDS CLARIFICATION] markers remain\n- [ ] Requirements are testable and unambiguous  \n- [ ] Success criteria are measurable\n```\n\nThese checklists force the LLM to self-review its output systematically, catching gaps that might otherwise slip through. It's like giving the LLM a quality assurance framework.\n\n#### 4. **Constitutional Compliance Through Gates**\n\nThe implementation plan template enforces architectural principles through phase gates:\n```\n### Phase -1: Pre-Implementation Gates\n#### Simplicity Gate (Article VII)\n- [ ] Using \u22643 projects?\n- [ ] No future-proofing?\n#### Anti-Abstraction Gate (Article VIII)\n- [ ] Using framework directly?\n- [ ] Single model representation?\n```\n\nThese gates prevent over-engineering by making the LLM explicitly justify any complexity. If a gate fails, the LLM must document why in the \"Complexity Tracking\" section, creating accountability for architectural decisions.\n\n#### 5. **Hierarchical Detail Management**\n\nThe templates enforce proper information architecture:\n```\n**IMPORTANT**: This implementation plan should remain high-level and readable. \nAny code samples, detailed algorithms, or extensive technical specifications \nmust be placed in the appropriate `implementation-details/` file\n```\n\nThis prevents the common problem of specifications becoming unreadable code dumps. The LLM learns to maintain appropriate detail levels, extracting complexity to separate files while keeping the main document navigable.\n\n#### 6. **Test-First Thinking**\n\nThe implementation template enforces test-first development:\n```\n### File Creation Order\n1. Create `contracts/` with API specifications\n2. Create test files in order: contract \u2192 integration \u2192 e2e \u2192 unit\n3. Create source files to make tests pass\n```\n\nThis ordering constraint ensures the LLM thinks about testability and contracts before implementation, leading to more robust and verifiable specifications.\n\n#### 7. **Preventing Speculative Features**\n\nTemplates explicitly discourage speculation:\n```\n- [ ] No speculative or \"might need\" features\n- [ ] All phases have clear prerequisites and deliverables\n```\n\nThis stops the LLM from adding \"nice to have\" features that complicate implementation. Every feature must trace back to a concrete user story with clear acceptance criteria.\n\n### The Compound Effect\n\nThese constraints work together to produce specifications that are:\n- **Complete**: Checklists ensure nothing is forgotten\n- **Unambiguous**: Forced clarification markers highlight uncertainties\n- **Testable**: Test-first thinking baked into the process\n- **Maintainable**: Proper abstraction levels and information hierarchy\n- **Implementable**: Clear phases with concrete deliverables\n\nThe templates transform the LLM from a creative writer into a disciplined specification engineer, channeling its capabilities toward producing consistently high-quality, executable specifications that truly drive development.\n\n## The Constitutional Foundation: Enforcing Architectural Discipline\n\nAt the heart of SDD lies a constitution\u2014a set of immutable principles that govern how specifications become code. The constitution (`base/memory/constitution.md`) acts as the architectural DNA of the system, ensuring that every generated implementation maintains consistency, simplicity, and quality.\n\n### The Nine Articles of Development\n\nThe constitution defines nine articles that shape every aspect of the development process:\n\n#### Article I: Library-First Principle\nEvery feature must begin as a standalone library\u2014no exceptions. This forces modular design from the start:\n```\nEvery feature in Specify MUST begin its existence as a standalone library. \nNo feature shall be implemented directly within application code without \nfirst being abstracted into a reusable library component.\n```\n\nThis principle ensures that specifications generate modular, reusable code rather than monolithic applications. When the LLM generates an implementation plan, it must structure features as libraries with clear boundaries and minimal dependencies.\n\n#### Article II: CLI Interface Mandate\nEvery library must expose its functionality through a command-line interface:\n```\nAll CLI interfaces MUST:\n- Accept text as input (via stdin, arguments, or files)\n- Produce text as output (via stdout)\n- Support JSON format for structured data exchange\n```\n\nThis enforces observability and testability. The LLM cannot hide functionality inside opaque classes\u2014everything must be accessible and verifiable through text-based interfaces.\n\n#### Article III: Test-First Imperative\nThe most transformative article\u2014no code before tests:\n```\nThis is NON-NEGOTIABLE: All implementation MUST follow strict Test-Driven Development.\nNo implementation code shall be written before:\n1. Unit tests are written\n2. Tests are validated and approved by the user\n3. Tests are confirmed to FAIL (Red phase)\n```\n\nThis completely inverts traditional AI code generation. Instead of generating code and hoping it works, the LLM must first generate comprehensive tests that define behavior, get them approved, and only then generate implementation.\n\n#### Articles VII & VIII: Simplicity and Anti-Abstraction\nThese paired articles combat over-engineering:\n```\nSection 7.3: Minimal Project Structure\n- Maximum 3 projects for initial implementation\n- Additional projects require documented justification\n\nSection 8.1: Framework Trust\n- Use framework features directly rather than wrapping them\n```\n\nWhen an LLM might naturally create elaborate abstractions, these articles force it to justify every layer of complexity. The implementation plan template's \"Phase -1 Gates\" directly enforce these principles.\n\n#### Article IX: Integration-First Testing\nPrioritizes real-world testing over isolated unit tests:\n```\nTests MUST use realistic environments:\n- Prefer real databases over mocks\n- Use actual service instances over stubs\n- Contract tests mandatory before implementation\n```\n\nThis ensures generated code works in practice, not just in theory.\n\n### Constitutional Enforcement Through Templates\n\nThe implementation plan template operationalizes these articles through concrete checkpoints:\n\n```markdown\n### Phase -1: Pre-Implementation Gates\n#### Simplicity Gate (Article VII)\n- [ ] Using \u22643 projects?\n- [ ] No future-proofing?\n\n#### Anti-Abstraction Gate (Article VIII)\n- [ ] Using framework directly?\n- [ ] Single model representation?\n\n#### Integration-First Gate (Article IX)\n- [ ] Contracts defined?\n- [ ] Contract tests written?\n```\n\nThese gates act as compile-time checks for architectural principles. The LLM cannot proceed without either passing the gates or documenting justified exceptions in the \"Complexity Tracking\" section.\n\n### The Power of Immutable Principles\n\nThe constitution's power lies in its immutability. While implementation details can evolve, the core principles remain constant. This provides:\n\n1. **Consistency Across Time**: Code generated today follows the same principles as code generated next year\n2. **Consistency Across LLMs**: Different AI models produce architecturally compatible code\n3. **Architectural Integrity**: Every feature reinforces rather than undermines the system design\n4. **Quality Guarantees**: Test-first, library-first, and simplicity principles ensure maintainable code\n\n### Constitutional Evolution\n\nWhile principles are immutable, their application can evolve:\n```\nSection 4.2: Amendment Process\nModifications to this constitution require:\n- Explicit documentation of the rationale for change\n- Review and approval by project maintainers\n- Backwards compatibility assessment\n```\n\nThis allows the methodology to learn and improve while maintaining stability. The constitution shows its own evolution with dated amendments, demonstrating how principles can be refined based on real-world experience.\n\n### Beyond Rules: A Development Philosophy\n\nThe constitution isn't just a rulebook\u2014it's a philosophy that shapes how LLMs think about code generation:\n\n- **Observability Over Opacity**: Everything must be inspectable through CLI interfaces\n- **Simplicity Over Cleverness**: Start simple, add complexity only when proven necessary\n- **Integration Over Isolation**: Test in real environments, not artificial ones\n- **Modularity Over Monoliths**: Every feature is a library with clear boundaries\n\nBy embedding these principles into the specification and planning process, SDD ensures that generated code isn't just functional\u2014it's maintainable, testable, and architecturally sound. The constitution transforms AI from a code generator into an architectural partner that respects and reinforces system design principles.\n\n## The Transformation\n\nThis isn't about replacing developers or automating creativity. It's about amplifying human capability by automating mechanical translation. It's about creating a tight feedback loop where specifications, research, and code evolve together, each iteration bringing deeper understanding and better alignment between intent and implementation.\n\nSoftware development needs better tools for maintaining alignment between intent and implementation. SDD provides the methodology for achieving this alignment through executable specifications that generate code rather than merely guiding it.",
      "\u2192 integration test task\n- Implementation tasks to make tests pass\n\n**Ordering Strategy**:\n- TDD order: Tests before implementation \n- Dependency order: Models before services before UI\n- Mark [P] for parallel execution (independent files)\n\n**Estimated Output**: 25-30 numbered, ordered tasks in tasks.md\n\n**IMPORTANT**: This phase is executed by the /tasks command, NOT by /plan\n\n## Phase 3+: Future Implementation\n*These phases are beyond the scope of the /plan command*\n\n**Phase 3**: Task execution (/tasks command creates tasks.md)  \n**Phase 4**: Implementation (execute tasks.md following constitutional principles)  \n**Phase 5**: Validation (run tests, execute quickstart.md, performance validation)\n\n## Complexity Tracking\n*Fill ONLY if Constitution Check has violations that must be justified*\n\n| Violation | Why Needed | Simpler Alternative Rejected Because |\n|-----------|------------|-------------------------------------|\n| [e.g., 4th project] | [current need] | [why 3 projects insufficient] |\n| [e.g., Repository pattern] | [specific problem] | [why direct DB access insufficient] |\n\n\n## Progress Tracking\n*This checklist is updated during execution flow*\n\n**Phase Status**:\n- [ ] Phase 0: Research complete (/plan command)\n- [ ] Phase 1: Design complete (/plan command)\n- [ ] Phase 2: Task planning complete (/plan command - describe approach only)\n- [ ] Phase 3: Tasks generated (/tasks command)\n- [ ] Phase 4: Implementation complete\n- [ ] Phase 5: Validation passed\n\n**Gate Status**:\n- [ ] Initial Constitution Check: PASS\n- [ ] Post-Design Constitution Check: PASS\n- [ ] All NEEDS CLARIFICATION resolved\n- [ ] Complexity deviations documented\n\n---\n*Based on Constitution v2.1.1 - See `/memory/constitution.md`*",
      "[Describe the main user journey in plain language]\n\n### Acceptance Scenarios\n1. **Given** [initial state], **When** [action], **Then** [expected outcome]\n2. **Given** [initial state], **When** [action], **Then** [expected outcome]\n\n### Edge Cases\n- What happens when [boundary condition]?\n- How does system handle [error scenario]?\n\n## Requirements *(mandatory)*\n\n### Functional Requirements\n- **FR-001**: System MUST [specific capability, e.g., \"allow users to create accounts\"]\n- **FR-002**: System MUST [specific capability, e.g., \"validate email addresses\"]  \n- **FR-003**: Users MUST be able to [key interaction, e.g., \"reset their password\"]\n- **FR-004**: System MUST [data requirement, e.g., \"persist user preferences\"]\n- **FR-005**: System MUST [behavior, e.g., \"log all security events\"]\n\n*Example of marking unclear requirements:*\n- **FR-006**: System MUST authenticate users via [NEEDS CLARIFICATION: auth method not specified - email/password, SSO, OAuth?]\n- **FR-007**: System MUST retain user data for [NEEDS CLARIFICATION: retention period not specified]\n\n### Key Entities *(include if feature involves data)*\n- **[Entity 1]**: [What it represents, key attributes without implementation]\n- **[Entity 2]**: [What it represents, relationships to other entities]\n\n---\n\n## Review & Acceptance Checklist\n*GATE: Automated checks run during main() execution*\n\n### Content Quality\n- [ ] No implementation details (languages, frameworks, APIs)\n- [ ] Focused on user value and business needs\n- [ ] Written for non-technical stakeholders\n- [ ] All mandatory sections completed\n\n### Requirement Completeness\n- [ ] No [NEEDS CLARIFICATION] markers remain\n- [ ] Requirements are testable and unambiguous  \n- [ ] Success criteria are measurable\n- [ ] Scope is clearly bounded\n- [ ] Dependencies and assumptions identified\n\n---\n\n## Execution Status\n*Updated by main() during processing*\n\n- [ ] User description parsed\n- [ ] Key concepts extracted\n- [ ] Ambiguities marked\n- [ ] User scenarios defined\n- [ ] Requirements generated\n- [ ] Entities identified\n- [ ] Review checklist passed\n\n---",
      "\u2192 integration test marked [P]\n   - Different files = can be parallel [P]\n   - Same file = sequential (no [P])\n\n5. Order tasks by dependencies:\n   - Setup before everything\n   - Tests before implementation (TDD)\n   - Models before services\n   - Services before endpoints\n   - Core before integration\n   - Everything before polish\n\n6. Include parallel execution examples:\n   - Group [P] tasks that can run together\n   - Show actual Task agent commands\n\n7. Create FEATURE_DIR/tasks.md with:\n   - Correct feature name from implementation plan\n   - Numbered tasks (T001, T002, etc.)\n   - Clear file paths for each task\n   - Dependency notes\n   - Parallel execution guidance\n\nContext for task generation: {ARGS}\n\nThe tasks.md should be immediately executable - each task must be specific enough that an LLM can complete it without additional context."
    ],
    "api_endpoints_found": [
      "Get started",
      "Get started",
      "Get feature",
      "get the",
      "delete any",
      "delete comments",
      "put of",
      "get to",
      "get https://github",
      "created",
      "spec",
      "Get started",
      "Get started",
      "get the",
      "delete any",
      "delete comments",
      "put of",
      "get to",
      "get https://github",
      "created",
      "spec",
      "Get started",
      "Get started",
      "Get feature",
      "get the",
      "delete any",
      "delete comments",
      "put of",
      "get to",
      "get https://github",
      "created",
      "spec",
      "get help",
      "put that",
      "put in",
      "put systematically",
      "get them",
      "endpoints",
      "endpoints",
      "contracts",
      "contracts",
      "contracts",
      "specifications",
      "put formats",
      "conflicts",
      "endpoint",
      "POST /api/users",
      "GET /api/users/{id}",
      "POST /api/users",
      "GET /api/users/{id}",
      "put validation",
      "POST /api/users",
      "GET /api/users/{id}",
      "-",
      "-",
      "put path",
      "get Platform",
      "patch research",
      "put OpenAPI/GraphQL",
      "put to",
      "Use",
      "Assert",
      "contracts",
      "put path",
      "endpoints",
      "put for"
    ],
    "technologies_mentioned": [
      "gitlab",
      "docker",
      "react",
      "rails",
      "typescript",
      "rest",
      "python",
      "postgresql",
      "redis",
      ".net",
      "dotnet",
      "spring",
      "github",
      "api",
      "graphql",
      "git",
      "fastapi",
      "javascript",
      "java",
      "express"
    ],
    "parsing_errors": []
  },
  "code_analysis": {
    "project_path": "/home/runner/work/spec-kit/spec-kit",
    "files_analyzed": [
      "scripts/py/check_task_prerequisites.py",
      "scripts/py/create_new_feature.py",
      "scripts/py/__init__.py",
      "scripts/py/get_feature_paths.py",
      "scripts/py/update_agent_context.py",
      "scripts/py/common.py",
      "scripts/py/setup_plan.py",
      "src/spec_kit_mcp/scripts.py",
      "src/spec_kit_mcp/__init__.py",
      "src/spec_kit_mcp/server.py",
      "src/spec_kit_mcp/onboarding.py",
      "src/spec_kit_mcp/cli.py",
      "pyproject.toml"
    ],
    "comments_found": [
      {
        "file": "scripts/py/check_task_prerequisites.py",
        "comment": "!/usr/bin/env python3",
        "type": "single_line"
      },
      {
        "file": "scripts/py/check_task_prerequisites.py",
        "comment": "Import from common module",
        "type": "single_line"
      },
      {
        "file": "scripts/py/check_task_prerequisites.py",
        "comment": "Get all paths",
        "type": "single_line"
      },
      {
        "file": "scripts/py/check_task_prerequisites.py",
        "comment": "Check if on feature branch",
        "type": "single_line"
      },
      {
        "file": "scripts/py/check_task_prerequisites.py",
        "comment": "Check if feature directory exists",
        "type": "single_line"
      },
      {
        "file": "scripts/py/check_task_prerequisites.py",
        "comment": "Check for implementation plan (required)",
        "type": "single_line"
      },
      {
        "file": "scripts/py/check_task_prerequisites.py",
        "comment": "Build JSON array of available docs that actually exist",
        "type": "single_line"
      },
      {
        "file": "scripts/py/check_task_prerequisites.py",
        "comment": "List available design documents (optional)",
        "type": "single_line"
      },
      {
        "file": "scripts/py/check_task_prerequisites.py",
        "comment": "Use common check functions",
        "type": "single_line"
      },
      {
        "file": "scripts/py/check_task_prerequisites.py",
        "comment": "Always succeed - task generation should work with whatever docs are available",
        "type": "single_line"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "comment": "!/usr/bin/env python3",
        "type": "single_line"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "comment": "Import from common module",
        "type": "single_line"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "comment": "Get repository root",
        "type": "single_line"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "comment": "Create specs directory if it doesn't exist",
        "type": "single_line"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "comment": "Get next feature number",
        "type": "single_line"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "comment": "Create branch name from description",
        "type": "single_line"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "comment": "Final branch name",
        "type": "single_line"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "comment": "Create and switch to new branch",
        "type": "single_line"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "comment": "Create feature directory",
        "type": "single_line"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "comment": "Copy template if it exists",
        "type": "single_line"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "comment": "Output results",
        "type": "single_line"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "comment": "Output results for the LLM to use (legacy key: value format)",
        "type": "single_line"
      },
      {
        "file": "scripts/py/get_feature_paths.py",
        "comment": "!/usr/bin/env python3",
        "type": "single_line"
      },
      {
        "file": "scripts/py/get_feature_paths.py",
        "comment": "Import from common module",
        "type": "single_line"
      },
      {
        "file": "scripts/py/get_feature_paths.py",
        "comment": "Get all paths",
        "type": "single_line"
      },
      {
        "file": "scripts/py/get_feature_paths.py",
        "comment": "Check if on feature branch",
        "type": "single_line"
      },
      {
        "file": "scripts/py/get_feature_paths.py",
        "comment": "Output paths (don't create anything)",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "!/usr/bin/env python3",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Import from common module",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Extract tech information using regex patterns",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Filter out placeholder values",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Replace placeholders",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Add project structure based on type",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Add commands based on language",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Add commands for {tech_info.get('language', 'your language')}\"",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Add code style",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Add recent changes",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Write the new file",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Extract manual additions if they exist",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Remove manual additions from content for processing",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Update Active Technologies section",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "# Active Technologies\\n(.*?)\\n\\n', content, re.DOTALL)",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Add new tech if not already present",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "# Active Technologies\\n{updated_tech}\\n\\n\"",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Update project structure if needed for web projects",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "# Project Structure\\n```\\n(.*?)\\n```', content, re.DOTALL)",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Web UI\"",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "# Project Structure\\n```\\n).*?(\\n```)',",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Add new commands if language is new",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "{language}\" not in content:",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "# Commands\\n```bash\\n(.*?)\\n```', content, re.DOTALL)",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "# Commands\\n(.*?)\\n\\n', content, re.DOTALL)",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "# Commands\\n```bash\\n).*?(\\n```)',",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "# Commands\\n).*?(\\n\\n)',",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Update recent changes (keep only last 3)",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "# Recent Changes\\n(.*?)(\\n\\n|$)', content, re.DOTALL)",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Add new change at the beginning",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Keep only last 3",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "# Recent Changes\\n).*?(\\n\\n|$)',",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Update date",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Add back manual additions if they existed",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Write the updated file",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Get repository information",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Check if plan exists",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Extract tech information from plan",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Define agent context files",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Update files based on argument or detect existing files",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Update specific agent file",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Update all existing files",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "If no files exist, create Claude Code context file by default",
        "type": "single_line"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "comment": "Print summary",
        "type": "single_line"
      },
      {
        "file": "scripts/py/common.py",
        "comment": "!/usr/bin/env python3",
        "type": "single_line"
      },
      {
        "file": "scripts/py/common.py",
        "comment": "Convert to lowercase and replace non-alphanumeric with hyphens",
        "type": "single_line"
      },
      {
        "file": "scripts/py/common.py",
        "comment": "Remove multiple consecutive hyphens",
        "type": "single_line"
      },
      {
        "file": "scripts/py/common.py",
        "comment": "Remove leading/trailing hyphens",
        "type": "single_line"
      },
      {
        "file": "scripts/py/common.py",
        "comment": "Extract 2-3 meaningful words",
        "type": "single_line"
      },
      {
        "file": "scripts/py/setup_plan.py",
        "comment": "!/usr/bin/env python3",
        "type": "single_line"
      },
      {
        "file": "scripts/py/setup_plan.py",
        "comment": "Import from common module",
        "type": "single_line"
      },
      {
        "file": "scripts/py/setup_plan.py",
        "comment": "Get all paths",
        "type": "single_line"
      },
      {
        "file": "scripts/py/setup_plan.py",
        "comment": "Check if on feature branch",
        "type": "single_line"
      },
      {
        "file": "scripts/py/setup_plan.py",
        "comment": "Create feature directory if it doesn't exist",
        "type": "single_line"
      },
      {
        "file": "scripts/py/setup_plan.py",
        "comment": "Copy plan template if it exists",
        "type": "single_line"
      },
      {
        "file": "scripts/py/setup_plan.py",
        "comment": "Output results",
        "type": "single_line"
      },
      {
        "file": "scripts/py/setup_plan.py",
        "comment": "Output all paths for LLM use",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "comment": "On Windows, try Python script first, then bash (if available)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "comment": "Fallback to bash script if Python isn't available",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "comment": "On Unix, try bash script first, then Python as fallback",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "comment": "Fallback to Python script",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "comment": "Try to find repo root",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "comment": "Build command based on script type",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "comment": "Run the command",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "comment": "Try to parse JSON output if --json was in args",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "comment": "Not JSON, return as-is",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "comment": "Check bash scripts",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "comment": "Check Python scripts",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "comment": "Try to run the script with --help to test basic functionality",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "!/usr/bin/env python3",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "MCP imports",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Import our existing functionality",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Progressive onboarding functions",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Set up logging",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Create the MCP server",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Validate AI assistant",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Determine project directory",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Check git availability if needed",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "git-scm.com/downloads\")",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Check agent tools unless ignored",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "docs.anthropic.com/en/docs/claude-code/setup\"):",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "github.com/google-gemini/gemini-cli\"):",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Download and extract template",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Initialize git repository if needed",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Clean up project directory if created and not current directory",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Check internet connectivity",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "api.github.com\", timeout=5, follow_redirects=True)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "git-scm.com/downloads\")",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "docs.anthropic.com/en/docs/claude-code/setup\")",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "github.com/google-gemini/gemini-cli\")",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Show summary",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "JSON output",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Text output",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "JSON output",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Text output",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "JSON output",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Text output",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Step 1: Analyze project structure",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Step 2: Parse documentation",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Step 3: Extract from code",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Step 4: Generate standardized spec",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Step 5: Create migration plan (if requested)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Combine all results",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "comment": "Progressive Onboarding Handler Functions",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "!/usr/bin/env python3",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Common file patterns to analyze",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Convert string to Path if needed",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Scan directory structure",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Skip deep directories and common ignore patterns",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Estimate project size",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Convert sets to lists for JSON serialization",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Categorize by type",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Detect languages",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Detect frameworks and tools",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for tests",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for CI/CD",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Convert string to Path if needed",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Convert sets to lists for JSON serialization",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Try to read first few bytes to check if it's text",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Null bytes indicate binary",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Try to decode as UTF-8",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Try with different encoding",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Store content sections",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Extract requirements-like content",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Look for requirement-like patterns",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Filter out very short matches",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Common technologies to look for",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Convert string to Path if needed",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Skip binary or non-UTF8 files",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Extract comments",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Extract docstrings (Python-specific for now)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Extract TODO/FIXME items",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Single line comments (// or #)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "|#)\\s*(.+)'",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Multi-line comments (/* ... */)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Filter very short comments",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Triple quoted strings (docstrings)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Project Overview",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Requirements",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Non-functional requirements",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "User stories",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Technical details",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "API specification",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Data model",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Implementation guidance",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Quality assurance",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Gaps and recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Basic project info",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "{project_name}\")",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Languages and technologies",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Documentation summary",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "From documentation",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "From features",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Based on project characteristics",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Based on technologies",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "From documentation",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Generate from features if no explicit stories found",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Limit to first 20 endpoints",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "This is a placeholder - could be enhanced to parse actual data models from code",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "TODO items from code",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "FIXME items",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Documentation gaps",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Technical gaps",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Code quality gaps",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Documentation recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Requirements recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Technical recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Process recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Phase 1: Assessment and Planning",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Phase 2: Specification Creation",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Phase 3: Process Integration",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Phase 4: Pilot Implementation",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Phase 5: Full Adoption",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Could be enhanced to estimate team size",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Progressive Onboarding Functions",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Analyze feature directory structure",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Skip deep directories and common ignore patterns",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Estimate complexity",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Analyze external dependencies and references",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Identify potential sub-feature boundaries",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Convert sets to lists for JSON serialization",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Categorize by type",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for test files",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Detect languages (same logic as before)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "', '.cpp': 'C++', '.c': 'C',",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Detect frameworks and dependencies specific to this feature",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Look for import statements and external references in code files",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Extract import statements and external references",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Python imports",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check if it's an external reference (not within the current feature)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "JavaScript/TypeScript imports",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "This is a simplified check - could be enhanced for more accurate detection",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check if the reference corresponds to a file within the feature",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check if it's within the project but outside the feature",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "It's in the project but external to the feature",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Assume external if we can't determine",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check if subdirectory has enough content to be a separate feature",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Arbitrary threshold for potential sub-feature",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Convert string to Path if needed",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Analyze top-level directories as potential features",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Define boundary criteria used",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Collect files within the directory",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for tests and documentation",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Calculate confidence score",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "File count criteria",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Quality indicators",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Logical cohesion (simplified check)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Step 1: Analyze feature structure",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Step 2: Parse feature documentation",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Step 3: Extract from feature code",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Step 4: Generate feature specification",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Step 5: Analyze dependencies if requested",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Combine results",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Analyze external references from the feature",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Look for references TO this feature from other parts of the project",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Calculate integration complexity",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Search for imports/references to this feature in other files",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Skip files within the feature itself",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Look for imports or references to the feature",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Limit to first 10 references",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Basic recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Integration-specific recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Spec-driven recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "File organization",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Code quality indicators",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Dependency management",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Complexity assessment",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Determine readiness level",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Specification Assembly and Coordination Functions",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Initialize master specification",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Process each feature specification",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Merge functional requirements",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Merge non-functional requirements",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Merge user stories",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Merge technical stack",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Merge API specifications",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Collect implementation notes",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Collect gaps",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Convert sets to lists for serialization",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Generate master overview",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Generate coordination recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Analyze potential conflicts",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "{project_name}\")",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Technical stack summary",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Feature summary",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Technical coordination",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Process coordination",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Conflict resolution",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for API endpoint conflicts",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for conflicting requirements",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for technology stack conflicts",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Generate resolution suggestions",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Extract endpoint from API specification (simplified)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Simple pattern matching for common endpoint formats",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "This is a simplified conflict detection - could be enhanced with NLP",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Extract key terms from requirements (simplified)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for conflicting statements",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Simple keyword extraction - could be enhanced with NLP",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Simple conflict detection based on contradictory keywords",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for conflicting technology choices",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for potential conflicts (e.g., different versions)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Simple conflict detection - could be enhanced",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Same base technology but potentially different versions",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Known conflicting technologies",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "General suggestions",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Extract feature names and paths",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Analyze dependencies between features",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check if feature_a depends on feature_b",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Detect circular dependencies",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Identify critical dependencies",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Generate implementation order",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Create resolution plan",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for explicit references in external_references",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for API dependencies (simplified)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "If feature_a references endpoints that feature_b provides",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Cap at 1.0",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "This is a simplified classification - could be enhanced",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for API dependencies",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for data dependencies",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for service dependencies",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Limit to first 5 details",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check each pair of features for circular dependencies",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check if A -> B and B -> A",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "High strength dependencies",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "API dependencies are often critical",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Calculate dependency counts (how many features depend on each feature)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Sort by dependency count (features with fewer dependencies first)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Limit to first 5",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "General recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Progressive Workflow Management Functions",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Prioritize features for migration",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Create progressive migration phases",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Estimate timeline",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Plan resource allocation",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Define success metrics",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Risk mitigation strategies",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Coordination plan",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Add priority features first",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Add remaining features based on complexity and dependencies",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Sort by complexity (simple features first) and confidence score",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Phase 1: Pilot - Start with 1-2 simple features",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Phase 2: Expansion - Add more features gradually",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Final phase: Integration and optimization",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Base time estimates",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Calculate based on feature count and complexity",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "3)  # Subtract pilot features",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "4}-{(total_weeks + 4) // 4} months)\"",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Calculate overall progress",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Track phase progress",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Integration phase",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Track individual feature status",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Generate recommendations and next actions",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Find current phase",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "General actions",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check for potential issues",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Validate format consistency",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Validate naming consistency",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Validate requirement consistency",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Validate technical consistency",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Calculate overall consistency score",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Determine overall status",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Generate recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Define expected sections",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check if all specs have required sections",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check section naming consistency (simplified)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Placeholder",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Placeholder",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check feature naming patterns",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check requirement numbering consistency (simplified)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Placeholder",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Placeholder",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check requirement format consistency",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Simple format check - requirements should start with \"REQ-\" or similar",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Placeholder",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Placeholder",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Check technology stack alignment",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Higher consistency if fewer different technologies are used",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Placeholder",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Placeholder",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Format recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Naming recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "Technical recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "comment": "General recommendations",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "!/usr/bin/env python3",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "/// script",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "requires-python = \">=3.11\"",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "dependencies = [",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "\"typer\",",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "\"rich\",",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "\"platformdirs\",",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "\"readchar\",",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "\"httpx\",",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "For cross-platform keyboard input",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Constants",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "ASCII Art Banner",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "list of dicts: {key, label, status, detail}",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "callable to trigger UI refresh",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "If not present, add it",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Circles (unchanged styling)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Entire line light gray (pending)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Label white, detail (if any) light gray in parentheses",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Arrow keys",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Enter/Return",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Escape",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Ctrl+C",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Suppress explicit selection print; tracker / later logic will report consolidated status",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Show banner before help",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Create gradient effect with different colors",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Show banner only when no subcommand and no help flag",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "(help is handled by BannerGroup)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Use git command to check if inside a work tree",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "api.github.com/repos/{repo_owner}/{repo_name}/releases/latest\"",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Find the template asset for the specified AI assistant",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Use the first matching asset",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Download the file",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "No content-length header, download without progress",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Show progress bar",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Silent download loop",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Step: fetch + download combined",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "already downloaded inside helper",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Create project directory only if not using current directory",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "List all files in the ZIP for debugging",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "For current directory, extract to a temp location first",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Check what was extracted",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Handle GitHub-style ZIP with a single root directory",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Copy contents to current directory",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Recursively copy directory contents",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Extract directly to project directory (original behavior)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Check what was extracted",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Handle GitHub-style ZIP with a single root directory",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Move contents up one level",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Move the nested directory contents to temp location",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Remove the now-empty project directory",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Rename temp directory to project directory",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Clean up project directory if created and not current directory",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Clean up downloaded ZIP file",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Show banner first",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Validate arguments",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Determine project directory",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Check if current directory has any files",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Ask for confirmation",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Check if project directory already exists",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Check git only if we might need it (not --no-git)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "git-scm.com/downloads\")",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "AI assistant selection",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Use arrow-key selection interface",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Check agent tools unless ignored",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "docs.anthropic.com/en/docs/claude-code/setup\"):",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "github.com/google-gemini/gemini-cli\"):",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "GitHub Copilot check is not needed as it's typically available in supported IDEs",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Download and set up project",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "New tree-based progress (no emojis); include earlier substeps",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Flag to allow suppressing legacy headings",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Pre steps recorded as completed before live rendering",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Use transient so live tree is replaced by the final static render (avoids duplicate output)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Git step",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Force final render",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Final static tree (ensures finished state visible after Live context ends)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Boxed \"Next steps\" section",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "blank line",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Removed farewell line per user request",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Import here to avoid import errors if scripts.py has issues",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Get available scripts",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Show summary",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "Check if we have internet connectivity by trying to reach GitHub API",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "api.github.com\", timeout=5, follow_redirects=True)",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "git-scm.com/downloads\")",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "docs.anthropic.com/en/docs/claude-code/setup\")",
        "type": "single_line"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "comment": "github.com/google-gemini/gemini-cli\")",
        "type": "single_line"
      }
    ],
    "docstrings_found": [
      {
        "file": "scripts/py/check_task_prerequisites.py",
        "docstring": "Check that implementation plan exists and find optional design documents.\nPython equivalent of check-task-prerequisites.sh for cross-platform compatibility.\n\nUsage: python check_task_prerequisites.py [--json]"
      },
      {
        "file": "scripts/py/create_new_feature.py",
        "docstring": "Create a new feature with branch, directory structure, and template.\nPython equivalent of create-new-feature.sh for cross-platform compatibility.\n\nUsage: python create_new_feature.py \"feature description\" [--json]"
      },
      {
        "file": "scripts/py/__init__.py",
        "docstring": "Python equivalents of bash scripts for cross-platform compatibility.\nThis package provides Windows-compatible versions of the spec-kit shell scripts."
      },
      {
        "file": "scripts/py/get_feature_paths.py",
        "docstring": "Get paths for current feature branch without creating anything.\nPython equivalent of get-feature-paths.sh for cross-platform compatibility.\nUsed by commands that need to find existing feature files.\n\nUsage: python get_feature_paths.py [--json]"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "docstring": "Incrementally update agent context files based on new feature plan.\nPython equivalent of update-agent-context.sh for cross-platform compatibility.\nSupports: CLAUDE.md, GEMINI.md, and .github/copilot-instructions.md\n\nUsage: python update_agent_context.py [claude|gemini|copilot]"
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "docstring": "Extract technology information from plan.md file."
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "docstring": "Create a new agent context file from template."
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "docstring": "Update an existing agent context file with new technology information."
      },
      {
        "file": "scripts/py/update_agent_context.py",
        "docstring": "Update a single agent context file."
      },
      {
        "file": "scripts/py/common.py",
        "docstring": "Common functions and utilities for spec-kit scripts.\nPython equivalent of common.sh for cross-platform compatibility."
      },
      {
        "file": "scripts/py/common.py",
        "docstring": "Run a git command and return the output."
      },
      {
        "file": "scripts/py/common.py",
        "docstring": "Get repository root directory."
      },
      {
        "file": "scripts/py/common.py",
        "docstring": "Get current branch name."
      },
      {
        "file": "scripts/py/common.py",
        "docstring": "Check if current branch is a feature branch.\n    Returns True if valid, False if not.\n    Feature branches should be named like: 001-feature-name"
      },
      {
        "file": "scripts/py/common.py",
        "docstring": "Get feature directory path."
      },
      {
        "file": "scripts/py/common.py",
        "docstring": "Get all standard paths for a feature.\n    Returns a dictionary with all the paths."
      },
      {
        "file": "scripts/py/common.py",
        "docstring": "Check if a file exists and report."
      },
      {
        "file": "scripts/py/common.py",
        "docstring": "Check if a directory exists and has files."
      },
      {
        "file": "scripts/py/common.py",
        "docstring": "Create a branch name from a description."
      },
      {
        "file": "scripts/py/common.py",
        "docstring": "Get the next feature number with zero padding."
      },
      {
        "file": "scripts/py/common.py",
        "docstring": "Copy template file if it exists."
      },
      {
        "file": "scripts/py/setup_plan.py",
        "docstring": "Setup implementation plan structure for current branch.\nPython equivalent of setup-plan.sh for cross-platform compatibility.\n\nUsage: python setup_plan.py [--json]"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "docstring": "Cross-platform script execution utilities for spec-kit.\nHandles execution of bash scripts on Unix and Python scripts on Windows."
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "docstring": "Get the current platform type."
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "docstring": "Check if running on Windows."
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "docstring": "Find the appropriate script path based on platform.\n    On Windows, prefer Python scripts. On Unix, prefer bash scripts."
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "docstring": "Run a script with cross-platform compatibility.\n    \n    Args:\n        script_name: Name of the script (without extension)\n        args: Arguments to pass to the script\n        repo_root: Repository root path (auto-detected if None)\n        capture_output: Whether to capture stdout/stderr\n        check: Whether to raise exception on non-zero exit\n        \n    Returns:\n        CompletedProcess result or parsed dict for JSON output"
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "docstring": "Get a list of available scripts and their paths."
      },
      {
        "file": "src/spec_kit_mcp/scripts.py",
        "docstring": "Test which scripts are available and working on current platform."
      },
      {
        "file": "src/spec_kit_mcp/__init__.py",
        "docstring": "Spec-Kit MCP Server\n\nModel Context Protocol server for Spec-Driven Development toolkit."
      },
      {
        "file": "src/spec_kit_mcp/__init__.py",
        "docstring": "Entry point for MCP server."
      },
      {
        "file": "src/spec_kit_mcp/__init__.py",
        "docstring": "Entry point for CLI."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "MCP Server for Spec-Kit - Spec-Driven Development Toolkit\n\nThis MCP server exposes all the functionality of the spec-kit CLI and scripts\nas MCP tools that can be used by AI agents."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "List all available tools."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle tool calls."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle project initialization."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Project initialization completed successfully!\n\nProject: {project_name}\nPath: {project_path}\nAI Assistant: {ai_assistant} ({AI_CHOICES[ai_assistant]})\nGit Repository: {git_status}\n\nNext steps:\n1. {'You are already in the project directory' if use_current_dir else f'cd {project_name}'}\n2. Use AI agent commands with your chosen assistant\n3. Update CONSTITUTION.md with your project's principles"
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle requirements checking."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle script listing."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle new feature creation."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle plan setup."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle task prerequisites checking."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle agent context updates."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle feature path retrieval."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle generic script execution."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle existing project analysis."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle existing documentation parsing."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle requirements extraction from code."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle standardized specification generation."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle migration plan creation."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle complete end-to-end project onboarding."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle feature component analysis."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle feature boundary extraction."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle feature onboarding."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle feature specification merging."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle specification conflict detection."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle feature dependency resolution."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle progressive migration plan creation."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle onboarding progress tracking."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Handle specification consistency validation."
      },
      {
        "file": "src/spec_kit_mcp/server.py",
        "docstring": "Main entry point for the MCP server."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Onboarding functionality for existing projects to adopt spec-driven development.\n\nThis module provides tools to analyze existing projects, parse their documentation,\nextract requirements, and help migrate them to the spec-kit workflow."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Analyze the structure of an existing project to understand its organization.\n    \n    Args:\n        project_path: Path to the project directory (string or Path object)\n        max_depth: Maximum directory depth to scan\n        \n    Returns:\n        Dictionary containing project structure analysis"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Categorize a file and update analysis."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Check if filename matches any of the given patterns."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Parse existing documentation files to extract requirements and specifications.\n    \n    Args:\n        project_path: Path to the project directory (string or Path object)\n        file_patterns: Optional list of file patterns to search for\n        \n    Returns:\n        Dictionary containing parsed documentation content"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Check if a file is likely to be a text file."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Parse a single documentation file and extract relevant information."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract markdown-style headings from content."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract text that looks like requirements."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract text that looks like features."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract text that looks like user stories."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract API endpoint patterns."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract mentions of technologies, frameworks, and tools."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract requirements and specifications from code comments and docstrings.\n    \n    Args:\n        project_path: Path to the project directory (string or Path object)\n        file_patterns: Optional list of file patterns to search for\n        \n    Returns:\n        Dictionary containing extracted requirements from code"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract requirements from a single code file."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract comments from code."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract Python docstrings."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract TODO and FIXME items."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate a standardized specification from existing project analysis.\n    \n    Args:\n        project_analysis: Result from analyze_project_structure\n        documentation_analysis: Result from parse_existing_documentation\n        code_analysis: Result from extract_requirements_from_code\n        template_dir: Optional path to template directory\n        \n    Returns:\n        Dictionary containing the generated standardized specification"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Get current timestamp in ISO format."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate project overview from analysis."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate functional requirements from analysis."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate non-functional requirements."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate user stories from analysis."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate technical stack information."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate API specification from analysis."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate data model information."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate implementation notes."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate testing strategy based on project analysis."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Identify gaps in current project structure."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate recommendations for adopting spec-driven development."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Create a migration plan for adopting spec-driven development.\n    \n    Args:\n        project_analysis: Result from analyze_project_structure\n        standardized_spec: Result from generate_standardized_spec\n        \n    Returns:\n        Dictionary containing detailed migration plan"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Assess current state of the project."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate migration phases."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Estimate migration timeline based on project size."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Estimate resources needed for migration."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Identify migration risks and mitigations."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Define success criteria for migration."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Analyze a specific feature or component within a project.\n    \n    Args:\n        project_path: Path to the main project directory\n        feature_path: Relative path to the feature/component within the project\n        max_depth: Maximum directory depth to scan within the feature\n        \n    Returns:\n        Dictionary containing feature-specific analysis"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Categorize a file within a feature and update analysis."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Analyze dependencies and external references for a feature."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract import statements and external references from code."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Check if a reference is internal to the current feature or project."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Identify potential sub-feature boundaries within a feature."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Identify logical feature boundaries within a project.\n    \n    Args:\n        project_path: Path to the project directory (string or Path object)\n        analysis_depth: Depth to analyze for feature boundaries\n        \n    Returns:\n        Dictionary containing identified feature boundaries"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Analyze a directory to determine if it's a good feature candidate."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Onboard a specific feature to spec-driven development.\n    \n    Args:\n        project_path: Path to the main project directory\n        feature_path: Relative path to the feature within the project\n        include_dependencies: Whether to analyze feature dependencies\n        \n    Returns:\n        Dictionary containing complete feature onboarding analysis"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Analyze how a feature integrates with the rest of the project."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Find references to a feature from other parts of the project."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate recommendations for integrating a feature into spec-driven development."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Assess how ready a feature is for spec-driven development."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Merge multiple feature specifications into a master specification.\n    \n    Args:\n        feature_specifications: List of feature specification dictionaries\n        master_project_info: Optional master project information for context\n        \n    Returns:\n        Dictionary containing the merged master specification"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate an overview for the master specification."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate recommendations for coordinating multiple features."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Detect conflicts between multiple feature specifications.\n    \n    Args:\n        feature_specifications: List of feature specification dictionaries\n        \n    Returns:\n        Dictionary containing detected conflicts and resolution suggestions"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Detect API endpoint conflicts between features."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract endpoint pattern from API specification string."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Detect conflicting requirements between features."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract key terms from a requirement string."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Check if two requirements are potentially conflicting."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Detect technology stack conflicts between features."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Normalize technology name for comparison."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Check if two technology choices are conflicting."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate suggestions for resolving detected conflicts."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Analyze and document dependencies between features.\n    \n    Args:\n        feature_specifications: List of feature specification dictionaries\n        \n    Returns:\n        Dictionary containing dependency analysis and resolution plan"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Calculate the strength of dependency from feature_a to feature_b."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Classify the type of dependency between features."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Extract specific details about dependencies between features."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Detect circular dependencies in the dependency graph."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Identify critical dependencies that require special attention."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate suggested implementation order based on dependencies."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Create a plan for resolving dependency issues."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Create a progressive migration plan for incremental adoption of spec-driven development.\n    \n    Args:\n        project_path: Path to the project directory\n        feature_boundaries: Result from extract_feature_boundaries\n        priority_features: Optional list of features to prioritize\n        \n    Returns:\n        Dictionary containing progressive migration plan"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Prioritize features for progressive migration."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Create progressive migration phases."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Estimate timeline for progressive migration."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Plan resource allocation for progressive migration."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Define success metrics for progressive migration."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Identify risks specific to progressive migration."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Create a coordination plan for progressive migration."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Track progress of progressive onboarding migration.\n    \n    Args:\n        project_path: Path to the project directory\n        migration_plan: Result from create_progressive_migration_plan\n        completed_features: List of features that have been completed\n        \n    Returns:\n        Dictionary containing progress tracking information"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Determine phase status based on completion percentage."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Find which phase a feature belongs to."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate next actions based on current progress."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate recommendations based on progress analysis."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Validate consistency across multiple feature specifications.\n    \n    Args:\n        feature_specifications: List of feature specification dictionaries\n        \n    Returns:\n        Dictionary containing consistency validation results"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Validate format consistency across specifications."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Validate naming consistency across specifications."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Validate requirement consistency across specifications."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Validate technical consistency across specifications."
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "docstring": "Generate recommendations for improving specification consistency."
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Specify CLI - Setup tool for Specify projects\n\nUsage:\n    uvx specify-cli.py init <project-name>\n    uvx specify-cli.py init --here\n\nOr install globally:\n    uv tool install --from specify-cli.py specify-cli\n    specify init <project-name>\n    specify init --here"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557   \u2588\u2588\u2557\n\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d\n\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2551     \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557   \u255a\u2588\u2588\u2588\u2588\u2554\u255d \n\u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u255d  \u2588\u2588\u2551     \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d    \u255a\u2588\u2588\u2554\u255d  \n\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551        \u2588\u2588\u2551   \n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d     \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u255d        \u255a\u2550\u255d"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Track and render hierarchical steps without emojis, similar to Claude Code tree output.\n    Supports live auto-refresh via an attached refresh callback."
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "\u2554\u2550\u2557\u2554\u2550\u2557\u2554\u2550\u2557\u2554\u2550\u2557\u2566\u2554\u2550\u2557\u2566 \u2566\n\u255a\u2550\u2557\u2560\u2550\u255d\u2551\u2563 \u2551  \u2551\u2560\u2563 \u255a\u2566\u255d\n\u255a\u2550\u255d\u2569  \u255a\u2550\u255d\u255a\u2550\u255d\u2569\u255a   \u2569"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Get a single keypress in a cross-platform way using readchar."
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Interactive selection using arrow keys with Rich Live display.\n    \n    Args:\n        options: Dict with keys as option keys and values as descriptions\n        prompt_text: Text to show above the options\n        default_key: Default option key to start with\n        \n    Returns:\n        Selected option key"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Create the selection panel with current selection highlighted."
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Custom group that shows banner before help."
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Display the ASCII art banner."
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Show banner when no subcommand is provided."
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Run a shell command and optionally capture output."
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Check if a tool is installed."
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Check if the specified path is inside a git repository."
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Initialize a git repository in the specified path.\n    quiet: if True suppress console output (tracker handles status)"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Download the latest template release from GitHub using HTTP requests.\n    Returns (zip_path, metadata_dict)"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Download the latest release and extract it to create a new project.\n    Returns project_path. Uses tracker if provided (with keys: fetch, download, extract, cleanup)"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Initialize a new Specify project from the latest template.\n    \n    This command will:\n    1. Check that required tools are installed (git is optional)\n    2. Let you choose your AI assistant (Claude Code, Gemini CLI, or GitHub Copilot)\n    3. Download the appropriate template from GitHub\n    4. Extract the template to a new project directory or current directory\n    5. Initialize a fresh git repository (if not --no-git and no existing repo)\n    6. Optionally set up AI assistant commands\n    \n    Examples:\n        specify init my-project\n        specify init my-project --ai claude\n        specify init my-project --ai gemini\n        specify init my-project --ai copilot --no-git\n        specify init --ignore-agent-tools my-project\n        specify init --here --ai claude\n        specify init --here"
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Show available scripts and platform compatibility."
      },
      {
        "file": "src/spec_kit_mcp/cli.py",
        "docstring": "Check that all required tools are installed."
      }
    ],
    "todo_items": [
      {
        "file": "src/spec_kit_mcp/server.py",
        "item": "/FIXME items\","
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "_items\": [],"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "/FIXME items"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "_fixme(content, extracted, relative_path)"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "_fixme(content: str, extracted: Dict[str, Any], file_path: str) -> None:"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "and FIXME items.\"\"\""
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "_pattern = r'(?i)todo[:\\-\\s]*(.+)'"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "_pattern, content, re.MULTILINE):"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "= match.group(1).strip()"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": ") > 3:"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "_items\"].append({"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "items from code"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "s = code_analysis.get(\"todo_items\", [])"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "items found in code:\")"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "in todos[:5]:"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "['file']}: {todo['item']}\")"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "s = len(code_analysis.get(\"todo_items\", []))"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "s + fixmes > 10:"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "/FIXME items ({todos + fixmes}) indicating incomplete implementation\")"
      }
    ],
    "fixme_items": [
      {
        "file": "src/spec_kit_mcp/server.py",
        "item": "items\","
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "_items\": [],"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "items"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "(content, extracted, relative_path)"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "(content: str, extracted: Dict[str, Any], file_path: str) -> None:"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "items.\"\"\""
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "_pattern = r'(?i)fixme[:\\-\\s]*(.+)'"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "_pattern, content, re.MULTILINE):"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "= match.group(1).strip()"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": ") > 3:"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "_items\"].append({"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "items"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "s = code_analysis.get(\"fixme_items\", [])"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "items found in code:\")"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "in fixmes[:5]:"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "['file']}: {fixme['item']}\")"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "s = len(code_analysis.get(\"fixme_items\", []))"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "s > 10:"
      },
      {
        "file": "src/spec_kit_mcp/onboarding.py",
        "item": "items ({todos + fixmes}) indicating incomplete implementation\")"
      }
    ],
    "function_descriptions": [],
    "class_descriptions": [],
    "api_documentation": [],
    "extraction_errors": []
  },
  "generated_specification": {
    "project_name": "spec-kit",
    "project_path": "/home/runner/work/spec-kit/spec-kit",
    "generated_from": "existing_project_analysis",
    "analysis_date": "2025-09-11T01:51:28.805400",
    "overview": "# spec-kit\n\nThis is a medium-sized project with approximately 72 files.\n\nPrimary languages: Python\n\nDocumentation files analyzed: 19",
    "functional_requirements": [
      "REQ-1: adhere to when establishing the plan.",
      "REQ-2: be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.",
      "REQ-3: allow users to create projects, add team members,",
      "REQ-4: be able to change the current status of the task between the different columns in the Kanban work board.",
      "REQ-5: be able to leave an unlimited number of comments for a particular card. You should be able to, from that task",
      "REQ-6: see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.",
      "REQ-7: have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.",
      "REQ-8: contain a set of user stories and functional requirements, as defined in the template.",
      "REQ-9: resemble the following:",
      "REQ-10: be a variable number of tasks between 5 and 15",
      "REQ-11: System shall branches with specifications",
      "REQ-12: System shall boundaries for progressive onboarding",
      "REQ-13: System shall specifications into master specification",
      "REQ-14: System shall specifications",
      "REQ-15: System shall specifications"
    ],
    "non_functional_requirements": [
      "NFR-1: System shall maintain test coverage above 80%",
      "NFR-2: System shall support automated CI/CD pipeline",
      "NFR-3: System shall be compatible with Python 3.8+"
    ],
    "user_stories": [
      "Model Context Protocol (MCP) server that provides AI agents with powerful spec-driven development tools:\n\n```bash\n# Install the MCP server\npip install git+https://github.com/ASISaga/spec-kit.git\n\n# Run the MCP server\nspec-kit-mcp\n```\n\n### 2. Configure your AI agent\n\nAdd the Spec-Kit MCP server to your AI agent's configuration. The server provides these tools:\n\n**For New Projects:**\n- **init_project**: Initialize new Spec-Kit projects with templates\n- **create_new_feature**: Create feature branches with specifications  \n- **setup_plan**: Set up implementation plans\n- **check_task_prerequisites**: Validate task requirements\n- **update_agent_context**: Update agent context files\n- **get_feature_paths**: Get feature file paths\n- **run_script**: Execute cross-platform scripts\n- **check_requirements**: Check system requirements\n- **list_scripts**: Show available scripts and compatibility\n\n**For Existing Projects:**\n- **analyze_existing_project**: Analyze existing project structure and codebase\n- **parse_existing_documentation**: Extract requirements from existing documentation\n- **extract_requirements_from_code**: Extract specifications from code comments and docstrings\n- **generate_standardized_spec**: Generate Spec-Kit compatible specifications from analysis\n- **create_migration_plan**: Create detailed migration plans for adopting spec-driven development\n- **onboard_existing_project**: Complete end-to-end onboarding analysis\n\n**For Progressive Onboarding (NEW):**\n- **analyze_feature_component**: Analyze specific features/components within a project\n- **extract_feature_boundaries**: Identify logical feature boundaries for progressive onboarding\n- **onboard_project_feature**: Onboard individual features to spec-driven development\n- **merge_feature_specifications**: Combine multiple feature specifications into master specification\n- **detect_specification_conflicts**: Identify conflicts between feature specifications\n- **resolve_feature_dependencies**: Analyze and document dependencies between features\n- **create_progressive_migration_plan**: Create phased migration plans for incremental adoption\n- **track_onboarding_progress**: Track progress across multiple features/teams\n- **validate_specification_consistency**: Ensure consistency across progressive specifications\n\n### 3. Use with your AI agent\n\nOnce configured, your AI agent can use spec-driven development tools directly:\n\n**For New Projects:**\n- Create specifications that define the **what** and **why**, not the tech stack\n- Generate technical implementation plans with your chosen tech stack  \n- Break down features into actionable tasks\n- Manage the complete spec-driven development lifecycle\n\n**For Existing Projects:**\n- Analyze existing project structure and extract requirements\n- Parse documentation and code to understand current specifications\n- Generate standardized Spec-Kit compatible specifications\n- Create migration plans for adopting spec-driven development workflow\n- Onboard legacy projects to modern spec-driven approaches\n\n**For Progressive Onboarding (NEW):**\n- Analyze and onboard individual features or components incrementally\n- Support multiple teams working on different parts independently\n- Merge and coordinate specifications across features\n- Detect and resolve conflicts between feature specifications\n- Track progress and manage dependencies during progressive migration\n- Enable gradual adoption of spec-driven development across organizations\n\nFor detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).\nFor existing project onboarding, see our [onboarding guide](./ONBOARDING.md).\n\n## \ud83d\udcda Core philosophy\n\nSpec-Driven Development is a structured process that emphasizes:\n\n- **Intent-driven development** where specifications define the \"_what_\" before the \"_how_\"\n- **Rich specification creation** using guardrails and organizational principles\n- **Multi-step refinement** rather than one-shot code generation from prompts\n- **Heavy reliance** on advanced AI model capabilities for specification interpretation\n\n## \ud83c\udf1f Development phases\n\n| Phase | Focus | Key Activities |\n|-------|-------|----------------|\n| **0-to-1 Development** (\"Greenfield\") | Generate from scratch | <ul><li>Start with high-level requirements</li><li>Generate specifications</li><li>Plan implementation steps</li><li>Build production-ready applications</li></ul> |\n| **Creative Exploration** | Parallel implementations | <ul><li>Explore diverse solutions</li><li>Support multiple technology stacks & architectures</li><li>Experiment with UX patterns</li></ul> |\n| **Iterative Enhancement** (\"Brownfield\") | Brownfield modernization | <ul><li>Add features iteratively</li><li>Modernize legacy systems</li><li>Adapt processes</li></ul> |\n| **Existing Project Onboarding** (**ENHANCED**) | Legacy project migration | <ul><li>Analyze existing codebases and documentation</li><li>Extract and standardize requirements</li><li>Create migration plans</li><li>Adopt spec-driven workflows gradually</li></ul> |\n| **Progressive Onboarding** (**NEW**) | Incremental feature-level adoption | <ul><li>Onboard individual features and components</li><li>Support multi-team development workflows</li><li>Coordinate specifications across features</li><li>Enable gradual organizational adoption</li></ul> |\n\n## \ud83c\udfaf Experimental goals\n\nOur research and experimentation focus on:\n\n### Technology independence\n\n- Create applications using diverse technology stacks\n- Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks\n\n### Enterprise constraints\n\n- Demonstrate mission-critical application development\n- Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)\n- Support enterprise design systems and compliance requirements\n\n### User-centric development\n\n- Build applications for different user cohorts and preferences\n- Support various development approaches (from vibe-coding to AI-native development)\n\n### Creative & iterative processes\n\n- Validate the concept of parallel implementation exploration\n- Provide robust iterative feature development workflows\n- Extend processes to handle upgrades and modernization tasks  \n\n## \ud83d\udd27 Prerequisites\n\n- **Cross-platform**: Windows, Linux, macOS\n- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n- [uv](https://docs.astral.sh/uv/) for package management\n- [Python 3.11+](https://www.python.org/downloads/)\n- [Git](https://git-scm.com/downloads)\n\n## \ud83d\udcd6 Learn more\n\n- **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process\n- **[Detailed Walkthrough](#detailed-process)** - Step-by-step implementation guide\n\n---\n\n## Detailed process\n\n<details>\n<summary>Click to expand the detailed step-by-step walkthrough</summary>\n\nYou can use the Specify CLI to bootstrap your project, which will bring in the required artifacts in your environment. Run:\n\n```bash\nspecify init <project_name>\n```\n\nOr initialize in the current directory:\n\n```bash\nspecify init --here\n```\n\n![Specify CLI bootstrapping a new project in the terminal](./media/specify_cli.gif)\n\nYou will be prompted to select the AI agent you are using. You can also proactively specify it directly in the terminal:\n\n```bash\nspecify init <project_name> --ai claude\nspecify init <project_name> --ai gemini\nspecify init <project_name> --ai copilot\n# Or in current directory:\nspecify init --here --ai claude\n```\n\nThe CLI will check if you have Claude Code or Gemini CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:\n\n```bash\nspecify init <project_name> --ai claude --ignore-agent-tools\n```\n\n### **STEP 1:** Bootstrap the project\n\nGo to the project folder and run your AI agent. In our example, we're using `claude`.\n\n![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)\n\nYou will know that things are configured correctly if you see the `/specify`, `/plan`, and `/tasks` commands available.\n\nThe first step should be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.\n\n>[!IMPORTANT]\n>Be as explicit as possible about _what_ you are trying to build and _why_. **Do not focus on the tech stack at this point**.\n\nAn example prompt:\n\n```text\nDevelop Taskify, a team productivity platform. It should allow users to create projects, add team members,\nassign tasks, comment and move tasks between boards in Kanban style. In this initial phase for this feature,\nlet's call it \"Create Taskify,\" let's have multiple users but the users will be declared ahead of time, predefined. five users in two different categories, one product manager and four engineers. Let's create three\ndifferent sample projects. Let's have the standard Kanban columns for the status of each task, such as \"To Do,\"\n\"In Progress,\" \"In Review,\" and \"Done.\" There will be no login for this application as this is just the very\nfirst testing thing to ensure that our basic features are set up. For each task in the UI for a task card,\nyou should be able to change the current status of the task between the different columns in the Kanban work board.\nYou should be able to leave an unlimited number of comments for a particular card. You should be able to, from that task\ncard, assign one of the valid users. When you first launch Taskify, it's going to give you a list of the five users to pick\nfrom. There will be no password required. When you click on a user, you go into the main view, which displays the list of\nprojects. When you click on a project, you open the Kanban board for that project. You're going to see the columns.\nYou'll be able to drag and drop cards back and forth between different columns. You will see any cards that are\nassigned to you, the currently logged in user, in a different color from all the other ones, so you can quickly\nsee yours. You can edit any comments that you make, but you can't edit comments that other people made. You can\ndelete any comments that you made, but you can't delete comments anybody else made.\n```\n\nAfter this prompt is entered, you should see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.\n\nOnce this step is completed, you should have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text\nI want you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.",
      "Model Context Protocol (MCP) server that provides AI agents with powerful spec-driven development tools:\n\n```bash\n# Install the MCP server\npip install git+https://github.com/ASISaga/spec-kit.git\n\n# Run the MCP server\nspec-kit-mcp\n```\n\n### 2. Configure your AI agent\n\nAdd the Spec-Kit MCP server to your AI agent's configuration. The server provides these tools:\n\n**For New Projects:**\n- **init_project**: Initialize new Spec-Kit projects with templates\n- **create_new_feature**: Create feature branches with specifications  \n- **setup_plan**: Set up implementation plans\n- **check_task_prerequisites**: Validate task requirements\n- **update_agent_context**: Update agent context files\n- **get_feature_paths**: Get feature file paths\n- **run_script**: Execute cross-platform scripts\n- **check_requirements**: Check system requirements\n- **list_scripts**: Show available scripts and compatibility\n\n**For Existing Projects:**\n- **analyze_existing_project**: Analyze existing project structure and codebase\n- **parse_existing_documentation**: Extract requirements from existing documentation\n- **extract_requirements_from_code**: Extract specifications from code comments and docstrings\n- **generate_standardized_spec**: Generate Spec-Kit compatible specifications from analysis\n- **create_migration_plan**: Create detailed migration plans for adopting spec-driven development\n- **onboard_existing_project**: Complete end-to-end onboarding analysis\n\n**For Progressive Onboarding (NEW):**\n- **analyze_feature_component**: Analyze specific features/components within a project\n- **extract_feature_boundaries**: Identify logical feature boundaries for progressive onboarding\n- **onboard_project_feature**: Onboard individual features to spec-driven development\n- **merge_feature_specifications**: Combine multiple feature specifications into master specification\n- **detect_specification_conflicts**: Identify conflicts between feature specifications\n- **resolve_feature_dependencies**: Analyze and document dependencies between features\n- **create_progressive_migration_plan**: Create phased migration plans for incremental adoption\n- **track_onboarding_progress**: Track progress across multiple features/teams\n- **validate_specification_consistency**: Ensure consistency across progressive specifications\n\n### 3. Use with your AI agent\n\nOnce configured, your AI agent can use spec-driven development tools directly:\n\n**For New Projects:**\n- Create specifications that define the **what** and **why**, not the tech stack\n- Generate technical implementation plans with your chosen tech stack  \n- Break down features into actionable tasks\n- Manage the complete spec-driven development lifecycle\n\n**For Existing Projects:**\n- Analyze existing project structure and extract requirements\n- Parse documentation and code to understand current specifications\n- Generate standardized Spec-Kit compatible specifications\n- Create migration plans for adopting spec-driven development workflow\n- Onboard legacy projects to modern spec-driven approaches\n\n**For Progressive Onboarding (NEW):**\n- Analyze and onboard individual features or components incrementally\n- Support multiple teams working on different parts independently\n- Merge and coordinate specifications across features\n- Detect and resolve conflicts between feature specifications\n- Track progress and manage dependencies during progressive migration\n- Enable gradual adoption of spec-driven development across organizations\n\nFor detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).\nFor existing project onboarding, see our [onboarding guide](./ONBOARDING.md).\n\n## \ud83d\udcda Core philosophy\n\nSpec-Driven Development is a structured process that emphasizes:\n\n- **Intent-driven development** where specifications define the \"_what_\" before the \"_how_\"\n- **Rich specification creation** using guardrails and organizational principles\n- **Multi-step refinement** rather than one-shot code generation from prompts\n- **Heavy reliance** on advanced AI model capabilities for specification interpretation\n\n## \ud83c\udf1f Development phases\n\n| Phase | Focus | Key Activities |\n|-------|-------|----------------|\n| **0-to-1 Development** (\"Greenfield\") | Generate from scratch | <ul><li>Start with high-level requirements</li><li>Generate specifications</li><li>Plan implementation steps</li><li>Build production-ready applications</li></ul> |\n| **Creative Exploration** | Parallel implementations | <ul><li>Explore diverse solutions</li><li>Support multiple technology stacks & architectures</li><li>Experiment with UX patterns</li></ul> |\n| **Iterative Enhancement** (\"Brownfield\") | Brownfield modernization | <ul><li>Add features iteratively</li><li>Modernize legacy systems</li><li>Adapt processes</li></ul> |\n| **Existing Project Onboarding** (**ENHANCED**) | Legacy project migration | <ul><li>Analyze existing codebases and documentation</li><li>Extract and standardize requirements</li><li>Create migration plans</li><li>Adopt spec-driven workflows gradually</li></ul> |\n| **Progressive Onboarding** (**NEW**) | Incremental feature-level adoption | <ul><li>Onboard individual features and components</li><li>Support multi-team development workflows</li><li>Coordinate specifications across features</li><li>Enable gradual organizational adoption</li></ul> |\n\n## \ud83c\udfaf Experimental goals\n\nOur research and experimentation focus on:\n\n### Technology independence\n\n- Create applications using diverse technology stacks\n- Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks\n\n### Enterprise constraints\n\n- Demonstrate mission-critical application development\n- Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)\n- Support enterprise design systems and compliance requirements\n\n### User-centric development\n\n- Build applications for different user cohorts and preferences\n- Support various development approaches (from vibe-coding to AI-native development)\n\n### Creative & iterative processes\n\n- Validate the concept of parallel implementation exploration\n- Provide robust iterative feature development workflows\n- Extend processes to handle upgrades and modernization tasks  \n\n## \ud83d\udd27 Prerequisites\n\n- **Cross-platform**: Windows, Linux, macOS\n- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n- [uv](https://docs.astral.sh/uv/) for package management\n- [Python 3.11+](https://www.python.org/downloads/)\n- [Git](https://git-scm.com/downloads)\n\n## \ud83d\udcd6 Learn more\n\n- **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process\n- **[Detailed Walkthrough](#detailed-process)** - Step-by-step implementation guide\n\n---\n\n## Detailed process\n\n<details>\n<summary>Click to expand the detailed step-by-step walkthrough</summary>\n\nYou can use the Specify CLI to bootstrap your project, which will bring in the required artifacts in your environment. Run:\n\n```bash\nspecify init <project_name>\n```\n\nOr initialize in the current directory:\n\n```bash\nspecify init --here\n```\n\n![Specify CLI bootstrapping a new project in the terminal](./media/specify_cli.gif)\n\nYou will be prompted to select the AI agent you are using. You can also proactively specify it directly in the terminal:\n\n```bash\nspecify init <project_name> --ai claude\nspecify init <project_name> --ai gemini\nspecify init <project_name> --ai copilot\n# Or in current directory:\nspecify init --here --ai claude\n```\n\nThe CLI will check if you have Claude Code or Gemini CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:\n\n```bash\nspecify init <project_name> --ai claude --ignore-agent-tools\n```\n\n### **STEP 1:** Bootstrap the project\n\nGo to the project folder and run your AI agent. In our example, we're using `claude`.\n\n![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)\n\nYou will know that things are configured correctly if you see the `/specify`, `/plan`, and `/tasks` commands available.\n\nThe first step should be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.\n\n>[!IMPORTANT]\n>Be as explicit as possible about _what_ you are trying to build and _why_. **Do not focus on the tech stack at this point**.\n\nAn example prompt:\n\n```text\nDevelop Taskify, a team productivity platform. It should allow users to create projects, add team members,\nassign tasks, comment and move tasks between boards in Kanban style. In this initial phase for this feature,\nlet's call it \"Create Taskify,\" let's have multiple users but the users will be declared ahead of time, predefined. five users in two different categories, one product manager and four engineers. Let's create three\ndifferent sample projects. Let's have the standard Kanban columns for the status of each task, such as \"To Do,\"\n\"In Progress,\" \"In Review,\" and \"Done.\" There will be no login for this application as this is just the very\nfirst testing thing to ensure that our basic features are set up. For each task in the UI for a task card,\nyou should be able to change the current status of the task between the different columns in the Kanban work board.\nYou should be able to leave an unlimited number of comments for a particular card. You should be able to, from that task\ncard, assign one of the valid users. When you first launch Taskify, it's going to give you a list of the five users to pick\nfrom. There will be no password required. When you click on a user, you go into the main view, which displays the list of\nprojects. When you click on a project, you open the Kanban board for that project. You're going to see the columns.\nYou'll be able to drag and drop cards back and forth between different columns. You will see any cards that are\nassigned to you, the currently logged in user, in a different color from all the other ones, so you can quickly\nsee yours. You can edit any comments that you make, but you can't edit comments that other people made. You can\ndelete any comments that you made, but you can't delete comments anybody else made.\n```\n\nAfter this prompt is entered, you should see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.\n\nOnce this step is completed, you should have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text\nI want you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.",
      "new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.",
      "new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.",
      "Model Context Protocol (MCP) server that provides AI agents with powerful spec-driven development tools:\n\n```bash\n# Install the MCP server\npip install git+https://github.com/ASISaga/spec-kit.git\n\n# Run the MCP server\nspec-kit-mcp\n```\n\n### 2. Configure your AI agent\n\nAdd the Spec-Kit MCP server to your AI agent's configuration. The server provides these tools:\n\n**For New Projects:**\n- **init_project**: Initialize new Spec-Kit projects with templates\n- **create_new_feature**: Create feature branches with specifications  \n- **setup_plan**: Set up implementation plans\n- **check_task_prerequisites**: Validate task requirements\n- **update_agent_context**: Update agent context files\n- **get_feature_paths**: Get feature file paths\n- **run_script**: Execute cross-platform scripts\n- **check_requirements**: Check system requirements\n- **list_scripts**: Show available scripts and compatibility\n\n**For Existing Projects:**\n- **analyze_existing_project**: Analyze existing project structure and codebase\n- **parse_existing_documentation**: Extract requirements from existing documentation\n- **extract_requirements_from_code**: Extract specifications from code comments and docstrings\n- **generate_standardized_spec**: Generate Spec-Kit compatible specifications from analysis\n- **create_migration_plan**: Create detailed migration plans for adopting spec-driven development\n- **onboard_existing_project**: Complete end-to-end onboarding analysis\n\n**For Progressive Onboarding (NEW):**\n- **analyze_feature_component**: Analyze specific features/components within a project\n- **extract_feature_boundaries**: Identify logical feature boundaries for progressive onboarding\n- **onboard_project_feature**: Onboard individual features to spec-driven development\n- **merge_feature_specifications**: Combine multiple feature specifications into master specification\n- **detect_specification_conflicts**: Identify conflicts between feature specifications\n- **resolve_feature_dependencies**: Analyze and document dependencies between features\n- **create_progressive_migration_plan**: Create phased migration plans for incremental adoption\n- **track_onboarding_progress**: Track progress across multiple features/teams\n- **validate_specification_consistency**: Ensure consistency across progressive specifications\n\n### 3. Use with your AI agent\n\nOnce configured, your AI agent can use spec-driven development tools directly:\n\n**For New Projects:**\n- Create specifications that define the **what** and **why**, not the tech stack\n- Generate technical implementation plans with your chosen tech stack  \n- Break down features into actionable tasks\n- Manage the complete spec-driven development lifecycle\n\n**For Existing Projects:**\n- Analyze existing project structure and extract requirements\n- Parse documentation and code to understand current specifications\n- Generate standardized Spec-Kit compatible specifications\n- Create migration plans for adopting spec-driven development workflow\n- Onboard legacy projects to modern spec-driven approaches\n\n**For Progressive Onboarding (NEW):**\n- Analyze and onboard individual features or components incrementally\n- Support multiple teams working on different parts independently\n- Merge and coordinate specifications across features\n- Detect and resolve conflicts between feature specifications\n- Track progress and manage dependencies during progressive migration\n- Enable gradual adoption of spec-driven development across organizations\n\nFor detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).\nFor existing project onboarding, see our [onboarding guide](./ONBOARDING.md).\n\n## \ud83d\udcda Core philosophy\n\nSpec-Driven Development is a structured process that emphasizes:\n\n- **Intent-driven development** where specifications define the \"_what_\" before the \"_how_\"\n- **Rich specification creation** using guardrails and organizational principles\n- **Multi-step refinement** rather than one-shot code generation from prompts\n- **Heavy reliance** on advanced AI model capabilities for specification interpretation\n\n## \ud83c\udf1f Development phases\n\n| Phase | Focus | Key Activities |\n|-------|-------|----------------|\n| **0-to-1 Development** (\"Greenfield\") | Generate from scratch | <ul><li>Start with high-level requirements</li><li>Generate specifications</li><li>Plan implementation steps</li><li>Build production-ready applications</li></ul> |\n| **Creative Exploration** | Parallel implementations | <ul><li>Explore diverse solutions</li><li>Support multiple technology stacks & architectures</li><li>Experiment with UX patterns</li></ul> |\n| **Iterative Enhancement** (\"Brownfield\") | Brownfield modernization | <ul><li>Add features iteratively</li><li>Modernize legacy systems</li><li>Adapt processes</li></ul> |\n| **Existing Project Onboarding** (**ENHANCED**) | Legacy project migration | <ul><li>Analyze existing codebases and documentation</li><li>Extract and standardize requirements</li><li>Create migration plans</li><li>Adopt spec-driven workflows gradually</li></ul> |\n| **Progressive Onboarding** (**NEW**) | Incremental feature-level adoption | <ul><li>Onboard individual features and components</li><li>Support multi-team development workflows</li><li>Coordinate specifications across features</li><li>Enable gradual organizational adoption</li></ul> |\n\n## \ud83c\udfaf Experimental goals\n\nOur research and experimentation focus on:\n\n### Technology independence\n\n- Create applications using diverse technology stacks\n- Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks\n\n### Enterprise constraints\n\n- Demonstrate mission-critical application development\n- Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)\n- Support enterprise design systems and compliance requirements\n\n### User-centric development\n\n- Build applications for different user cohorts and preferences\n- Support various development approaches (from vibe-coding to AI-native development)\n\n### Creative & iterative processes\n\n- Validate the concept of parallel implementation exploration\n- Provide robust iterative feature development workflows\n- Extend processes to handle upgrades and modernization tasks  \n\n## \ud83d\udd27 Prerequisites\n\n- **Cross-platform**: Windows, Linux, macOS\n- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n- [uv](https://docs.astral.sh/uv/) for package management\n- [Python 3.11+](https://www.python.org/downloads/)\n- [Git](https://git-scm.com/downloads)\n\n## \ud83d\udcd6 Learn more\n\n- **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process\n- **[Detailed Walkthrough](#detailed-process)** - Step-by-step implementation guide\n\n---\n\n## Detailed process\n\n<details>\n<summary>Click to expand the detailed step-by-step walkthrough</summary>\n\nYou can use the Specify CLI to bootstrap your project, which will bring in the required artifacts in your environment. Run:\n\n```bash\nspecify init <project_name>\n```\n\nOr initialize in the current directory:\n\n```bash\nspecify init --here\n```\n\n![Specify CLI bootstrapping a new project in the terminal](./media/specify_cli.gif)\n\nYou will be prompted to select the AI agent you are using. You can also proactively specify it directly in the terminal:\n\n```bash\nspecify init <project_name> --ai claude\nspecify init <project_name> --ai gemini\nspecify init <project_name> --ai copilot\n# Or in current directory:\nspecify init --here --ai claude\n```\n\nThe CLI will check if you have Claude Code or Gemini CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:\n\n```bash\nspecify init <project_name> --ai claude --ignore-agent-tools\n```\n\n### **STEP 1:** Bootstrap the project\n\nGo to the project folder and run your AI agent. In our example, we're using `claude`.\n\n![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)\n\nYou will know that things are configured correctly if you see the `/specify`, `/plan`, and `/tasks` commands available.\n\nThe first step should be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.\n\n>[!IMPORTANT]\n>Be as explicit as possible about _what_ you are trying to build and _why_. **Do not focus on the tech stack at this point**.\n\nAn example prompt:\n\n```text\nDevelop Taskify, a team productivity platform. It should allow users to create projects, add team members,\nassign tasks, comment and move tasks between boards in Kanban style. In this initial phase for this feature,\nlet's call it \"Create Taskify,\" let's have multiple users but the users will be declared ahead of time, predefined. five users in two different categories, one product manager and four engineers. Let's create three\ndifferent sample projects. Let's have the standard Kanban columns for the status of each task, such as \"To Do,\"\n\"In Progress,\" \"In Review,\" and \"Done.\" There will be no login for this application as this is just the very\nfirst testing thing to ensure that our basic features are set up. For each task in the UI for a task card,\nyou should be able to change the current status of the task between the different columns in the Kanban work board.\nYou should be able to leave an unlimited number of comments for a particular card. You should be able to, from that task\ncard, assign one of the valid users. When you first launch Taskify, it's going to give you a list of the five users to pick\nfrom. There will be no password required. When you click on a user, you go into the main view, which displays the list of\nprojects. When you click on a project, you open the Kanban board for that project. You're going to see the columns.\nYou'll be able to drag and drop cards back and forth between different columns. You will see any cards that are\nassigned to you, the currently logged in user, in a different color from all the other ones, so you can quickly\nsee yours. You can edit any comments that you make, but you can't edit comments that other people made. You can\ndelete any comments that you made, but you can't delete comments anybody else made.\n```\n\nAfter this prompt is entered, you should see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.\n\nOnce this step is completed, you should have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text\nI want you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.",
      "Model Context Protocol (MCP) server that provides AI agents with powerful spec-driven development tools:\n\n```bash\n# Install the MCP server\npip install git+https://github.com/ASISaga/spec-kit.git\n\n# Run the MCP server\nspec-kit-mcp\n```\n\n### 2. Configure your AI agent\n\nAdd the Spec-Kit MCP server to your AI agent's configuration. The server provides these tools:\n\n**For New Projects:**\n- **init_project**: Initialize new Spec-Kit projects with templates\n- **create_new_feature**: Create feature branches with specifications  \n- **setup_plan**: Set up implementation plans\n- **check_task_prerequisites**: Validate task requirements\n- **update_agent_context**: Update agent context files\n- **get_feature_paths**: Get feature file paths\n- **run_script**: Execute cross-platform scripts\n- **check_requirements**: Check system requirements\n- **list_scripts**: Show available scripts and compatibility\n\n**For Existing Projects:**\n- **analyze_existing_project**: Analyze existing project structure and codebase\n- **parse_existing_documentation**: Extract requirements from existing documentation\n- **extract_requirements_from_code**: Extract specifications from code comments and docstrings\n- **generate_standardized_spec**: Generate Spec-Kit compatible specifications from analysis\n- **create_migration_plan**: Create detailed migration plans for adopting spec-driven development\n- **onboard_existing_project**: Complete end-to-end onboarding analysis\n\n**For Progressive Onboarding (NEW):**\n- **analyze_feature_component**: Analyze specific features/components within a project\n- **extract_feature_boundaries**: Identify logical feature boundaries for progressive onboarding\n- **onboard_project_feature**: Onboard individual features to spec-driven development\n- **merge_feature_specifications**: Combine multiple feature specifications into master specification\n- **detect_specification_conflicts**: Identify conflicts between feature specifications\n- **resolve_feature_dependencies**: Analyze and document dependencies between features\n- **create_progressive_migration_plan**: Create phased migration plans for incremental adoption\n- **track_onboarding_progress**: Track progress across multiple features/teams\n- **validate_specification_consistency**: Ensure consistency across progressive specifications\n\n### 3. Use with your AI agent\n\nOnce configured, your AI agent can use spec-driven development tools directly:\n\n**For New Projects:**\n- Create specifications that define the **what** and **why**, not the tech stack\n- Generate technical implementation plans with your chosen tech stack  \n- Break down features into actionable tasks\n- Manage the complete spec-driven development lifecycle\n\n**For Existing Projects:**\n- Analyze existing project structure and extract requirements\n- Parse documentation and code to understand current specifications\n- Generate standardized Spec-Kit compatible specifications\n- Create migration plans for adopting spec-driven development workflow\n- Onboard legacy projects to modern spec-driven approaches\n\n**For Progressive Onboarding (NEW):**\n- Analyze and onboard individual features or components incrementally\n- Support multiple teams working on different parts independently\n- Merge and coordinate specifications across features\n- Detect and resolve conflicts between feature specifications\n- Track progress and manage dependencies during progressive migration\n- Enable gradual adoption of spec-driven development across organizations\n\nFor detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).\nFor existing project onboarding, see our [onboarding guide](./ONBOARDING.md).\n\n## \ud83d\udcda Core philosophy\n\nSpec-Driven Development is a structured process that emphasizes:\n\n- **Intent-driven development** where specifications define the \"_what_\" before the \"_how_\"\n- **Rich specification creation** using guardrails and organizational principles\n- **Multi-step refinement** rather than one-shot code generation from prompts\n- **Heavy reliance** on advanced AI model capabilities for specification interpretation\n\n## \ud83c\udf1f Development phases\n\n| Phase | Focus | Key Activities |\n|-------|-------|----------------|\n| **0-to-1 Development** (\"Greenfield\") | Generate from scratch | <ul><li>Start with high-level requirements</li><li>Generate specifications</li><li>Plan implementation steps</li><li>Build production-ready applications</li></ul> |\n| **Creative Exploration** | Parallel implementations | <ul><li>Explore diverse solutions</li><li>Support multiple technology stacks & architectures</li><li>Experiment with UX patterns</li></ul> |\n| **Iterative Enhancement** (\"Brownfield\") | Brownfield modernization | <ul><li>Add features iteratively</li><li>Modernize legacy systems</li><li>Adapt processes</li></ul> |\n| **Existing Project Onboarding** (**ENHANCED**) | Legacy project migration | <ul><li>Analyze existing codebases and documentation</li><li>Extract and standardize requirements</li><li>Create migration plans</li><li>Adopt spec-driven workflows gradually</li></ul> |\n| **Progressive Onboarding** (**NEW**) | Incremental feature-level adoption | <ul><li>Onboard individual features and components</li><li>Support multi-team development workflows</li><li>Coordinate specifications across features</li><li>Enable gradual organizational adoption</li></ul> |\n\n## \ud83c\udfaf Experimental goals\n\nOur research and experimentation focus on:\n\n### Technology independence\n\n- Create applications using diverse technology stacks\n- Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks\n\n### Enterprise constraints\n\n- Demonstrate mission-critical application development\n- Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)\n- Support enterprise design systems and compliance requirements\n\n### User-centric development\n\n- Build applications for different user cohorts and preferences\n- Support various development approaches (from vibe-coding to AI-native development)\n\n### Creative & iterative processes\n\n- Validate the concept of parallel implementation exploration\n- Provide robust iterative feature development workflows\n- Extend processes to handle upgrades and modernization tasks  \n\n## \ud83d\udd27 Prerequisites\n\n- **Cross-platform**: Windows, Linux, macOS\n- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n- [uv](https://docs.astral.sh/uv/) for package management\n- [Python 3.11+](https://www.python.org/downloads/)\n- [Git](https://git-scm.com/downloads)\n\n## \ud83d\udcd6 Learn more\n\n- **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process\n- **[Detailed Walkthrough](#detailed-process)** - Step-by-step implementation guide\n\n---\n\n## Detailed process\n\n<details>\n<summary>Click to expand the detailed step-by-step walkthrough</summary>\n\nYou can use the Specify CLI to bootstrap your project, which will bring in the required artifacts in your environment. Run:\n\n```bash\nspecify init <project_name>\n```\n\nOr initialize in the current directory:\n\n```bash\nspecify init --here\n```\n\n![Specify CLI bootstrapping a new project in the terminal](./media/specify_cli.gif)\n\nYou will be prompted to select the AI agent you are using. You can also proactively specify it directly in the terminal:\n\n```bash\nspecify init <project_name> --ai claude\nspecify init <project_name> --ai gemini\nspecify init <project_name> --ai copilot\n# Or in current directory:\nspecify init --here --ai claude\n```\n\nThe CLI will check if you have Claude Code or Gemini CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:\n\n```bash\nspecify init <project_name> --ai claude --ignore-agent-tools\n```\n\n### **STEP 1:** Bootstrap the project\n\nGo to the project folder and run your AI agent. In our example, we're using `claude`.\n\n![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)\n\nYou will know that things are configured correctly if you see the `/specify`, `/plan`, and `/tasks` commands available.\n\nThe first step should be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.\n\n>[!IMPORTANT]\n>Be as explicit as possible about _what_ you are trying to build and _why_. **Do not focus on the tech stack at this point**.\n\nAn example prompt:\n\n```text\nDevelop Taskify, a team productivity platform. It should allow users to create projects, add team members,\nassign tasks, comment and move tasks between boards in Kanban style. In this initial phase for this feature,\nlet's call it \"Create Taskify,\" let's have multiple users but the users will be declared ahead of time, predefined. five users in two different categories, one product manager and four engineers. Let's create three\ndifferent sample projects. Let's have the standard Kanban columns for the status of each task, such as \"To Do,\"\n\"In Progress,\" \"In Review,\" and \"Done.\" There will be no login for this application as this is just the very\nfirst testing thing to ensure that our basic features are set up. For each task in the UI for a task card,\nyou should be able to change the current status of the task between the different columns in the Kanban work board.\nYou should be able to leave an unlimited number of comments for a particular card. You should be able to, from that task\ncard, assign one of the valid users. When you first launch Taskify, it's going to give you a list of the five users to pick\nfrom. There will be no password required. When you click on a user, you go into the main view, which displays the list of\nprojects. When you click on a project, you open the Kanban board for that project. You're going to see the columns.\nYou'll be able to drag and drop cards back and forth between different columns. You will see any cards that are\nassigned to you, the currently logged in user, in a different color from all the other ones, so you can quickly\nsee yours. You can edit any comments that you make, but you can't edit comments that other people made. You can\ndelete any comments that you made, but you can't delete comments anybody else made.\n```\n\nAfter this prompt is entered, you should see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.\n\nOnce this step is completed, you should have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\n### **STEP 2:** Functional specification clarification\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there's at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 3:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n\u251c\u2500\u2500 CLAUDE.md\n\u251c\u2500\u2500 memory\n\u2502\t \u251c\u2500\u2500 constitution.md\n\u2502\t \u2514\u2500\u2500 constitution_update_checklist.md\n\u251c\u2500\u2500 scripts\n\u2502\t \u251c\u2500\u2500 check-task-prerequisites.sh\n\u2502\t \u251c\u2500\u2500 common.sh\n\u2502\t \u251c\u2500\u2500 create-new-feature.sh\n\u2502\t \u251c\u2500\u2500 get-feature-paths.sh\n\u2502\t \u251c\u2500\u2500 setup-plan.sh\n\u2502\t \u2514\u2500\u2500 update-claude-md.sh\n\u251c\u2500\u2500 specs\n\u2502\t \u2514\u2500\u2500 001-create-taskify\n\u2502\t     \u251c\u2500\u2500 contracts\n\u2502\t     \u2502\t \u251c\u2500\u2500 api-spec.json\n\u2502\t     \u2502\t \u2514\u2500\u2500 signalr-spec.md\n\u2502\t     \u251c\u2500\u2500 data-model.md\n\u2502\t     \u251c\u2500\u2500 plan.md\n\u2502\t     \u251c\u2500\u2500 quickstart.md\n\u2502\t     \u251c\u2500\u2500 research.md\n\u2502\t     \u2514\u2500\u2500 spec.md\n\u2514\u2500\u2500 templates\n    \u251c\u2500\u2500 CLAUDE-template.md\n    \u251c\u2500\u2500 plan-template.md\n    \u251c\u2500\u2500 spec-template.md\n    \u2514\u2500\u2500 tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it's something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text\nI want you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you're not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don't think that's gonna do much for us in this case.\nThat's way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n>[!NOTE]\n>Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 4:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don't know if there's enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n>[!NOTE]\n>Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### STEP 5: Implementation\n\nOnce ready, instruct Claude Code to implement your solution (example path included):\n\n```text\nimplement specs/002-create-taskify/plan.md\n```\n\nClaude Code will spring into action and will start creating the implementation.\n\n>[!IMPORTANT]\n>Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.\n\nOnce the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.\n\n</details>\n\n---\n\n## Troubleshooting\n\n### Windows Support\n\nSpec Kit now provides full Windows support through Python-based scripts. The CLI automatically detects your platform and uses:\n\n- **Windows**: Python scripts (`.py`) for full compatibility\n- **Linux/macOS**: Bash scripts (`.sh`) with Python fallback\n\n#### Windows-Specific Helpers\n\nFor Windows users, additional wrapper scripts are provided for convenience:\n\n**PowerShell users:**\n```powershell\n# Navigate to your spec-kit project directory\n.\\scripts\\specify-tools.ps1 create-feature \"Add user authentication\"\n.\\scripts\\specify-tools.ps1 setup-plan\n.\\scripts\\specify-tools.ps1 check-prerequisites\n```\n\n**Command Prompt users:**\n```cmd\nREM Navigate to your spec-kit project directory\nscripts\\specify-tools.bat create-feature \"Add user authentication\"\nscripts\\specify-tools.bat setup-plan\nscripts\\specify-tools.bat check-prerequisites\n```\n\n#### Windows Troubleshooting\n\nIf you encounter issues on Windows:\n\n1. **Ensure Python 3.11+ is installed** and available in your PATH\n   ```cmd\n   python --version\n   ```\n\n2. **Install Git for Windows**: https://gitforwindows.org/\n\n3. **Use PowerShell or Command Prompt** for running commands\n\n4. **Check script compatibility**:\n   ```cmd\n   specify scripts\n   ```\n\n5. **If bash scripts fail**, the Python equivalents will be used automatically\n\n### Git Credential Manager on Linux\n\nIf you're having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho \"Downloading Git Credential Manager v2.6.1...\"\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho \"Installing Git Credential Manager...\"\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho \"Configuring Git to use GCM...\"\ngit config --global credential.helper manager\necho \"Cleaning up...\"\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.",
      "### Example: Building a Chat Feature\n\nHere's how these commands transform the traditional development workflow:\n\n**Traditional Approach:**\n```\n1. Write a PRD in a document (2-3 hours)\n2. Create design documents (2-3 hours)\n3. Set up project structure manually (30 minutes)\n4. Write technical specifications (3-4 hours)\n5. Create test plans (2 hours)\nTotal: ~12 hours of documentation work\n```\n\n**SDD with Commands Approach:**\n```bash\n# Step 1: Create the feature specification (5 minutes)\n/new_feature Real-time chat system with message history and user presence\n\n# This automatically:\n# - Creates branch \"003-chat-system\"\n# - Generates specs/003-chat-system/feature-spec.md\n# - Populates it with structured requirements\n\n# Step 2: Generate implementation plan (10 minutes)\n/generate_plan WebSocket for real-time messaging, PostgreSQL for history, Redis for presence\n\n# This automatically creates:\n# - specs/003-chat-system/implementation-plan.md\n# - specs/003-chat-system/implementation-details/\n#   - 00-research.md (WebSocket library comparisons)\n#   - 02-data-model.md (Message and User schemas)\n#   - 03-api-contracts.md (WebSocket events, REST endpoints)\n#   - 06-contract-tests.md (Message flow scenarios)\n#   - 08-inter-library-tests.md (Database-WebSocket integration)\n# - specs/003-chat-system/manual-testing.md\n```\n\nIn 15 minutes, you have:\n- A complete feature specification with user stories and acceptance criteria\n- A detailed implementation plan with technology choices and rationale\n- API contracts and data models ready for code generation\n- Comprehensive test scenarios for both automated and manual testing\n- All documents properly versioned in a feature branch\n\n### The Power of Structured Automation\n\nThese commands don't just save time\u2014they enforce consistency and completeness:\n\n1. **No Forgotten Details**: Templates ensure every aspect is considered, from non-functional requirements to error handling\n2. **Traceable Decisions**: Every technical choice links back to specific requirements\n3. **Living Documentation**: Specifications stay in sync with code because they generate it\n4. **Rapid Iteration**: Change requirements and regenerate plans in minutes, not days\n\nThe commands embody SDD principles by treating specifications as executable artifacts rather than static documents. They transform the specification process from a necessary evil into the driving force of development.\n\n### Template-Driven Quality: How Structure Constrains LLMs for Better Outcomes\n\nThe true power of these commands lies not just in automation, but in how the templates guide LLM behavior toward higher-quality specifications. The templates act as sophisticated prompts that constrain the LLM's output in productive ways:\n\n#### 1. **Preventing Premature Implementation Details**\n\nThe feature specification template explicitly instructs:\n```\n- \u2705 Focus on WHAT users need and WHY\n- \u274c Avoid HOW to implement (no tech stack, APIs, code structure)\n```\n\nThis constraint forces the LLM to maintain proper abstraction levels. When an LLM might naturally jump to \"implement using React with Redux,\" the template keeps it focused on \"users need real-time updates of their data.\" This separation ensures specifications remain stable even as implementation technologies change.\n\n#### 2. **Forcing Explicit Uncertainty Markers**\n\nBoth templates mandate the use of `[NEEDS CLARIFICATION]` markers:\n```\nWhen creating this spec from a user prompt:\n1. **Mark all ambiguities**: Use [NEEDS CLARIFICATION: specific question] \n2. **Don't guess**: If the prompt doesn't specify something, mark it\n```\n\nThis prevents the common LLM behavior of making plausible but potentially incorrect assumptions. Instead of guessing that a \"login system\" uses email/password authentication, the LLM must mark it as `[NEEDS CLARIFICATION: auth method not specified - email/password, SSO, OAuth?]`.\n\n#### 3. **Structured Thinking Through Checklists**\n\nThe templates include comprehensive checklists that act as \"unit tests\" for the specification:\n```\n### Requirement Completeness\n- [ ] No [NEEDS CLARIFICATION] markers remain\n- [ ] Requirements are testable and unambiguous  \n- [ ] Success criteria are measurable\n```\n\nThese checklists force the LLM to self-review its output systematically, catching gaps that might otherwise slip through. It's like giving the LLM a quality assurance framework.\n\n#### 4. **Constitutional Compliance Through Gates**\n\nThe implementation plan template enforces architectural principles through phase gates:\n```\n### Phase -1: Pre-Implementation Gates\n#### Simplicity Gate (Article VII)\n- [ ] Using \u22643 projects?\n- [ ] No future-proofing?\n#### Anti-Abstraction Gate (Article VIII)\n- [ ] Using framework directly?\n- [ ] Single model representation?\n```\n\nThese gates prevent over-engineering by making the LLM explicitly justify any complexity. If a gate fails, the LLM must document why in the \"Complexity Tracking\" section, creating accountability for architectural decisions.\n\n#### 5. **Hierarchical Detail Management**\n\nThe templates enforce proper information architecture:\n```\n**IMPORTANT**: This implementation plan should remain high-level and readable. \nAny code samples, detailed algorithms, or extensive technical specifications \nmust be placed in the appropriate `implementation-details/` file\n```\n\nThis prevents the common problem of specifications becoming unreadable code dumps. The LLM learns to maintain appropriate detail levels, extracting complexity to separate files while keeping the main document navigable.\n\n#### 6. **Test-First Thinking**\n\nThe implementation template enforces test-first development:\n```\n### File Creation Order\n1. Create `contracts/` with API specifications\n2. Create test files in order: contract \u2192 integration \u2192 e2e \u2192 unit\n3. Create source files to make tests pass\n```\n\nThis ordering constraint ensures the LLM thinks about testability and contracts before implementation, leading to more robust and verifiable specifications.\n\n#### 7. **Preventing Speculative Features**\n\nTemplates explicitly discourage speculation:\n```\n- [ ] No speculative or \"might need\" features\n- [ ] All phases have clear prerequisites and deliverables\n```\n\nThis stops the LLM from adding \"nice to have\" features that complicate implementation. Every feature must trace back to a concrete user story with clear acceptance criteria.\n\n### The Compound Effect\n\nThese constraints work together to produce specifications that are:\n- **Complete**: Checklists ensure nothing is forgotten\n- **Unambiguous**: Forced clarification markers highlight uncertainties\n- **Testable**: Test-first thinking baked into the process\n- **Maintainable**: Proper abstraction levels and information hierarchy\n- **Implementable**: Clear phases with concrete deliverables\n\nThe templates transform the LLM from a creative writer into a disciplined specification engineer, channeling its capabilities toward producing consistently high-quality, executable specifications that truly drive development.\n\n## The Constitutional Foundation: Enforcing Architectural Discipline\n\nAt the heart of SDD lies a constitution\u2014a set of immutable principles that govern how specifications become code. The constitution (`base/memory/constitution.md`) acts as the architectural DNA of the system, ensuring that every generated implementation maintains consistency, simplicity, and quality.\n\n### The Nine Articles of Development\n\nThe constitution defines nine articles that shape every aspect of the development process:\n\n#### Article I: Library-First Principle\nEvery feature must begin as a standalone library\u2014no exceptions. This forces modular design from the start:\n```\nEvery feature in Specify MUST begin its existence as a standalone library. \nNo feature shall be implemented directly within application code without \nfirst being abstracted into a reusable library component.\n```\n\nThis principle ensures that specifications generate modular, reusable code rather than monolithic applications. When the LLM generates an implementation plan, it must structure features as libraries with clear boundaries and minimal dependencies.\n\n#### Article II: CLI Interface Mandate\nEvery library must expose its functionality through a command-line interface:\n```\nAll CLI interfaces MUST:\n- Accept text as input (via stdin, arguments, or files)\n- Produce text as output (via stdout)\n- Support JSON format for structured data exchange\n```\n\nThis enforces observability and testability. The LLM cannot hide functionality inside opaque classes\u2014everything must be accessible and verifiable through text-based interfaces.\n\n#### Article III: Test-First Imperative\nThe most transformative article\u2014no code before tests:\n```\nThis is NON-NEGOTIABLE: All implementation MUST follow strict Test-Driven Development.\nNo implementation code shall be written before:\n1. Unit tests are written\n2. Tests are validated and approved by the user\n3. Tests are confirmed to FAIL (Red phase)\n```\n\nThis completely inverts traditional AI code generation. Instead of generating code and hoping it works, the LLM must first generate comprehensive tests that define behavior, get them approved, and only then generate implementation.\n\n#### Articles VII & VIII: Simplicity and Anti-Abstraction\nThese paired articles combat over-engineering:\n```\nSection 7.3: Minimal Project Structure\n- Maximum 3 projects for initial implementation\n- Additional projects require documented justification\n\nSection 8.1: Framework Trust\n- Use framework features directly rather than wrapping them\n```\n\nWhen an LLM might naturally create elaborate abstractions, these articles force it to justify every layer of complexity. The implementation plan template's \"Phase -1 Gates\" directly enforce these principles.\n\n#### Article IX: Integration-First Testing\nPrioritizes real-world testing over isolated unit tests:\n```\nTests MUST use realistic environments:\n- Prefer real databases over mocks\n- Use actual service instances over stubs\n- Contract tests mandatory before implementation\n```\n\nThis ensures generated code works in practice, not just in theory.\n\n### Constitutional Enforcement Through Templates\n\nThe implementation plan template operationalizes these articles through concrete checkpoints:\n\n```markdown\n### Phase -1: Pre-Implementation Gates\n#### Simplicity Gate (Article VII)\n- [ ] Using \u22643 projects?\n- [ ] No future-proofing?\n\n#### Anti-Abstraction Gate (Article VIII)\n- [ ] Using framework directly?\n- [ ] Single model representation?\n\n#### Integration-First Gate (Article IX)\n- [ ] Contracts defined?\n- [ ] Contract tests written?\n```\n\nThese gates act as compile-time checks for architectural principles. The LLM cannot proceed without either passing the gates or documenting justified exceptions in the \"Complexity Tracking\" section.\n\n### The Power of Immutable Principles\n\nThe constitution's power lies in its immutability. While implementation details can evolve, the core principles remain constant. This provides:\n\n1. **Consistency Across Time**: Code generated today follows the same principles as code generated next year\n2. **Consistency Across LLMs**: Different AI models produce architecturally compatible code\n3. **Architectural Integrity**: Every feature reinforces rather than undermines the system design\n4. **Quality Guarantees**: Test-first, library-first, and simplicity principles ensure maintainable code\n\n### Constitutional Evolution\n\nWhile principles are immutable, their application can evolve:\n```\nSection 4.2: Amendment Process\nModifications to this constitution require:\n- Explicit documentation of the rationale for change\n- Review and approval by project maintainers\n- Backwards compatibility assessment\n```\n\nThis allows the methodology to learn and improve while maintaining stability. The constitution shows its own evolution with dated amendments, demonstrating how principles can be refined based on real-world experience.\n\n### Beyond Rules: A Development Philosophy\n\nThe constitution isn't just a rulebook\u2014it's a philosophy that shapes how LLMs think about code generation:\n\n- **Observability Over Opacity**: Everything must be inspectable through CLI interfaces\n- **Simplicity Over Cleverness**: Start simple, add complexity only when proven necessary\n- **Integration Over Isolation**: Test in real environments, not artificial ones\n- **Modularity Over Monoliths**: Every feature is a library with clear boundaries\n\nBy embedding these principles into the specification and planning process, SDD ensures that generated code isn't just functional\u2014it's maintainable, testable, and architecturally sound. The constitution transforms AI from a code generator into an architectural partner that respects and reinforces system design principles.\n\n## The Transformation\n\nThis isn't about replacing developers or automating creativity. It's about amplifying human capability by automating mechanical translation. It's about creating a tight feedback loop where specifications, research, and code evolve together, each iteration bringing deeper understanding and better alignment between intent and implementation.\n\nSoftware development needs better tools for maintaining alignment between intent and implementation. SDD provides the methodology for achieving this alignment through executable specifications that generate code rather than merely guiding it.",
      "\u2192 integration test task\n- Implementation tasks to make tests pass\n\n**Ordering Strategy**:\n- TDD order: Tests before implementation \n- Dependency order: Models before services before UI\n- Mark [P] for parallel execution (independent files)\n\n**Estimated Output**: 25-30 numbered, ordered tasks in tasks.md\n\n**IMPORTANT**: This phase is executed by the /tasks command, NOT by /plan\n\n## Phase 3+: Future Implementation\n*These phases are beyond the scope of the /plan command*\n\n**Phase 3**: Task execution (/tasks command creates tasks.md)  \n**Phase 4**: Implementation (execute tasks.md following constitutional principles)  \n**Phase 5**: Validation (run tests, execute quickstart.md, performance validation)\n\n## Complexity Tracking\n*Fill ONLY if Constitution Check has violations that must be justified*\n\n| Violation | Why Needed | Simpler Alternative Rejected Because |\n|-----------|------------|-------------------------------------|\n| [e.g., 4th project] | [current need] | [why 3 projects insufficient] |\n| [e.g., Repository pattern] | [specific problem] | [why direct DB access insufficient] |\n\n\n## Progress Tracking\n*This checklist is updated during execution flow*\n\n**Phase Status**:\n- [ ] Phase 0: Research complete (/plan command)\n- [ ] Phase 1: Design complete (/plan command)\n- [ ] Phase 2: Task planning complete (/plan command - describe approach only)\n- [ ] Phase 3: Tasks generated (/tasks command)\n- [ ] Phase 4: Implementation complete\n- [ ] Phase 5: Validation passed\n\n**Gate Status**:\n- [ ] Initial Constitution Check: PASS\n- [ ] Post-Design Constitution Check: PASS\n- [ ] All NEEDS CLARIFICATION resolved\n- [ ] Complexity deviations documented\n\n---\n*Based on Constitution v2.1.1 - See `/memory/constitution.md`*",
      "[Describe the main user journey in plain language]\n\n### Acceptance Scenarios\n1. **Given** [initial state], **When** [action], **Then** [expected outcome]\n2. **Given** [initial state], **When** [action], **Then** [expected outcome]\n\n### Edge Cases\n- What happens when [boundary condition]?\n- How does system handle [error scenario]?\n\n## Requirements *(mandatory)*\n\n### Functional Requirements\n- **FR-001**: System MUST [specific capability, e.g., \"allow users to create accounts\"]\n- **FR-002**: System MUST [specific capability, e.g., \"validate email addresses\"]  \n- **FR-003**: Users MUST be able to [key interaction, e.g., \"reset their password\"]\n- **FR-004**: System MUST [data requirement, e.g., \"persist user preferences\"]\n- **FR-005**: System MUST [behavior, e.g., \"log all security events\"]\n\n*Example of marking unclear requirements:*\n- **FR-006**: System MUST authenticate users via [NEEDS CLARIFICATION: auth method not specified - email/password, SSO, OAuth?]\n- **FR-007**: System MUST retain user data for [NEEDS CLARIFICATION: retention period not specified]\n\n### Key Entities *(include if feature involves data)*\n- **[Entity 1]**: [What it represents, key attributes without implementation]\n- **[Entity 2]**: [What it represents, relationships to other entities]\n\n---\n\n## Review & Acceptance Checklist\n*GATE: Automated checks run during main() execution*\n\n### Content Quality\n- [ ] No implementation details (languages, frameworks, APIs)\n- [ ] Focused on user value and business needs\n- [ ] Written for non-technical stakeholders\n- [ ] All mandatory sections completed\n\n### Requirement Completeness\n- [ ] No [NEEDS CLARIFICATION] markers remain\n- [ ] Requirements are testable and unambiguous  \n- [ ] Success criteria are measurable\n- [ ] Scope is clearly bounded\n- [ ] Dependencies and assumptions identified\n\n---\n\n## Execution Status\n*Updated by main() during processing*\n\n- [ ] User description parsed\n- [ ] Key concepts extracted\n- [ ] Ambiguities marked\n- [ ] User scenarios defined\n- [ ] Requirements generated\n- [ ] Entities identified\n- [ ] Review checklist passed\n\n---",
      "\u2192 integration test marked [P]\n   - Different files = can be parallel [P]\n   - Same file = sequential (no [P])\n\n5. Order tasks by dependencies:\n   - Setup before everything\n   - Tests before implementation (TDD)\n   - Models before services\n   - Services before endpoints\n   - Core before integration\n   - Everything before polish\n\n6. Include parallel execution examples:\n   - Group [P] tasks that can run together\n   - Show actual Task agent commands\n\n7. Create FEATURE_DIR/tasks.md with:\n   - Correct feature name from implementation plan\n   - Numbered tasks (T001, T002, etc.)\n   - Clear file paths for each task\n   - Dependency notes\n   - Parallel execution guidance\n\nContext for task generation: {ARGS}\n\nThe tasks.md should be immediately executable - each task must be specific enough that an LLM can complete it without additional context."
    ],
    "technical_stack": {
      "languages": [
        "Python"
      ],
      "frameworks": [],
      "build_systems": [
        "Python (pyproject.toml)"
      ],
      "technologies_mentioned": [
        "gitlab",
        "docker",
        "react",
        "rails",
        "typescript",
        "rest",
        "python",
        "postgresql",
        "redis",
        ".net",
        "dotnet",
        "spring",
        "github",
        "api",
        "graphql",
        "git",
        "fastapi",
        "javascript",
        "java",
        "express"
      ]
    },
    "api_specification": [
      "Get started",
      "Get started",
      "Get feature",
      "get the",
      "delete any",
      "delete comments",
      "put of",
      "get to",
      "get https://github",
      "created",
      "spec",
      "Get started",
      "Get started",
      "get the",
      "delete any",
      "delete comments",
      "put of",
      "get to",
      "get https://github",
      "created"
    ],
    "data_model": "[Data model needs to be specified based on code analysis]",
    "implementation_notes": [
      "TODO items found in code:",
      "  - src/spec_kit_mcp/server.py: /FIXME items\",",
      "  - src/spec_kit_mcp/onboarding.py: _items\": [],",
      "  - src/spec_kit_mcp/onboarding.py: /FIXME items",
      "  - src/spec_kit_mcp/onboarding.py: _fixme(content, extracted, relative_path)",
      "  - src/spec_kit_mcp/onboarding.py: _fixme(content: str, extracted: Dict[str, Any], file_path: str) -> None:",
      "FIXME items found in code:",
      "  - src/spec_kit_mcp/server.py: items\",",
      "  - src/spec_kit_mcp/onboarding.py: _items\": [],",
      "  - src/spec_kit_mcp/onboarding.py: items",
      "  - src/spec_kit_mcp/onboarding.py: (content, extracted, relative_path)",
      "  - src/spec_kit_mcp/onboarding.py: (content: str, extracted: Dict[str, Any], file_path: str) -> None:"
    ],
    "testing_strategy": "Existing test infrastructure detected. Maintain and expand current testing approach.",
    "gaps_identified": [
      "High number of TODO/FIXME items (38) indicating incomplete implementation"
    ],
    "recommendations": [
      "Migrate to spec-driven development workflow:",
      "- Consolidate existing documentation into standardized specification format",
      "- Formalize existing requirements into structured format",
      "- Establish regular specification review and update process",
      "- Train team on spec-driven development methodology",
      "- Implement specification-to-implementation toolchain"
    ]
  }
}